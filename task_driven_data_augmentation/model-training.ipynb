{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iITVTcjGrm8"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "%%capture\n",
    "from google.colab import drive # import drive from google colab\n",
    "\n",
    "ROOT = \"/content/drive\"     # default location for the drive\n",
    "\n",
    "drive.mount(ROOT);           # we mount the google drive at /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hltsNIUwGs2-"
   },
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "%%capture\n",
    "%cd /content/drive/My Drive/restoration-mapper/task_driven_data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41963,
     "status": "ok",
     "timestamp": 1588168411763,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "GYrtC8obIAAr",
    "outputId": "a522554d-270f-4c0c-fa41-74e133456b77"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9414,
     "status": "ok",
     "timestamp": 1588171764337,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "RZ1tigQMIehQ",
    "outputId": "9288dcb2-10e0-4aba-abeb-018bd6c0ef37"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4157,
     "status": "ok",
     "timestamp": 1588171909761,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "TExx0ZMDa2vX",
    "outputId": "d8e364ea-362b-4e4d-a5c9-0c59dfbab6ee"
   },
   "outputs": [],
   "source": [
    "!pip install array2gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1588176113179,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "L7Zag0WcIPR_",
    "outputId": "8fae1163-19f0-41a6-ea0d-649a5f31ddb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeVhwS5BJcBR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uu_tUB8IKRGh"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#to make directories\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXpK-mkyKWCY"
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "  dataset = 'acdc'\n",
    "  #no of training images\n",
    "  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n",
    "  #combination of training images\n",
    "  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n",
    "\n",
    "  #learning rate of seg unet\n",
    "  lr_seg = 0.001\n",
    "  # learning rate of generator\n",
    "  lr_gen = 0.0001\n",
    "  # learning rate of discriminator\n",
    "  lr_disc = 0.0001\n",
    "  # lat dim of z sample\n",
    "  z_lat_dim = 100\n",
    "\n",
    "  # ra_en : 0 - disabled, 1 - enabled\n",
    "  ra_en = 0\n",
    "  # select gan type\n",
    "  gan_type = 'gan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n",
    "  # beta value of Adam optimizer\n",
    "  beta_val = 0.9\n",
    "  # to enable the representation of labels with 1 hot encoding\n",
    "  en_1hot = 1\n",
    "\n",
    "  # lamda factors\n",
    "  # for segmenation loss term (lamda_dsc)\n",
    "  lamda_dsc = 1\n",
    "  # adversarial loss term (lamda_adv)\n",
    "  lamda_adv = 1\n",
    "  ### deformation field cGAN specific\n",
    "  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n",
    "  lamda_l1_g = 0.001\n",
    "\n",
    "  ### Intensity field cGAN specific\n",
    "  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n",
    "  lamda_l1_i = 0.001\n",
    "\n",
    "  #version of run\n",
    "  ver = 0\n",
    "\n",
    "  #data aug - 0 - disabled, 1 - enabled\n",
    "  data_aug_seg = 1 # Options include: [0,1]\n",
    "\n",
    "  # segmentation loss to optimize\n",
    "  # 0 for weighted cross entropy, 1 for dice score loss\n",
    "  dsc_loss = 0 # Options include: [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cqzpqbwnvoZ"
   },
   "source": [
    "## Deformation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss init\n",
      "save_dir data_aug_seg/models/acdc/tr_deformation_cgan_unet/ra_en_0_gantype_gan/with_data_aug/lamda_dsc_1_lamda_adv_1_lamda_g_0.001/tr3/c1_v0/unet_model_beta1_0.9_lr_seg_0.001_lr_gen_0.0001_lr_disc_0.0001/\n",
      "loading train imgs\n",
      "(224, 224, 26)\n",
      "<class 'numpy.ndarray'>\n",
      "(224, 224, 26)\n",
      "<class 'numpy.ndarray'>\n",
      "loading val imgs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading unlabeled imgs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/cropped/patient/100/img_cropped.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ff231178d95d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0munl_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlabeled_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loading unlabeled imgs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m \u001b[0munlabeled_imgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_acdc_cropped_img_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munl_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_present\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;31m#print('unlabeled_imgs',unlabeled_imgs.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\School Work\\Yale FES\\2nd year\\Spring\\Deep Learning\\mapping project\\tree-gan\\task_driven_data_augmentation\\dataloaders.py\u001b[0m in \u001b[0;36mload_acdc_cropped_img_labels\u001b[1;34m(self, train_ids_list, label_present)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;31m#print(\"study_id\",study_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mimg_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path_tr_cropped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/img_cropped.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mimg_tmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_present\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mmask_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path_tr_cropped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/mask_cropped.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/cropped/patient/100/img_cropped.npy'"
     ]
    }
   ],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# # load unlabeled images\n",
    "unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_acdc_cropped_img_labels(unl_list,label_present=0)\n",
    "#print('unlabeled_imgs',unlabeled_imgs.shape)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot deformed images for an fixed input image and different per-pixel flow vectors generated from sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    flow_vec,y_geo_deformed,z_cost=sess.run([ae['flow_vec'],ae['y_trans'],ae['z_cost']], feed_dict={ae['x_l']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_deformed_imgs(ld_img_tmp,y_geo_deformed,flow_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the deformed images generated for the fixed input image\n",
    "    f1_util.write_gif_func(ip_img=y_geo_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n",
    "\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "qfnJ_KT5nul0",
    "outputId": "d7e1718a-6ccc-4358-bb7c-dcf421292077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Inputs\n",
      "gen_c1_weights: (100, 6272)\n",
      "gen_c1_biases: (6272,)\n",
      "fcn_c1_weights: (6272, 128)\n",
      "fcn_c1_biases: (128,)\n",
      "fcn_c2_weights: (128, 128)\n",
      "fcn_c2_biases: (128,)\n",
      "fcn_c3_weights: (128, 1)\n",
      "fcn_c3_biases: (1,)\n",
      "z: (20, 100)\n",
      "x_l: (20, 224, 224, 1)\n",
      "x: (?, 224, 224, 1)\n",
      "x_unl: (?, 224, 224, 1)\n",
      "Generator\n",
      "gen_fcn_c1: (20, 6272)\n",
      "gen_fcn_relu_c1: (20, 6272)\n",
      "gen_fcn_reshaped: (20, 7, 7, 128)\n",
      "gen_up5: (20, 14, 14, 128)\n",
      "gen_c5: (20, 14, 14, 128)\n",
      "gen_up4: (20, 28, 28, 128)\n",
      "gen_c4: (20, 28, 28, 64)\n",
      "gen_up3: (20, 56, 56, 64)\n",
      "gen_c3: (20, 56, 56, 32)\n",
      "gen_up2: (20, 112, 112, 32)\n",
      "gen_c2: (20, 112, 112, 16)\n",
      "gen_up1: (20, 224, 224, 16)\n",
      "gen_c1: (20, 224, 224, 16)\n",
      "conv_1a: (20, 224, 224, 16)\n",
      "conv_1b: (20, 224, 224, 16)\n",
      "gen_cat: (20, 224, 224, 32)\n",
      "conv_1c: (20, 224, 224, 16)\n",
      "conv_1d: (20, 224, 224, 16)\n",
      "conv_1e: (20, 224, 224, 2)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "y_trans: (20, 224, 224, 1)\n",
      "Discriminator\n",
      "cat_disc_c1: (?, 224, 224, 1)\n",
      "cat_disc_c1: (?, 224, 224, 1)\n",
      "disc_c1: (?, 112, 112, 16)\n",
      "disc_c2: (?, 56, 56, 32)\n",
      "disc_c3: (?, 28, 28, 64)\n",
      "disc_c4: (?, 14, 14, 128)\n",
      "disc_c5: (?, 7, 7, 128)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "flat_conv: (?, 6272)\n",
      "z_fcn_relu_c1: (?, 128)\n",
      "z_fcn_relu_c2: (?, 128)\n",
      "z_class: (?, 1)\n",
      "D ra_off sigmoid loss\n",
      "G ra_off sigmoid loss\n",
      "UNet Downsampling\n",
      "enc_c1_a: (?, 224, 224, 16)\n",
      "enc_c1_b: (?, 224, 224, 16)\n",
      "enc_c1_pool: (?, 112, 112, 16)\n",
      "enc_c2_a: (?, 112, 112, 32)\n",
      "enc_c2_b: (?, 112, 112, 32)\n",
      "enc_c2_pool: (?, 56, 56, 32)\n",
      "enc_c3_a: (?, 56, 56, 64)\n",
      "enc_c3_b: (?, 56, 56, 64)\n",
      "enc_c3_pool: (?, 28, 28, 64)\n",
      "enc_c4_a: (?, 28, 28, 128)\n",
      "enc_c4_b: (?, 28, 28, 128)\n",
      "enc_c4_pool: (?, 14, 14, 128)\n",
      "enc_c5_a: (?, 14, 14, 256)\n",
      "enc_c5_b: (?, 14, 14, 256)\n",
      "UNet Upsampling\n",
      "dec_up5: (?, 28, 28, 256)\n",
      "dec_dc5: (?, 28, 28, 128)\n",
      "dec_cat_c5: (?, 28, 28, 256)\n",
      "dec_c4_a: (?, 28, 28, 128)\n",
      "dec_c4_b: (?, 28, 28, 128)\n",
      "dec_up4: (?, 56, 56, 128)\n",
      "dec_dc4: (?, 56, 56, 64)\n",
      "dec_cat_c4: (?, 56, 56, 128)\n",
      "dec_c3_a: (?, 56, 56, 64)\n",
      "dec_c3_b: (?, 56, 56, 64)\n",
      "dec_up3: (?, 112, 112, 64)\n",
      "dec_dc3: (?, 112, 112, 32)\n",
      "dec_cat_c3: (?, 112, 112, 64)\n",
      "dec_c2_a: (?, 112, 112, 32)\n",
      "dec_c2_b: (?, 112, 112, 32)\n",
      "dec_up2: (?, 224, 224, 32)\n",
      "dec_dc2: (?, 224, 224, 16)\n",
      "dec_cat_c2: (?, 224, 224, 32)\n",
      "dec_c1_a: (?, 224, 224, 16)\n",
      "seg_c1_a: (?, 224, 224, 16)\n",
      "seg_c1_b: (?, 224, 224, 16)\n",
      "seg_c1_c: (?, 224, 224, 16)\n",
      "seg_fin_layer: (?, 224, 224, 4)\n",
      "y_pred: (?, 224, 224, 4)\n",
      "y_pred_cls: (?, 224, 224)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Define deformation field generator model graph\n",
    "ae = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI-JoaIAOeFl"
   },
   "source": [
    "# Train Additive Intensity Field GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGmOCYBzOi3g"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "# load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "# load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# load unlabeled images\n",
    "unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_acdc_cropped_img_labels(unl_list,label_present=0)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot intensity transformed images for an fixed input image and different sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    int_vec,y_int_deformed,z_cost=sess.run([ae['int_c1'],ae['y_int'],ae['z_cost']], feed_dict={ae['x']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_intensity_transformed_imgs(ld_img_tmp,y_int_deformed,int_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the transformed images generated for the fixed input image\n",
    "    #f1_util.write_gif_func(ip_img=y_int_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define additive intensity field generator model graph\n",
    "ae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define graph to compute 1 hot encoding for an input label\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labeled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        # Here, the labels do not change on application of intensity transformation since it is an additive operation\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        # use additive intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        _,ld_img_batch=sess.run([ae['int_c1'],ae['y_int']],\\\n",
    "                                    feed_dict={ae['x']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        ###########################\n",
    "        # shuffle the quantity/number of images chosen from intensity field cGAN augmented images and rest are original images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch = ld_label_batch_1hot\n",
    "        else:\n",
    "            ld_label_batch = ld_label_batch_tmp\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        #Optimize only Segmentation Network for initial 500 epochs\n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr = np.asarray(mean_f1_arr)\n",
    "        mean_f1 = np.mean(mean_f1_arr)\n",
    "        f1_arr = np.asarray(f1_arr)\n",
    "\n",
    "        if ((epoch_i%disp_step == 0) or (epoch_i==n_epochs-1)):\n",
    "            print('mean_f1',epoch_i, mean_f1)\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Htfi8elnNp4c"
   },
   "source": [
    "# Train Unet with trained GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24877,
     "status": "error",
     "timestamp": 1588173382149,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "W_67bO43M4_R",
    "outputId": "b06d2d3b-0e1c-483a-ea76-baf68b1f7e8d"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('set acdc img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "proj_save_name='tr_deform_and_int_cgans_data_aug/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+\\\n",
    "         '_lamda_g_'+str(params.lamda_l1_g)+'_lamda_i_'+str(params.lamda_l1_i)+\\\n",
    "         '/'+str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+'/unet_model_dsc_loss_'+str(params.dsc_loss)+'_lr_seg_'+str(params.lr_seg)+'/'\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#print(train_list)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "#print(val_list)\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "#print(pixel_val_list)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load deformation field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_geo = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading deformation field cGAN checkpoint file',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_geo = tf.train.Saver(max_to_keep=2)\n",
    "sess_geo = tf.Session(config=config)\n",
    "saver_geo.restore(sess_geo,mp)\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load additive intensity field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_int = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading additive intensity field cGAN checkpoint file ',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_int = tf.train.Saver(max_to_keep=2)\n",
    "sess_int = tf.Session(config=config)\n",
    "saver_int.restore(sess_int,mp)\n",
    "\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=500\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "debug_en=0\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define current graph - unet\n",
    "tf.reset_default_graph()\n",
    "ae = model.unet(learn_rate_seg=params.lr_seg,en_1hot=params.en_1hot,dsc_loss=params.dsc_loss)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define deformations net for labels\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "\n",
    "    ld_img_batch_orig_tmp=np.copy(ld_img_batch)\n",
    "    ld_label_batch_orig_tmp=np.copy(ld_label_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_orig_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp})\n",
    "\n",
    "    ############################\n",
    "    ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    flow_vec,ld_img_batch_geo=sess_geo.run([ae_geo['flow_vec'],ae_geo['y_trans']],\\\n",
    "                                feed_dict={ae_geo['x_l']: ld_img_batch_orig_tmp, ae_geo['z']:z_samples, ae_geo['train_phase']: False})\n",
    "\n",
    "    ld_label_batch_geo=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp,df_ae['flow_v']:flow_vec})\n",
    "    ld_label_batch_geo=ld_label_batch_geo[0]\n",
    "\n",
    "    ############################\n",
    "    # use additive Intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    int_c1,ld_img_batch_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_orig_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_int = ld_label_batch_orig_1hot\n",
    "\n",
    "    ############################\n",
    "    # use additive intensity field cGAN over augmented images generated from deformation field cGAN to create augmented images \\\n",
    "    # that have both spatial deformations and intensity transformations applied in them\n",
    "    ld_img_batch_geo_tmp=np.copy(ld_img_batch_geo)\n",
    "    int_c1,ld_img_batch_geo_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_geo_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_geo_int = np.copy(ld_label_batch_geo)\n",
    "\n",
    "    # shuffle the quantity/number of images chosen from \n",
    "    # deformation field cGAN --> no_g,\n",
    "    # intensity field cGAN   --> no_i,\n",
    "    # both cGANs             --> no_b,\n",
    "    # and rest (batch_size - (no_g+no_i+no_b)) are original images with conventional affine transformations.\n",
    "    no_g=np.random.randint(1, high=5)\n",
    "    no_i=np.random.randint(5, high=10)\n",
    "    no_b=np.random.randint(10, high=15)\n",
    "\n",
    "    ld_img_batch=ld_img_batch_orig_tmp\n",
    "    ld_label_batch=ld_label_batch_orig_1hot\n",
    "\n",
    "    ld_img_batch[0:no_g] = ld_img_batch_geo[0:no_g]\n",
    "    ld_label_batch[0:no_g] = ld_label_batch_geo[0:no_g]\n",
    "    ld_img_batch[no_g:no_i] = ld_img_batch_int[no_g:no_i]\n",
    "    ld_label_batch[no_g:no_i] = ld_label_batch_int[no_g:no_i]\n",
    "    ld_img_batch[no_i:no_b] = ld_img_batch_geo_int[no_i:no_b]\n",
    "    ld_label_batch[no_i:no_b] = ld_label_batch_geo_int[no_i:no_b]\n",
    "\n",
    "    #Optimer over this batch of images\n",
    "    train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                               ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "        mean_f1=np.mean(mean_f1_arr)\n",
    "        f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQSIfVO4TuWI"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.000001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define graph to compute deformed image given an per-pixel flow vector and input image\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        flow_vec,ld_img_batch=sess.run([ae['flow_vec'],ae['y_trans']],\\\n",
    "                                    feed_dict={ae['x_l']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "\n",
    "        ld_label_batch=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch,df_ae['flow_v']:flow_vec})\n",
    "        ld_label_batch=ld_label_batch[0]\n",
    "\n",
    "        ###########################\n",
    "        #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n",
    "        else:\n",
    "            ld_label_batch = np.argmax(ld_label_batch,axis=3)\n",
    "            ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        #Optimize only Segmentation Network for initial 500 epochs\n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch, ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "        mean_f1=np.mean(mean_f1_arr)\n",
    "        f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt name\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOQ/AvBAxfsutD1iwqRfglf",
   "collapsed_sections": [],
   "name": "model-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
