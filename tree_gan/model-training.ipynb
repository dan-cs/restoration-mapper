{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False\n",
    "install = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iITVTcjGrm8"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "if colab:\n",
    "    %%capture\n",
    "    from google.colab import drive # import drive from google colab\n",
    "\n",
    "    ROOT = \"/content/drive\"     # default location for the drive\n",
    "\n",
    "    drive.mount(ROOT);           # we mount the google drive at /content/drive\n",
    "    \n",
    "    # Set working directory\n",
    "    %%capture\n",
    "    %cd /content/drive/My Drive/restoration-mapper/tree_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3487,
     "status": "ok",
     "timestamp": 1588306932931,
     "user": {
      "displayName": "Daniel Csonth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64",
      "userId": "10232999259256545758"
     },
     "user_tz": 240
    },
    "id": "GYrtC8obIAAr",
    "outputId": "edde49b8-a682-409c-fa54-1ee6ca7d233a"
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    !pip install tensorflow==1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10775,
     "status": "ok",
     "timestamp": 1588306940366,
     "user": {
      "displayName": "Daniel Csonth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64",
      "userId": "10232999259256545758"
     },
     "user_tz": 240
    },
    "id": "RZ1tigQMIehQ",
    "outputId": "21841371-a8bf-4c64-d00d-bf839e46a8ee"
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    !pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13068,
     "status": "ok",
     "timestamp": 1588306942836,
     "user": {
      "displayName": "Daniel Csonth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64",
      "userId": "10232999259256545758"
     },
     "user_tz": 240
    },
    "id": "TExx0ZMDa2vX",
    "outputId": "faba60ae-fa16-43fa-bd7f-4aa9410f6dc7"
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    !pip install array2gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13575,
     "status": "ok",
     "timestamp": 1588306943695,
     "user": {
      "displayName": "Daniel Csonth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64",
      "userId": "10232999259256545758"
     },
     "user_tz": 240
    },
    "id": "L7Zag0WcIPR_",
    "outputId": "d1533f77-2224-4221-dd0b-3285ae26dfb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#to make directories\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXpK-mkyKWCY"
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "  dataset = 'acdc'\n",
    "  #no of training images\n",
    "  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n",
    "  #combination of training images\n",
    "  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n",
    "\n",
    "  #learning rate of seg unet\n",
    "  lr_seg = 0.001\n",
    "  # learning rate of generator\n",
    "  lr_gen = 0.0001\n",
    "  # learning rate of discriminator\n",
    "  lr_disc = 0.0001\n",
    "  # lat dim of z sample\n",
    "  z_lat_dim = 100\n",
    "\n",
    "  # ra_en : 0 - disabled, 1 - enabled\n",
    "  ra_en = 0\n",
    "  # select gan type\n",
    "  gan_type = 'gan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n",
    "  # beta value of Adam optimizer\n",
    "  beta_val = 0.9\n",
    "  # to enable the representation of labels with 1 hot encoding\n",
    "  en_1hot = 1\n",
    "\n",
    "  # lamda factors\n",
    "  # for segmenation loss term (lamda_dsc)\n",
    "  lamda_dsc = 1\n",
    "  # adversarial loss term (lamda_adv)\n",
    "  lamda_adv = 1\n",
    "  ### deformation field cGAN specific\n",
    "  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n",
    "  lamda_l1_g = 0.001\n",
    "\n",
    "  ### Intensity field cGAN specific\n",
    "  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n",
    "  lamda_l1_i = 0.001\n",
    "\n",
    "  #version of run\n",
    "  ver = 0\n",
    "\n",
    "  #data aug - 0 - disabled, 1 - enabled\n",
    "  data_aug_seg = 1 # Options include: [0,1]\n",
    "\n",
    "  # segmentation loss to optimize\n",
    "  # 0 for weighted cross entropy, 1 for dice score loss\n",
    "  dsc_loss = 0 # Options include: [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cqzpqbwnvoZ"
   },
   "source": [
    "## Deformation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss init\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir data_aug_seg/models/acdc/tr_deformation_cgan_unet/ra_en_0_gantype_gan/with_data_aug/lamda_dsc_1_lamda_adv_1_lamda_g_0.001/tr3/c1_v0/unet_model_beta1_0.9_lr_seg_0.001_lr_gen_0.0001_lr_disc_0.0001/\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train imgs\n",
      "(16, 16, 20)\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 16, 20)\n",
      "<class 'numpy.ndarray'>\n",
      "loading unlabeled imgs\n",
      "get test imgs list\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels()\n",
    "\n",
    "#D: we might have to adjust this if our mini sample is too small compared to batch size\n",
    "# if(params.no_of_tr_imgs=='tr1'):\n",
    "#     train_imgs_copy=np.copy(train_imgs)\n",
    "#     train_labels_copy=np.copy(train_labels)\n",
    "#     while(train_imgs.shape[2]<cfg.batch_size):\n",
    "#         train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "#         train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "#     del train_imgs_copy,train_labels_copy\n",
    "\n",
    "#D: we will have to put back some of these validation data references\n",
    "#val_list = data_list.val_data()\n",
    "#load both val data and its cropped images\n",
    "#print('loading val imgs')\n",
    "#val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# # load unlabeled images\n",
    "#unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_acdc_cropped_img_labels(label_present=0)\n",
    "#print('unlabeled_imgs',unlabeled_imgs.shape)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "#D: will have to add this back once test data created\n",
    "#test_list = data_list.test_data()\n",
    "#D: will have to figure out struct name in our case - it is used for computing the \n",
    "# model performance, segmentation mask etc. in f1_util.pred_segs_acdc_test_subjs\n",
    "#struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot deformed images for an fixed input image and different per-pixel flow vectors generated from sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    flow_vec,y_geo_deformed,z_cost=sess.run([ae['flow_vec'],ae['y_trans'],ae['z_cost']], feed_dict={ae['x_l']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_deformed_imgs(ld_img_tmp,y_geo_deformed,flow_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the deformed images generated for the fixed input image\n",
    "    f1_util.write_gif_func(ip_img=y_geo_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(20, 4, 4, 128)\n",
      "(20, 8, 8, 128)\n",
      "(20, 16, 16, 16)\n",
      "(20, 16, 16, 16)\n",
      "(20, 16, 16, 16)\n",
      "(20, 16, 16, 32)\n",
      "(20, 16, 16, 16)\n",
      "(20, 16, 16, 16)\n",
      "(20, 16, 16, 2)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "ytrans\n",
      "(20, 16, 16, 1)\n",
      "Discriminator Shapes\n",
      "X unlabel\n",
      "(?, 16, 16, 1)\n",
      "(?, 16, 16, 1)\n",
      "(?, 16, 16, 1)\n",
      "(?, 8, 8, 32)\n",
      "(?, 4, 4, 128)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "(?, 2048)\n",
      "D ra_off sigmoid loss\n",
      "G ra_off sigmoid loss\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Define deformation field generator model graph\n",
    "ae = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: just add some dummy paths to get things to run, was having an error b/c the path name was too long\n",
    "best_model_dir = 'data_aug_seg/models/dabes'\n",
    "logs_path = 'data_aug_seg/models/dabes/tflogs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "#L: make this 10 for quick training to test\n",
    "n_epochs = 10\n",
    "disp_step=400\n",
    "#D: print_step is not used anywhere - remove from our version\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.000001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# define graph to compute deformed image given an per-pixel flow vector and input image\n",
    "df_ae= model.deform_net()\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# D: The FileWriter class provides a mechanism to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.\n",
    "# http://tensorflow.biotecan.com/python/Python_1.8/tensorflow.google.cn/api_docs/python/tf/summary/FileWriter.html \n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1656,
     "status": "error",
     "timestamp": 1588306949148,
     "user": {
      "displayName": "Daniel Csonth",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSdHLnwnqx6y0K49d41peLXVaonB_cLI8fznPw7bc=s64",
      "userId": "10232999259256545758"
     },
     "user_tz": 240
    },
    "id": "qfnJ_KT5nul0",
    "outputId": "debf3d50-b73d-434d-a707-787bb6365bcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    #D: I am not sure why this is out here, but the copy of the ld_label_batch_tmp is inside the next if statement, \n",
    "    # can we consolidate to one place to make it clearer?\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "\n",
    "    #D: for our implementation we should modify this to get rid of all the 1-hot logic\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        flow_vec,ld_img_batch=sess.run([ae['flow_vec'],ae['y_trans']],\\\n",
    "                                    feed_dict={ae['x_l']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "        #D: for our implementation we should modify this to get out 'deform_y' not one hot\n",
    "        ld_label_batch=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch,df_ae['flow_v']:flow_vec})\n",
    "        ld_label_batch=ld_label_batch[0]\n",
    "\n",
    "        ###########################\n",
    "        #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original  images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n",
    "        else:\n",
    "            ld_label_batch = np.argmax(ld_label_batch,axis=3)\n",
    "            ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    ##Optimize only Segmentation Network for initial 500 epochs\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        \n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "    ##Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        \n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch, ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "#D: we will have to put this back, but it requires working out the validation image structure\n",
    "    # if(epoch_i%val_step_update==0):\n",
    "    #     ##Save the model with best DSC for Validation Image\n",
    "    #     mean_f1_arr=[]\n",
    "    #     f1_arr=[]\n",
    "    #     for val_id_no in range(0,len(val_list)):\n",
    "    #         val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "    #         val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "    #         val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "    #         pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "    #         # Compute segmentation mask and dice_score for each validation subject\n",
    "    #         pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "    #         re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "    #         #concatenate dice scores of each val image\n",
    "    #         mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "    #         f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "    #     #avg mean over 2 val subjects\n",
    "    #     mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "    #     mean_f1=np.mean(mean_f1_arr)\n",
    "    #     f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "    #     if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "    #         print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "    #         mean_f1_val_prev = mean_f1\n",
    "    #         # to save the best model with maximum dice score over the entire n_epochs\n",
    "    #         print(\"best model saved at epoch no. \", epoch_i)\n",
    "    #         mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "    #         saver.save(sess, mp_best)\n",
    "\n",
    "    #     #calc. and save validation image dice summary\n",
    "    #     dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "    #                             ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "    #     val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "    #     val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "#L: comment out these b/c mp_best isn't assigned...\n",
    "#saver_new.restore(sess_new, mp_best)\n",
    "#print(\"best model chkpt name\",mp_best)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13968), started -1 day, 23:04:10 ago. (Use '!kill 13968' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21f09f34278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir data_aug_seg/models/dabes/tflogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "#D: we will have to put back some of these validation data references\n",
    "# To compute inference on validation images on the best model\n",
    "#save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "#f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI-JoaIAOeFl"
   },
   "source": [
    "# Train Additive Intensity Field GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGmOCYBzOi3g"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "# load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "# load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# load unlabeled images\n",
    "unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_acdc_cropped_img_labels(unl_list,label_present=0)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot intensity transformed images for an fixed input image and different sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    int_vec,y_int_deformed,z_cost=sess.run([ae['int_c1'],ae['y_int'],ae['z_cost']], feed_dict={ae['x']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_intensity_transformed_imgs(ld_img_tmp,y_int_deformed,int_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the transformed images generated for the fixed input image\n",
    "    #f1_util.write_gif_func(ip_img=y_int_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define additive intensity field generator model graph\n",
    "ae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define graph to compute 1 hot encoding for an input label\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labeled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        # Here, the labels do not change on application of intensity transformation since it is an additive operation\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        # use additive intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        _,ld_img_batch=sess.run([ae['int_c1'],ae['y_int']],\\\n",
    "                                    feed_dict={ae['x']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        ###########################\n",
    "        # shuffle the quantity/number of images chosen from intensity field cGAN augmented images and rest are original images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch = ld_label_batch_1hot\n",
    "        else:\n",
    "            ld_label_batch = ld_label_batch_tmp\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        #Optimize only Segmentation Network for initial 500 epochs\n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr = np.asarray(mean_f1_arr)\n",
    "        mean_f1 = np.mean(mean_f1_arr)\n",
    "        f1_arr = np.asarray(f1_arr)\n",
    "\n",
    "        if ((epoch_i%disp_step == 0) or (epoch_i==n_epochs-1)):\n",
    "            print('mean_f1',epoch_i, mean_f1)\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Htfi8elnNp4c"
   },
   "source": [
    "# Train Unet with trained GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24877,
     "status": "error",
     "timestamp": 1588173382149,
     "user": {
      "displayName": "David Paolella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhyvQ2T2w5gaFLerdln3UycYDOGbTDuyWch0kmG=s64",
      "userId": "06299863553633725725"
     },
     "user_tz": 240
    },
    "id": "W_67bO43M4_R",
    "outputId": "b06d2d3b-0e1c-483a-ea76-baf68b1f7e8d"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('set acdc img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "proj_save_name='tr_deform_and_int_cgans_data_aug/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+\\\n",
    "         '_lamda_g_'+str(params.lamda_l1_g)+'_lamda_i_'+str(params.lamda_l1_i)+\\\n",
    "         '/'+str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+'/unet_model_dsc_loss_'+str(params.dsc_loss)+'_lr_seg_'+str(params.lr_seg)+'/'\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#print(train_list)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_acdc_cropped_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "#print(val_list)\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "#print(pixel_val_list)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load deformation field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_geo = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading deformation field cGAN checkpoint file',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_geo = tf.train.Saver(max_to_keep=2)\n",
    "sess_geo = tf.Session(config=config)\n",
    "saver_geo.restore(sess_geo,mp)\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load additive intensity field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_int = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading additive intensity field cGAN checkpoint file ',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_int = tf.train.Saver(max_to_keep=2)\n",
    "sess_int = tf.Session(config=config)\n",
    "saver_int.restore(sess_int,mp)\n",
    "\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=500\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "debug_en=0\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define current graph - unet\n",
    "tf.reset_default_graph()\n",
    "ae = model.unet(learn_rate_seg=params.lr_seg,en_1hot=params.en_1hot,dsc_loss=params.dsc_loss)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define deformations net for labels\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "\n",
    "    ld_img_batch_orig_tmp=np.copy(ld_img_batch)\n",
    "    ld_label_batch_orig_tmp=np.copy(ld_label_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_orig_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp})\n",
    "\n",
    "    ############################\n",
    "    ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    flow_vec,ld_img_batch_geo=sess_geo.run([ae_geo['flow_vec'],ae_geo['y_trans']],\\\n",
    "                                feed_dict={ae_geo['x_l']: ld_img_batch_orig_tmp, ae_geo['z']:z_samples, ae_geo['train_phase']: False})\n",
    "\n",
    "    ld_label_batch_geo=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp,df_ae['flow_v']:flow_vec})\n",
    "    ld_label_batch_geo=ld_label_batch_geo[0]\n",
    "\n",
    "    ############################\n",
    "    # use additive Intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    int_c1,ld_img_batch_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_orig_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_int = ld_label_batch_orig_1hot\n",
    "\n",
    "    ############################\n",
    "    # use additive intensity field cGAN over augmented images generated from deformation field cGAN to create augmented images \\\n",
    "    # that have both spatial deformations and intensity transformations applied in them\n",
    "    ld_img_batch_geo_tmp=np.copy(ld_img_batch_geo)\n",
    "    int_c1,ld_img_batch_geo_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_geo_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_geo_int = np.copy(ld_label_batch_geo)\n",
    "\n",
    "    # shuffle the quantity/number of images chosen from \n",
    "    # deformation field cGAN --> no_g,\n",
    "    # intensity field cGAN   --> no_i,\n",
    "    # both cGANs             --> no_b,\n",
    "    # and rest (batch_size - (no_g+no_i+no_b)) are original images with conventional affine transformations.\n",
    "    no_g=np.random.randint(1, high=5)\n",
    "    no_i=np.random.randint(5, high=10)\n",
    "    no_b=np.random.randint(10, high=15)\n",
    "\n",
    "    ld_img_batch=ld_img_batch_orig_tmp\n",
    "    ld_label_batch=ld_label_batch_orig_1hot\n",
    "\n",
    "    ld_img_batch[0:no_g] = ld_img_batch_geo[0:no_g]\n",
    "    ld_label_batch[0:no_g] = ld_label_batch_geo[0:no_g]\n",
    "    ld_img_batch[no_g:no_i] = ld_img_batch_int[no_g:no_i]\n",
    "    ld_label_batch[no_g:no_i] = ld_label_batch_int[no_g:no_i]\n",
    "    ld_img_batch[no_i:no_b] = ld_img_batch_geo_int[no_i:no_b]\n",
    "    ld_label_batch[no_i:no_b] = ld_label_batch_geo_int[no_i:no_b]\n",
    "\n",
    "    #Optimer over this batch of images\n",
    "    train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                               ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "        mean_f1=np.mean(mean_f1_arr)\n",
    "        f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQSIfVO4TuWI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}