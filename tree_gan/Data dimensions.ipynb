{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is DE42-E989\n",
      "\n",
      " Directory of C:\\Users\\Lucien\\Documents\\School Work\\Yale FES\\2nd year\\Spring\\Deep Learning\\mapping project\\tree-gan\\tree_gan\n",
      "\n",
      "05/04/2020  12:08 PM    <DIR>          .\n",
      "05/04/2020  12:08 PM    <DIR>          ..\n",
      "05/01/2020  01:34 PM    <DIR>          .ipynb_checkpoints\n",
      "05/03/2020  08:07 PM    <DIR>          __pycache__\n",
      "05/01/2020  11:29 AM             1,895 create_cropped_imgs_acdc.py\n",
      "05/01/2020  11:38 AM    <DIR>          data\n",
      "05/04/2020  12:08 PM            16,767 Data dimensions.ipynb\n",
      "05/01/2020  02:56 PM    <DIR>          data_aug_seg\n",
      "05/03/2020  08:06 PM             9,519 dataloaders.py\n",
      "05/03/2020  08:06 PM    <DIR>          experiment_init\n",
      "05/01/2020  05:28 PM            19,998 f1_utils.py\n",
      "05/01/2020  05:28 PM            12,230 layers_bn.py\n",
      "05/01/2020  05:28 PM             3,721 losses.py\n",
      "05/03/2020  09:30 PM    <DIR>          models\n",
      "05/04/2020  12:08 PM            66,985 models.py\n",
      "05/04/2020  10:56 AM            58,847 model-training.ipynb\n",
      "05/03/2020  04:58 PM            51,001 model-training_D_v1.ipynb\n",
      "05/01/2020  11:29 AM             6,081 preprocessing.ipynb\n",
      "05/01/2020  11:29 AM             3,418 README.md\n",
      "05/01/2020  11:29 AM               112 requirements.txt\n",
      "05/01/2020  11:29 AM                 0 test.txt\n",
      "05/03/2020  04:58 PM    <DIR>          train_model\n",
      "05/01/2020  05:19 PM               170 treegan_workspace.code-workspace\n",
      "05/01/2020  05:19 PM            16,775 Untitled.ipynb\n",
      "05/03/2020  08:06 PM            15,521 utils.py\n",
      "              16 File(s)        283,040 bytes\n",
      "               9 Dir(s)  278,195,523,584 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lab_x_mini = np.load('data/gan_processed_data_original/lab_x_mini.npy')\n",
    "lab_y_mini = np.load('data/gan_processed_data_original/lab_y_mini.npy')\n",
    "val_x_mini = np.load('data/gan_processed_data_original/val_x_mini.npy')\n",
    "val_y_mini = np.load('data/gan_processed_data_original/val_y_mini.npy')\n",
    "unlab_x_mini = np.load('data/gan_processed_data_original/unlab_x_mini.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 24, 16, 16, 16)\n",
      "(100, 14, 14)\n",
      "(100, 24, 16, 16, 16)\n",
      "(100, 14, 14)\n",
      "(150, 24, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "print(lab_x_mini.shape)\n",
    "print(lab_y_mini.shape)\n",
    "print(val_x_mini.shape)\n",
    "print(val_y_mini.shape)\n",
    "print(unlab_x_mini.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am just adjusting the data Lucien created to match that of their network:\n",
    "1. The multiple images stacked on top of each other is their last dimension - whereas in the npy from Lucien it is the first\n",
    "    - this is something that we should fix at the data generation point this is just a patch that can be removed if Lucien regenarates the data concatenating it on the last dimension\n",
    "2. I am picking one of our time dimensions\n",
    "3. I am picking one of our 16 bands for now - haven't gotten to seeing how the code would handle it if I set num_channels = 16, so want to just get it to run like this first\n",
    "4. I am removing a pixel around the rim - not sure why our inputs are 16x16 but our masks are 14x14, but don't want that to trip it up for now\n",
    "\n",
    "    #L: the masks represent the labels, so our tree labels are 14x14 instead of the input dimensions of 16x16. This is something unique to our data, I'd imagine in their case (and most cases for segmentation) the dimensionality of the labels and the input data is the same. So we will have to adjust the architecture to allow for this.\n",
    "    \n",
    "    #L: we need to get the input back to 16x16 because all the convolutional arithmetic depends on that. will change mask to 16x16 for now and keep in mind that we need to fix that to 14x14 and address that in the GAN code.\n",
    "    \n",
    "    - though they have some mechanism for fixing this in utils.load_val_images, where they append 0's to match the image sizes, but not sure why their image dimensions don't match either... and that part is also commented out for now\n",
    "5. we might have to adjust the size of this tiny toy dataset to be a little bit bigger\n",
    " - see my comment titled: \"#D: we might have to adjust this if our mini sample is too small compared to batch size\" \n",
    "     - I got rid of code that would duplicate data if the input dataset is too small, so if you get far enough in the training this might become a problem \n",
    "     - so I am letting you know here so you know that is the problem when you get to an error that might be caused by it / maybe = even better: we should just feed it a little bit of a bigger dataset. The batch_size = 20, so let's jsut feed it more than that - I think we will do that anyway, we are not connerned about proving that it works with a super tiny training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: todo later, we need to make sure we are selecting a single band and not a single x/y value,\n",
    "#I forget how the data is originally structured\n",
    "lab_x_mini2 = np.moveaxis(lab_x_mini,0,-1)[0,:,:,:,:]\n",
    "val_x_mini2 = np.moveaxis(val_x_mini,0,-1)[0,:,:,:,:]\n",
    "unlab_x_mini2 = np.moveaxis(unlab_x_mini,0,-1)[0,:,:,:,:]\n",
    "npad = ((1, 1), (1, 1), (0, 0))\n",
    "#lab_y_mini2 = np.pad(np.moveaxis(lab_y_mini,0,-1), pad_width = npad, mode = 'constant')\n",
    "#val_y_mini2 = np.pad(np.moveaxis(val_y_mini,0,-1), pad_width = npad, mode = 'constant')\n",
    "lab_y_mini2 = np.moveaxis(lab_y_mini,0,-1)\n",
    "val_y_mini2 = np.moveaxis(val_y_mini,0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 16, 16, 100)\n",
      "(14, 14, 100)\n",
      "(16, 16, 16, 100)\n",
      "(14, 14, 100)\n",
      "(16, 16, 16, 150)\n"
     ]
    }
   ],
   "source": [
    "print(lab_x_mini2.shape)\n",
    "print(lab_y_mini2.shape)\n",
    "print(val_x_mini2.shape)\n",
    "print(val_y_mini2.shape)\n",
    "print(unlab_x_mini2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: Old turning everything to 14x14\n",
    "#lab_x_mini = np.moveaxis(lab_x_mini,0,-1)[0,1:-1,1:-1,3,:]\n",
    "#lab_y_mini = np.moveaxis(lab_y_mini,0,-1)\n",
    "#unlab_x_mini = np.moveaxis(unlab_x_mini,0,-1)[0,1:-1,1:-1,3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/gan_processed_data/lab_x_mini.npy', lab_x_mini2)\n",
    "np.save('data/gan_processed_data/lab_y_mini.npy', lab_y_mini2)\n",
    "np.save('data/gan_processed_data/val_x_mini.npy', val_x_mini2)\n",
    "np.save('data/gan_processed_data/val_y_mini.npy', val_y_mini2)\n",
    "np.save('data/gan_processed_data/unlab_x_mini.npy', unlab_x_mini2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloop = tf.placeholder(tf.float32, shape=[20, 16, 16, 2], name='v_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.repeat(1, 10240), shape=[20, 16, 16, 2], name='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = tf.compat.v1.image.central_crop(a, .875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(np.delete(np.delete(np.delete(a, 0, 1), 14, 1), 0, 2), 14, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.repeat(True, 7840), shape=[20, 14, 14, 2], name='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.pad(np.tile(1,(14,14)), pad_width = 1, mode = \"constant\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.delete(np.delete(np.delete(np.delete(test, 0, 0), 14, 0), 0, 1), 14, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_x_mini[1,1,:,:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
