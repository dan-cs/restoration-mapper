{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQF4P0_cQdFK"
   },
   "outputs": [],
   "source": [
    "colab = False  \n",
    "install = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6iITVTcjGrm8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "%%capture\n",
    "if colab:\n",
    "    from google.colab import drive # import drive from google colab\n",
    "\n",
    "    ROOT = \"/content/drive\"     # default location for the drive\n",
    "\n",
    "    drive.mount(ROOT);           # we mount the google drive at /content/drive\n",
    "    \n",
    "    # Set working directory\n",
    "    %cd /content/drive/My Drive/restoration-mapper/tree_gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYrtC8obIAAr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.13.1 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.33.6)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.0.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.11.3)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.17.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.27.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/danielcsonth/.local/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.2.1)\n",
      "Requirement already satisfied: h5py in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.4.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "if install:\n",
    "    !pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZ1tigQMIehQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==2.2.0 (from -r requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/51/15/a397b941318d7d7f9cf2acbb4a35ce53681ec9799068f5ea57d91a6eea7e/matplotlib-2.2.0.tar.gz\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/danielcsonth/opt/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/wx/9rxzg5fx3v3f96l8xxrw92dw0000gn/T/pip-install-k0wgtotj/matplotlib/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/wx/9rxzg5fx3v3f96l8xxrw92dw0000gn/T/pip-install-k0wgtotj/matplotlib/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base pip-egg-info\n",
      "         cwd: /private/var/folders/wx/9rxzg5fx3v3f96l8xxrw92dw0000gn/T/pip-install-k0wgtotj/matplotlib/\n",
      "    Complete output (61 lines):\n",
      "    IMPORTANT WARNING:\n",
      "        pkg-config is not installed.\n",
      "        matplotlib may not be able to find some of its dependencies\n",
      "    ============================================================================\n",
      "    Edit setup.cfg to change the build options\n",
      "    \n",
      "    BUILDING MATPLOTLIB\n",
      "                matplotlib: yes [2.2.0]\n",
      "                    python: yes [3.7.4 (default, Aug 13 2019, 15:17:50)  [Clang\n",
      "                            4.0.1 (tags/RELEASE_401/final)]]\n",
      "                  platform: yes [darwin]\n",
      "    \n",
      "    REQUIRED DEPENDENCIES AND EXTENSIONS\n",
      "                     numpy: yes [version 1.17.2]\n",
      "          install_requires: yes [handled by setuptools]\n",
      "                    libagg: yes [pkg-config information for 'libagg' could not\n",
      "                            be found. Using local copy.]\n",
      "                  freetype: no  [The C/C++ header for freetype2 (ft2build.h)\n",
      "                            could not be found.  You may need to install the\n",
      "                            development package.]\n",
      "                       png: yes [version 1.6.37]\n",
      "                     qhull: yes [pkg-config information for 'libqhull' could not\n",
      "                            be found. Using local copy.]\n",
      "    \n",
      "    OPTIONAL SUBPACKAGES\n",
      "               sample_data: yes [installing]\n",
      "                  toolkits: yes [installing]\n",
      "                     tests: no  [skipping due to configuration]\n",
      "            toolkits_tests: no  [skipping due to configuration]\n",
      "    \n",
      "    OPTIONAL BACKEND EXTENSIONS\n",
      "                    macosx: yes [installing, darwin]\n",
      "                    qt5agg: yes [installing, Qt: 5.9.6, PyQt: 5.9.2; PySide2 not\n",
      "                            found]\n",
      "                    qt4agg: no  [PySide not found; PyQt4 not found]\n",
      "                   gtk3agg: no  [Requires pygobject to be installed.]\n",
      "                 gtk3cairo: no  [Requires cairocffi or pycairo to be installed.]\n",
      "                    gtkagg: no  [Requires pygtk]\n",
      "                     tkagg: yes [installing; run-time loading from Python Tcl /\n",
      "                            Tk]\n",
      "                     wxagg: no  [requires wxPython]\n",
      "                       gtk: no  [Requires pygtk]\n",
      "                       agg: yes [installing]\n",
      "                     cairo: no  [cairocffi or pycairo not found]\n",
      "                 windowing: no  [Microsoft Windows only]\n",
      "    \n",
      "    OPTIONAL LATEX DEPENDENCIES\n",
      "                    dvipng: yes [version 1.15]\n",
      "               ghostscript: yes [version 9.23]\n",
      "                     latex: yes [version 3.14159265]\n",
      "                   pdftops: no\n",
      "    \n",
      "    OPTIONAL PACKAGE DATA\n",
      "                      dlls: no  [skipping due to configuration]\n",
      "    \n",
      "    ============================================================================\n",
      "                            * The following required packages can not be built:\n",
      "                            * freetype\n",
      "                            * Try installing freetype with `brew install\n",
      "                            * freetype` and pkg-config with `brew install pkg-\n",
      "                            * config`\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if install:\n",
    "    !pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TExx0ZMDa2vX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: array2gif in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (1.0.4)\n",
      "Requirement already satisfied: numpy in /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages (from array2gif) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "if install:\n",
    "    !pip install array2gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7Zag0WcIPR_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#to make directories\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import argparse\n",
    "\n",
    "# P: allows for easy module reloads\n",
    "from importlib import reload\n",
    "\n",
    "# P\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# P\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXpK-mkyKWCY"
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "  dataset = 'acdc'\n",
    "  #no of training images\n",
    "  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n",
    "  #combination of training images\n",
    "  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n",
    "\n",
    "  #learning rate of seg unet\n",
    "  lr_seg = 0.00001\n",
    "  # learning rate of generator\n",
    "  lr_gen = 0.0001\n",
    "  # learning rate of discriminator\n",
    "  lr_disc = 0.0001\n",
    "  # lat dim of z sample\n",
    "  z_lat_dim = 100\n",
    "\n",
    "  # ra_en : 0 - disabled, 1 - enabled\n",
    "  ra_en = 0\n",
    "  # select gan type\n",
    "  gan_type = 'lsgan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n",
    "  # beta value of Adam optimizer\n",
    "  beta_val = 0.9\n",
    "  # to enable the representation of labels with 1 hot encoding\n",
    "  en_1hot = 1\n",
    "\n",
    "  # lamda factors\n",
    "  # for segmenation loss term (lamda_dsc)\n",
    "  lamda_dsc = 1\n",
    "  # adversarial loss term (lamda_adv)\n",
    "  lamda_adv = 1\n",
    "  ### deformation field cGAN specific\n",
    "  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n",
    "  lamda_l1_g = 0.001\n",
    "\n",
    "  ### Intensity field cGAN specific\n",
    "  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n",
    "  lamda_l1_i = 0.001\n",
    "\n",
    "  #version of run\n",
    "  ver = 0\n",
    "\n",
    "  #data aug - 0 - disabled, 1 - enabled\n",
    "  data_aug_seg = 1 # Options include: [0,1]\n",
    "\n",
    "  # segmentation loss to optimize\n",
    "  # 0 for weighted cross entropy, 1 for dice score loss\n",
    "  dsc_loss = 0 # Options include: [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cqzpqbwnvoZ"
   },
   "source": [
    "## Deformation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB16wUjnQdHp"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "import experiment_init.init_acdc as cfg\n",
    "import experiment_init.data_cfg_acdc as data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMJmPLx-QdHz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss init\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "\n",
    "#print('set acdc orig img dataloader handle')\n",
    "orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "import models \n",
    "model = models.modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzKvy6cfQdIb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_dir:  models/\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir = 'models/'\n",
    "if not os.path.exists(save_dir[:-1]):\n",
    "    os.makedirs(save_dir[:-1])\n",
    "print('save_dir: ',save_dir)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLwxfnLoQdIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train imgs\n",
      "image shape:  (16, 16, 16, 1000)\n",
      "mask shape:  (14, 14, 1000)\n",
      "(1000, 16, 16, 16)\n",
      "(1000, 14, 14)\n",
      "loading val imgs\n",
      "image shape:  (16, 16, 16, 500)\n",
      "mask shape:  (14, 14, 500)\n",
      "val image dims after reshape\n",
      "(500, 16, 16, 16)\n",
      "(500, 14, 14)\n",
      "loading unlabeled imgs\n",
      "image shape:  (16, 16, 16, 2000)\n",
      "unlabeled_imgs (2000, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# load train and val images\n",
    "#train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_imgs(dataset= 'lab')\n",
    "# P: switching dimensions before feeding into minibatch function\n",
    "train_imgs = np.moveaxis(train_imgs,3,0)\n",
    "train_labels = np.moveaxis(train_labels,2,0)\n",
    "print(train_imgs.shape)\n",
    "print(train_labels.shape)\n",
    "#D: we might have to adjust this if our mini sample is too small compared to batch size\n",
    "# if(params.no_of_tr_imgs=='tr1'):\n",
    "#     train_imgs_copy=np.copy(train_imgs)\n",
    "#     train_labels_copy=np.copy(train_labels)\n",
    "#     while(train_imgs.shape[2]<cfg.batch_size):\n",
    "#         train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "#         train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "#     del train_imgs_copy,train_labels_copy\n",
    "\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_imgs,val_labels = dt.load_imgs(dataset= 'val')\n",
    "val_n = val_imgs.shape[3]\n",
    "#L: change to (20,16,16,16)\n",
    "val_imgs = np.moveaxis(val_imgs,3,0)\n",
    "val_labels = np.moveaxis(val_labels,2,0)\n",
    "print('val image dims after reshape')\n",
    "print(val_imgs.shape)\n",
    "print(val_labels.shape)\n",
    "\n",
    "# # load unlabeled images\n",
    "#unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_imgs(dataset= 'unlab')\n",
    "# P: switching dimensions before feeding into minibatch function\n",
    "unlabeled_imgs = np.moveaxis(unlabeled_imgs,3,0)\n",
    "print('unlabeled_imgs',unlabeled_imgs.shape)\n",
    "\n",
    "\n",
    "# get test list\n",
    "#print('get test imgs list')\n",
    "#D: will have to add this back once test data created\n",
    "#test_list = data_list.test_data()\n",
    "#D: will have to figure out struct name in our case - it is used for computing the \n",
    "# model performance, segmentation mask etc. in f1_util.pred_segs_acdc_test_subjs\n",
    "#struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wIQPyXweQdIo"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot deformed images for an fixed input image and different per-pixel flow vectors generated from sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    flow_vec,y_geo_deformed,z_cost=sess.run([ae['flow_vec'],ae['y_trans'],ae['z_cost']], feed_dict={ae['x_l']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_deformed_imgs(ld_img_tmp,y_geo_deformed,flow_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the deformed images generated for the fixed input image\n",
    "    f1_util.write_gif_func(ip_img=y_geo_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iq2HxGrQdJL"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: set class weights so adapts to training data if it changes\n",
    "ntrlabs = np.sum(np.unique(train_labels, return_counts = True)[1])\n",
    "propnotree = (ntrlabs - np.unique(train_labels, return_counts = True)[1][1])/ntrlabs\n",
    "proptree = 1-propnotree\n",
    "classweight = tf.constant([[proptree, propnotree]],name='class_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSUvxMguQdJQ"
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QamwiCTOQdJV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Inputs\n",
      "gen_c1_weights: (100, 256)\n",
      "gen_c1_biases: (256,)\n",
      "fcn_c1_weights: (256, 128)\n",
      "fcn_c1_biases: (128,)\n",
      "fcn_c2_weights: (128, 128)\n",
      "fcn_c2_biases: (128,)\n",
      "fcn_c3_weights: (128, 1)\n",
      "fcn_c3_biases: (1,)\n",
      "z: (20, 100)\n",
      "x_l: (20, 16, 16, 16)\n",
      "x: (?, 16, 16, 16)\n",
      "x_unl: (?, 16, 16, 16)\n",
      "Generator\n",
      "gen_fcn_c1: (20, 256)\n",
      "gen_fcn_relu_c1: (20, 256)\n",
      "gen_fcn_reshaped: (20, 2, 2, 64)\n",
      "gen_up5: (20, 4, 4, 64)\n",
      "gen_c5: (20, 4, 4, 64)\n",
      "gen_up4: (20, 8, 8, 64)\n",
      "gen_c4: (20, 8, 8, 32)\n",
      "gen_up3: (20, 16, 16, 32)\n",
      "gen_c3: (20, 16, 16, 16)\n",
      "conv_1a: (20, 16, 16, 32)\n",
      "conv_1b: (20, 16, 16, 64)\n",
      "gen_cat: (20, 16, 16, 80)\n",
      "conv_1c: (20, 16, 16, 32)\n",
      "conv_1d: (20, 16, 16, 16)\n",
      "conv_1e: (20, 16, 16, 2)\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "y_trans: (20, 16, 16, 16)\n",
      "Discriminator\n",
      "cat_disc_c1: (?, 16, 16, 16)\n",
      "cat_disc_c1: (?, 16, 16, 16)\n",
      "disc_c1: (?, 8, 8, 32)\n",
      "disc_c2: (?, 4, 4, 32)\n",
      "disc_c3: (?, 2, 2, 64)\n",
      "WARNING:tensorflow:From /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "flat_conv: (?, 256)\n",
      "z_fcn_relu_c1: (?, 128)\n",
      "z_fcn_relu_c2: (?, 128)\n",
      "z_class: (?, 1)\n",
      "UNet Downsampling\n",
      "enc_c1_a: (?, 16, 16, 32)\n",
      "enc_c1_b: (?, 16, 16, 32)\n",
      "enc_c1_pool: (?, 8, 8, 32)\n",
      "enc_c2_a: (?, 8, 8, 64)\n",
      "enc_c2_b: (?, 8, 8, 64)\n",
      "enc_c2_pool: (?, 4, 4, 64)\n",
      "enc_c3_a: (?, 4, 4, 128)\n",
      "enc_c3_b: (?, 4, 4, 128)\n",
      "UNet Upsampling\n",
      "dec_up5: (?, 8, 8, 128)\n",
      "dec_dc5: (?, 8, 8, 64)\n",
      "dec_cat_c5: (?, 8, 8, 128)\n",
      "dec_c4_a: (?, 8, 8, 64)\n",
      "dec_c4_b: (?, 8, 8, 64)\n",
      "dec_up4: (?, 16, 16, 64)\n",
      "dec_dc4: (?, 16, 16, 32)\n",
      "dec_cat_c4: (?, 16, 16, 64)\n",
      "dec_c1_a: (?, 16, 16, 32)\n",
      "seg_c1_a: (?, 16, 16, 16)\n",
      "seg_c1_b: (?, 16, 16, 16)\n",
      "seg_c1_c: (?, 16, 16, 16)\n",
      "seg_fin_layer: (?, 14, 14, 2)\n",
      "y_pred: (?, 14, 14, 2)\n",
      "y_pred_cls: (?, 14, 14)\n",
      "WARNING:tensorflow:From /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Define deformation field generator model graph\n",
    "ae = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g,\n",
    "                        class_weights = classweight, num_channels = cfg.num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPU6xYgvQdJm"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "#L: make this 10 for quick training to test\n",
    "n_epochs = 2000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=500\n",
    "f1_val_prev=0.1\n",
    "threshold_f1=0.000001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ja6WdYEQdJ0"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# define graph to compute deformed image given an per-pixel flow vector and input image\n",
    "#L: change this to new function, deform net clip\n",
    "df_ae= model.deform_netclip()\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T64RuzRgQdJ_"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfnJ_KT5nul0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Seg loss:  0.6069899797439575 Seg acc:  0.7089285714285715\n",
      "Epoch:  0 F1 (val):  0.49945028898196964 Acc (val):  0.5897448979591837\n",
      "Epoch:  1 Seg loss:  0.5593841969966888 Seg acc:  0.742219387755102\n",
      "Epoch:  2 Seg loss:  0.5996540586153666 Seg acc:  0.7171768707482992\n",
      "Epoch:  3 Seg loss:  0.5862268209457397 Seg acc:  0.7256377551020408\n",
      "Epoch:  4 Seg loss:  0.5974855422973633 Seg acc:  0.712704081632653\n",
      "Epoch:  5 Seg loss:  0.5860331952571869 Seg acc:  0.721471088435374\n",
      "Epoch:  6 Seg loss:  0.594189465045929 Seg acc:  0.7171282798833819\n",
      "Epoch:  7 Seg loss:  0.580986000597477 Seg acc:  0.7270727040816326\n",
      "Epoch:  8 Seg loss:  0.5713587337070041 Seg acc:  0.735799319727891\n",
      "Epoch:  9 Seg loss:  0.5571956962347031 Seg acc:  0.7464795918367346\n",
      "Epoch:  10 Seg loss:  0.5458080931143328 Seg acc:  0.7547541743970314\n",
      "Epoch:  10 F1 (val):  0.5476790612984974 Acc (val):  0.6297959183673469\n",
      "Epoch:  11 Seg loss:  0.5353772838910421 Seg acc:  0.7614158163265304\n",
      "Epoch:  12 Seg loss:  0.5238377291422623 Seg acc:  0.768877551020408\n",
      "Epoch:  13 Seg loss:  0.5177775876862662 Seg acc:  0.7715561224489794\n",
      "Epoch:  14 Seg loss:  0.5234760284423828 Seg acc:  0.7686734693877549\n",
      "Epoch:  15 Seg loss:  0.5105606485158205 Seg acc:  0.776578443877551\n",
      "Epoch:  16 Seg loss:  0.5071950730155496 Seg acc:  0.7790966386554622\n",
      "Epoch:  17 Seg loss:  0.5027180976337857 Seg acc:  0.7804563492063492\n",
      "Epoch:  18 Seg loss:  0.49988171144535665 Seg acc:  0.7830961331901181\n",
      "Epoch:  19 Seg loss:  0.4980396032333374 Seg acc:  0.7842474489795918\n",
      "Epoch:  20 Seg loss:  0.49325981452351525 Seg acc:  0.7877551020408162\n",
      "Epoch:  20 F1 (val):  0.5719047422601484 Acc (val):  0.6570714285714285\n",
      "Epoch:  21 Seg loss:  0.4849195263602517 Seg acc:  0.7933209647495361\n",
      "Epoch:  22 Seg loss:  0.47824930108111835 Seg acc:  0.7976153504880211\n",
      "Epoch:  23 Seg loss:  0.47762474914391834 Seg acc:  0.7981930272108843\n",
      "Epoch:  24 Seg loss:  0.474710658788681 Seg acc:  0.7997857142857143\n",
      "Epoch:  25 Seg loss:  0.4737884241801042 Seg acc:  0.7986263736263736\n",
      "Epoch:  26 Seg loss:  0.4705187976360321 Seg acc:  0.7999622071050643\n",
      "Epoch:  27 Seg loss:  0.47059136841978344 Seg acc:  0.7994897959183673\n",
      "Epoch:  28 Seg loss:  0.46765173509203156 Seg acc:  0.8013370865587615\n",
      "Epoch:  29 Seg loss:  0.46399889290332796 Seg acc:  0.8033673469387755\n",
      "Epoch:  30 Seg loss:  0.4608036846883835 Seg acc:  0.8050855826201448\n",
      "Epoch:  30 F1 (val):  0.592024267711033 Acc (val):  0.6795510204081633\n",
      "Epoch:  31 Seg loss:  0.4580809576436877 Seg acc:  0.806265943877551\n",
      "Epoch:  32 Seg loss:  0.45698736562873377 Seg acc:  0.8062925170068027\n",
      "Epoch:  33 Seg loss:  0.4555460433749592 Seg acc:  0.8072103841536614\n",
      "Epoch:  34 Seg loss:  0.45636210015841894 Seg acc:  0.8062609329446063\n",
      "Epoch:  35 Seg loss:  0.45508140905035865 Seg acc:  0.8068664965986394\n",
      "Epoch:  36 Seg loss:  0.4521573169811352 Seg acc:  0.8093629343629344\n",
      "Epoch:  37 Seg loss:  0.4504281211840479 Seg acc:  0.8101436627282492\n",
      "Epoch:  38 Seg loss:  0.4484198651252649 Seg acc:  0.81138147566719\n",
      "Epoch:  39 Seg loss:  0.4463204398751259 Seg acc:  0.8121428571428572\n",
      "Epoch:  40 Seg loss:  0.44528272239173333 Seg acc:  0.812655550024888\n",
      "Epoch:  40 F1 (val):  0.6371186359892802 Acc (val):  0.7078163265306122\n",
      "Epoch:  41 Seg loss:  0.44317602969351266 Seg acc:  0.8139152089407191\n",
      "Epoch:  42 Seg loss:  0.4423612162124279 Seg acc:  0.8138170384432842\n",
      "Epoch:  43 Seg loss:  0.44210592995990405 Seg acc:  0.8140596011131724\n",
      "Epoch:  44 Seg loss:  0.43889222078853185 Seg acc:  0.8162018140589568\n",
      "Epoch:  45 Seg loss:  0.436683758445408 Seg acc:  0.8174578527062998\n",
      "Epoch:  46 Seg loss:  0.43450274112376763 Seg acc:  0.8182859313938341\n",
      "Epoch:  47 Seg loss:  0.4332491426418225 Seg acc:  0.818951955782313\n",
      "Epoch:  48 Seg loss:  0.43449521429684695 Seg acc:  0.8182423990004164\n",
      "Epoch:  49 Seg loss:  0.4336614066362381 Seg acc:  0.8185918367346939\n",
      "Epoch:  50 Seg loss:  0.4313023014395845 Seg acc:  0.8200780312124849\n",
      "Epoch:  50 F1 (val):  0.66634326263324 Acc (val):  0.7236632653061225\n",
      "Epoch:  51 Seg loss:  0.4289242086502222 Seg acc:  0.8215463108320251\n",
      "Epoch:  52 Seg loss:  0.42670085520114537 Seg acc:  0.8233827493261455\n",
      "Epoch:  53 Seg loss:  0.4264721760043391 Seg acc:  0.8234977324263038\n",
      "Epoch:  54 Seg loss:  0.42511141246015377 Seg acc:  0.8246289424860853\n",
      "Epoch:  55 Seg loss:  0.4269303908305509 Seg acc:  0.8239340379008746\n",
      "Epoch:  56 Seg loss:  0.4252705202813734 Seg acc:  0.8245435016111707\n",
      "Epoch:  57 Seg loss:  0.42495902345098296 Seg acc:  0.8247800844475721\n",
      "Epoch:  58 Seg loss:  0.42234813510361363 Seg acc:  0.8263403666551367\n",
      "Epoch:  59 Seg loss:  0.4231342628598213 Seg acc:  0.8252763605442177\n",
      "Epoch:  60 Seg loss:  0.4231636157778443 Seg acc:  0.8250920040147207\n",
      "Epoch:  60 F1 (val):  0.6781656277444815 Acc (val):  0.7328979591836735\n",
      "Epoch:  61 Seg loss:  0.42125779438403343 Seg acc:  0.8263989466754444\n",
      "Epoch:  62 Seg loss:  0.42007848620414734 Seg acc:  0.8273769031422094\n",
      "Epoch:  63 Seg loss:  0.41858832631260157 Seg acc:  0.8285475127551021\n",
      "Epoch:  64 Seg loss:  0.41681203521215 Seg acc:  0.8297841444270015\n",
      "Epoch:  65 Seg loss:  0.4161673594604839 Seg acc:  0.8302295918367347\n",
      "Epoch:  66 Seg loss:  0.4147316711162453 Seg acc:  0.8310348766372221\n",
      "Epoch:  67 Seg loss:  0.415743788375574 Seg acc:  0.830904861944778\n",
      "Epoch:  68 Seg loss:  0.4144600893276325 Seg acc:  0.8316215616681455\n",
      "Epoch:  69 Seg loss:  0.4135233815227236 Seg acc:  0.8321282798833819\n",
      "Epoch:  70 Seg loss:  0.4118291798611762 Seg acc:  0.8332063811440069\n",
      "Epoch:  70 F1 (val):  0.7040720315167797 Acc (val):  0.7455918367346939\n",
      "Epoch:  71 Seg loss:  0.40996375845538247 Seg acc:  0.8344883786848072\n",
      "Epoch:  72 Seg loss:  0.41073035295695476 Seg acc:  0.834690383002516\n",
      "Epoch:  73 Seg loss:  0.4098577765194145 Seg acc:  0.8356212079426365\n",
      "Epoch:  74 Seg loss:  0.4089898713429769 Seg acc:  0.8361972789115646\n",
      "Epoch:  75 Seg loss:  0.40833286548915665 Seg acc:  0.8366239258861439\n",
      "Epoch:  76 Seg loss:  0.40641228022513454 Seg acc:  0.8380002650410814\n",
      "Epoch:  77 Seg loss:  0.4056922029226254 Seg acc:  0.8381933542647827\n",
      "Epoch:  78 Seg loss:  0.40489555951915207 Seg acc:  0.8385236373030224\n",
      "Epoch:  79 Seg loss:  0.4044560234993696 Seg acc:  0.8387404336734694\n",
      "Epoch:  80 Seg loss:  0.40483320421642727 Seg acc:  0.8386936255983876\n",
      "Epoch:  80 F1 (val):  0.6974749833416423 Acc (val):  0.7466326530612245\n",
      "Epoch:  81 Seg loss:  0.4047271580230899 Seg acc:  0.838744400199104\n",
      "Epoch:  82 Seg loss:  0.40377937454775154 Seg acc:  0.8392211703958692\n",
      "Epoch:  83 Seg loss:  0.40263345057056066 Seg acc:  0.839859693877551\n",
      "Epoch:  84 Seg loss:  0.40150473398320813 Seg acc:  0.8404801920768307\n",
      "Epoch:  85 Seg loss:  0.39999036802801974 Seg acc:  0.8412731371618414\n",
      "Epoch:  86 Seg loss:  0.39867917525357216 Seg acc:  0.8420654468684025\n",
      "Epoch:  87 Seg loss:  0.39733460105278273 Seg acc:  0.8428107606679035\n",
      "Epoch:  88 Seg loss:  0.3969588681553187 Seg acc:  0.842948864939234\n",
      "Epoch:  89 Seg loss:  0.3963750504785114 Seg acc:  0.8433390022675736\n",
      "Epoch:  90 Seg loss:  0.39576235708299573 Seg acc:  0.8437570082978245\n",
      "Epoch:  90 F1 (val):  0.6994232616089597 Acc (val):  0.7422040816326531\n",
      "Epoch:  91 Seg loss:  0.39503704464953876 Seg acc:  0.8442380212954746\n",
      "Epoch:  92 Seg loss:  0.39536787361227055 Seg acc:  0.8446017116524029\n",
      "Epoch:  93 Seg loss:  0.39458335809251094 Seg acc:  0.8452019105514545\n",
      "Epoch:  94 Seg loss:  0.394141854110517 Seg acc:  0.8454403866809882\n",
      "Epoch:  95 Seg loss:  0.3930963010837634 Seg acc:  0.8459502551020407\n",
      "Epoch:  96 Seg loss:  0.39261227477457106 Seg acc:  0.8462286976646328\n",
      "Epoch:  97 Seg loss:  0.3920804584512905 Seg acc:  0.8465405039566847\n",
      "Epoch:  98 Seg loss:  0.3912116457717587 Seg acc:  0.846938775510204\n",
      "Epoch:  99 Seg loss:  0.39024230003356936 Seg acc:  0.8474132653061224\n",
      "Epoch:  100 Seg loss:  0.38954737015289836 Seg acc:  0.8477849060416246\n",
      "Epoch:  100 F1 (val):  0.704762546375352 Acc (val):  0.7474795918367347\n",
      "Epoch:  101 Seg loss:  0.3880130853138718 Seg acc:  0.8486544617847138\n",
      "Epoch:  102 Seg loss:  0.3872759151227266 Seg acc:  0.8490167426193778\n",
      "Epoch:  103 Seg loss:  0.38651179579588085 Seg acc:  0.8494358320251177\n",
      "Epoch:  104 Seg loss:  0.3859745420160748 Seg acc:  0.8497837706511175\n",
      "Epoch:  105 Seg loss:  0.38526749329746895 Seg acc:  0.850089045051983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  106 Seg loss:  0.38414602719734764 Seg acc:  0.8505411977875261\n",
      "Epoch:  107 Seg loss:  0.38309644548981275 Seg acc:  0.8512306311413453\n",
      "Epoch:  108 Seg loss:  0.3820804261833156 Seg acc:  0.8518161392997564\n",
      "Epoch:  109 Seg loss:  0.3814967694607648 Seg acc:  0.8522263450834878\n",
      "Epoch:  110 Seg loss:  0.3805206791237668 Seg acc:  0.8527164920022061\n",
      "Epoch:  110 F1 (val):  0.7015365057989593 Acc (val):  0.7414795918367347\n",
      "Epoch:  111 Seg loss:  0.3792495176728283 Seg acc:  0.8533527696793003\n",
      "Epoch:  112 Seg loss:  0.37865512640075344 Seg acc:  0.8538310456926134\n",
      "Epoch:  113 Seg loss:  0.37823438984260227 Seg acc:  0.8541487647690655\n",
      "Epoch:  114 Seg loss:  0.3779619880344557 Seg acc:  0.8543078970718723\n",
      "Epoch:  115 Seg loss:  0.37679154464396936 Seg acc:  0.8548821252638987\n",
      "Epoch:  116 Seg loss:  0.37573981527079886 Seg acc:  0.8554683411826269\n",
      "Epoch:  117 Seg loss:  0.37508523350549955 Seg acc:  0.8557008820477345\n",
      "Epoch:  118 Seg loss:  0.37441182850288746 Seg acc:  0.8563668324472647\n",
      "Epoch:  119 Seg loss:  0.37391571439802646 Seg acc:  0.8566262755102041\n",
      "Epoch:  120 Seg loss:  0.3726791328142497 Seg acc:  0.8572335132400067\n",
      "Epoch:  120 F1 (val):  0.7024654209811526 Acc (val):  0.7471938775510204\n",
      "Epoch:  121 Seg loss:  0.3716981112957001 Seg acc:  0.8576969722315155\n",
      "Epoch:  122 Seg loss:  0.37124075807206997 Seg acc:  0.857831425253028\n",
      "Epoch:  123 Seg loss:  0.36977951432908734 Seg acc:  0.8585109447004607\n",
      "Epoch:  124 Seg loss:  0.37029940068721773 Seg acc:  0.8582224489795919\n",
      "Epoch:  125 Seg loss:  0.36942768558150246 Seg acc:  0.8586937155814707\n",
      "Epoch:  126 Seg loss:  0.3688344062547984 Seg acc:  0.8589868230756869\n",
      "Epoch:  127 Seg loss:  0.3677757466211915 Seg acc:  0.8594148596938777\n",
      "Epoch:  128 Seg loss:  0.36695524079855096 Seg acc:  0.8598461477614301\n",
      "Epoch:  129 Seg loss:  0.36609313717255226 Seg acc:  0.8604101255886969\n",
      "Epoch:  130 Seg loss:  0.3655856588414607 Seg acc:  0.860653918055772\n",
      "Epoch:  130 F1 (val):  0.7039632153979787 Acc (val):  0.7460204081632653\n",
      "Epoch:  131 Seg loss:  0.36419851739298215 Seg acc:  0.8612766697588127\n",
      "Epoch:  132 Seg loss:  0.3632807017941224 Seg acc:  0.8616637256406322\n",
      "Epoch:  133 Seg loss:  0.3623942256863438 Seg acc:  0.862046908315565\n",
      "Epoch:  134 Seg loss:  0.3615636077192095 Seg acc:  0.8623015873015872\n",
      "Epoch:  135 Seg loss:  0.360855921445524 Seg acc:  0.8627213385354142\n",
      "Epoch:  136 Seg loss:  0.3601936397761324 Seg acc:  0.8630865484880084\n",
      "Epoch:  137 Seg loss:  0.35995548272478406 Seg acc:  0.863300428867199\n",
      "Epoch:  138 Seg loss:  0.35892079641921915 Seg acc:  0.8639315078549406\n",
      "Epoch:  139 Seg loss:  0.3580240902091776 Seg acc:  0.8643458454810495\n",
      "Epoch:  140 Seg loss:  0.3570538838493063 Seg acc:  0.8647398321030539\n",
      "Epoch:  140 F1 (val):  0.702843805371886 Acc (val):  0.7466938775510205\n",
      "Epoch:  141 Seg loss:  0.35611029221138485 Seg acc:  0.8651929433745329\n",
      "Epoch:  142 Seg loss:  0.356069952249527 Seg acc:  0.8651848151848152\n",
      "Epoch:  143 Seg loss:  0.35735767852101064 Seg acc:  0.8651254251700681\n",
      "Epoch:  144 Seg loss:  0.3569401580711891 Seg acc:  0.8653078817733989\n",
      "Epoch:  145 Seg loss:  0.3565348846046892 Seg acc:  0.8656049063461001\n",
      "Epoch:  146 Seg loss:  0.35587150223401126 Seg acc:  0.8659551575732334\n",
      "Epoch:  147 Seg loss:  0.35533277106446187 Seg acc:  0.8662127688913404\n",
      "Epoch:  148 Seg loss:  0.35468945367224264 Seg acc:  0.8665131488837146\n",
      "Epoch:  149 Seg loss:  0.35435105085372925 Seg acc:  0.8666360544217686\n",
      "Epoch:  150 Seg loss:  0.3539897977121618 Seg acc:  0.8668046357615893\n",
      "Epoch:  150 F1 (val):  0.6928125923219386 Acc (val):  0.7400408163265306\n",
      "Epoch:  151 Seg loss:  0.35377735213229533 Seg acc:  0.8669256847475834\n",
      "Epoch:  152 Seg loss:  0.3529743129521414 Seg acc:  0.8673552754435108\n",
      "Epoch:  153 Seg loss:  0.3521720603495449 Seg acc:  0.8678190432016963\n",
      "Epoch:  154 Seg loss:  0.35137149037853366 Seg acc:  0.8680743910467413\n",
      "Epoch:  155 Seg loss:  0.3507890216051004 Seg acc:  0.8683526295133438\n",
      "Epoch:  156 Seg loss:  0.35036277922855064 Seg acc:  0.8685737033666969\n",
      "Epoch:  157 Seg loss:  0.3499820724695544 Seg acc:  0.8687726039783001\n",
      "Epoch:  158 Seg loss:  0.3492554393391939 Seg acc:  0.8691230265691181\n",
      "Epoch:  159 Seg loss:  0.3487219915725291 Seg acc:  0.8693797831632653\n",
      "Epoch:  160 Seg loss:  0.34835242493922663 Seg acc:  0.8696840537457218\n",
      "Epoch:  160 F1 (val):  0.6897777446319391 Acc (val):  0.7402755102040817\n",
      "Epoch:  161 Seg loss:  0.3477312253765118 Seg acc:  0.870014487276392\n",
      "Epoch:  162 Seg loss:  0.34693508709500903 Seg acc:  0.870334606235132\n",
      "Epoch:  163 Seg loss:  0.34650609796730486 Seg acc:  0.8706088227974116\n",
      "Epoch:  164 Seg loss:  0.3463017025680253 Seg acc:  0.870647804576376\n",
      "Epoch:  165 Seg loss:  0.3452861324311739 Seg acc:  0.8711150725350381\n",
      "Epoch:  166 Seg loss:  0.34470582989875426 Seg acc:  0.8713277526579494\n",
      "Epoch:  167 Seg loss:  0.34385424781413304 Seg acc:  0.8717322643343051\n",
      "Epoch:  168 Seg loss:  0.3436731066576828 Seg acc:  0.8717440526506461\n",
      "Epoch:  169 Seg loss:  0.34286429689211007 Seg acc:  0.8720678271308523\n",
      "Epoch:  170 Seg loss:  0.34238526085663956 Seg acc:  0.872252058718224\n",
      "Epoch:  170 F1 (val):  0.7162532579898924 Acc (val):  0.7433367346938775\n",
      "Epoch:  171 Seg loss:  0.34186618428590687 Seg acc:  0.8725053393450403\n",
      "Epoch:  172 Seg loss:  0.3409352254316297 Seg acc:  0.8728869293382093\n",
      "Epoch:  173 Seg loss:  0.34026814945812883 Seg acc:  0.8731776331222145\n",
      "Epoch:  174 Seg loss:  0.33987221581595284 Seg acc:  0.8733571428571429\n",
      "Epoch:  175 Seg loss:  0.3393938031724908 Seg acc:  0.873540410482375\n",
      "Epoch:  176 Seg loss:  0.33920024175428404 Seg acc:  0.8735803643491296\n",
      "Epoch:  177 Seg loss:  0.3386594157540396 Seg acc:  0.8737918481999541\n",
      "Epoch:  178 Seg loss:  0.33840055289215215 Seg acc:  0.8738171246152093\n",
      "Epoch:  179 Seg loss:  0.338190065158738 Seg acc:  0.8739328231292518\n",
      "Epoch:  180 Seg loss:  0.33754601234889164 Seg acc:  0.8742558349306575\n",
      "Epoch:  180 F1 (val):  0.7026317000538865 Acc (val):  0.7444081632653061\n",
      "Epoch:  181 Seg loss:  0.33748747686763386 Seg acc:  0.8743215967705763\n",
      "Epoch:  182 Seg loss:  0.3368402628299317 Seg acc:  0.8746236199397791\n",
      "Epoch:  183 Seg loss:  0.33639576431849727 Seg acc:  0.8748350155279503\n",
      "Epoch:  184 Seg loss:  0.33559847248567115 Seg acc:  0.8752192498621071\n",
      "Epoch:  185 Seg loss:  0.3348350500067075 Seg acc:  0.8755088325652841\n",
      "Epoch:  186 Seg loss:  0.3347515749899461 Seg acc:  0.8755456728145804\n",
      "Epoch:  187 Seg loss:  0.33487351294210616 Seg acc:  0.8754993486756404\n",
      "Epoch:  188 Seg loss:  0.33448914363586085 Seg acc:  0.8756154842889536\n",
      "Epoch:  189 Seg loss:  0.3340262375379864 Seg acc:  0.8758351235230935\n",
      "Epoch:  190 Seg loss:  0.33356692013940265 Seg acc:  0.8760270862271611\n",
      "Epoch:  190 F1 (val):  0.7067020612957884 Acc (val):  0.744061224489796\n",
      "Epoch:  191 Seg loss:  0.33313418660933775 Seg acc:  0.8762157206632653\n",
      "Epoch:  192 Seg loss:  0.3325146692250059 Seg acc:  0.8764909590779317\n",
      "Epoch:  193 Seg loss:  0.3319336674416188 Seg acc:  0.8767528403113823\n",
      "Epoch:  194 Seg loss:  0.3317777223311938 Seg acc:  0.8768380429094714\n",
      "Epoch:  195 Seg loss:  0.33128703339975707 Seg acc:  0.8770225947521865\n",
      "Epoch:  196 Seg loss:  0.33078874783770085 Seg acc:  0.8772052729721329\n",
      "Epoch:  197 Seg loss:  0.3301131497278358 Seg acc:  0.8775304061018345\n",
      "Epoch:  198 Seg loss:  0.32960245994167714 Seg acc:  0.8777599733360679\n",
      "Epoch:  199 Seg loss:  0.3288534839451313 Seg acc:  0.878126275510204\n",
      "Epoch:  200 Seg loss:  0.3282871776404072 Seg acc:  0.8784178596811858\n",
      "Epoch:  200 F1 (val):  0.700637211487459 Acc (val):  0.7421938775510204\n",
      "Epoch:  201 Seg loss:  0.327697983989031 Seg acc:  0.8786699333198625\n",
      "Epoch:  202 Seg loss:  0.3275048320957005 Seg acc:  0.8787410777118729\n",
      "Epoch:  203 Seg loss:  0.3269337815981285 Seg acc:  0.8789565826330532\n",
      "Epoch:  204 Seg loss:  0.32661267111941084 Seg acc:  0.8790492782478845\n",
      "Epoch:  205 Seg loss:  0.32616834494384744 Seg acc:  0.8792537646126412\n",
      "Epoch:  206 Seg loss:  0.3258485286564067 Seg acc:  0.879415606822439\n",
      "Epoch:  207 Seg loss:  0.3253172476990865 Seg acc:  0.8796740090266877\n",
      "Epoch:  208 Seg loss:  0.32536659086720227 Seg acc:  0.8798579240308564\n",
      "Epoch:  209 Seg loss:  0.3255073151418141 Seg acc:  0.8798457240038872\n",
      "Epoch:  210 Seg loss:  0.3252173639586752 Seg acc:  0.8799472869716607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  210 F1 (val):  0.6942694915949312 Acc (val):  0.7385\n",
      "Epoch:  211 Seg loss:  0.32461224426076096 Seg acc:  0.8802187620331152\n",
      "Epoch:  212 Seg loss:  0.3240966140664239 Seg acc:  0.8804601418032002\n",
      "Epoch:  213 Seg loss:  0.32372041610635327 Seg acc:  0.8806253576196835\n",
      "Epoch:  214 Seg loss:  0.3233205683009569 Seg acc:  0.8808459895586143\n",
      "Epoch:  215 Seg loss:  0.3230012030237251 Seg acc:  0.8809878117913833\n",
      "Epoch:  216 Seg loss:  0.3226719990303989 Seg acc:  0.8811530142010721\n",
      "Epoch:  217 Seg loss:  0.32260510161382344 Seg acc:  0.8812722336641079\n",
      "Epoch:  218 Seg loss:  0.32244055796431625 Seg acc:  0.8813495946323735\n",
      "Epoch:  219 Seg loss:  0.3222160581838001 Seg acc:  0.881400742115028\n",
      "Epoch:  220 Seg loss:  0.32172552459110504 Seg acc:  0.8815945609012836\n",
      "Epoch:  220 F1 (val):  0.6981014107835293 Acc (val):  0.7393265306122448\n",
      "Epoch:  221 Seg loss:  0.32163375045533654 Seg acc:  0.8815579610222468\n",
      "Epoch:  222 Seg loss:  0.3210800282089165 Seg acc:  0.8817733595680425\n",
      "Epoch:  223 Seg loss:  0.3209572488974248 Seg acc:  0.8818137299562682\n",
      "Epoch:  224 Seg loss:  0.320491681098938 Seg acc:  0.8820022675736962\n",
      "Epoch:  225 Seg loss:  0.3202873258727842 Seg acc:  0.8821451146830414\n",
      "Epoch:  226 Seg loss:  0.31998415179714756 Seg acc:  0.8822777128472534\n",
      "Epoch:  227 Seg loss:  0.3198621849480428 Seg acc:  0.8822883100608664\n",
      "Epoch:  228 Seg loss:  0.31920593963960375 Seg acc:  0.8825505748150788\n",
      "Epoch:  229 Seg loss:  0.31898216177587924 Seg acc:  0.882618677905945\n",
      "Epoch:  230 Seg loss:  0.31861360500127206 Seg acc:  0.8827336778867391\n",
      "Epoch:  230 F1 (val):  0.7056109401353279 Acc (val):  0.7386326530612245\n",
      "Epoch:  231 Seg loss:  0.3182345211248973 Seg acc:  0.8829026653764955\n",
      "Epoch:  232 Seg loss:  0.31794410777705934 Seg acc:  0.8831063326618201\n",
      "Epoch:  233 Seg loss:  0.317686041068827 Seg acc:  0.883239577882435\n",
      "Epoch:  234 Seg loss:  0.31724971386980505 Seg acc:  0.8833933999131567\n",
      "Epoch:  235 Seg loss:  0.3169543272105314 Seg acc:  0.8835015997924595\n",
      "Epoch:  236 Seg loss:  0.31651187559220356 Seg acc:  0.8837531215017654\n",
      "Epoch:  237 Seg loss:  0.316261040563343 Seg acc:  0.8838535414165668\n",
      "Epoch:  238 Seg loss:  0.31575967371463776 Seg acc:  0.8840417129194775\n",
      "Epoch:  239 Seg loss:  0.31547259793927274 Seg acc:  0.8841634778911565\n",
      "Epoch:  240 Seg loss:  0.3152089898640684 Seg acc:  0.8842577694978406\n",
      "Epoch:  240 F1 (val):  0.6973162378299349 Acc (val):  0.7370102040816326\n",
      "Epoch:  241 Seg loss:  0.31469925646939556 Seg acc:  0.8844588041828302\n",
      "Epoch:  242 Seg loss:  0.3141235262155533 Seg acc:  0.8847043755773915\n",
      "Epoch:  243 Seg loss:  0.3138718802298679 Seg acc:  0.8848820675811309\n",
      "Epoch:  244 Seg loss:  0.3140299185806391 Seg acc:  0.8848531861724283\n",
      "Epoch:  245 Seg loss:  0.31365936921864024 Seg acc:  0.8849676455948233\n",
      "Epoch:  246 Seg loss:  0.3130505085594741 Seg acc:  0.885211311245146\n",
      "Epoch:  247 Seg loss:  0.3127006412513794 Seg acc:  0.8854139236339698\n",
      "Epoch:  248 Seg loss:  0.3121464646844021 Seg acc:  0.8856241291697402\n",
      "Epoch:  249 Seg loss:  0.31183841425180436 Seg acc:  0.8857275510204081\n",
      "Epoch:  250 Seg loss:  0.31179912685160616 Seg acc:  0.8857447759980486\n",
      "Epoch:  250 F1 (val):  0.7079690223014354 Acc (val):  0.7414285714285714\n",
      "Epoch:  251 Seg loss:  0.31144621530695565 Seg acc:  0.8859076368642694\n",
      "Epoch:  252 Seg loss:  0.3109590556074979 Seg acc:  0.8861287004920545\n",
      "Epoch:  253 Seg loss:  0.31054552227962673 Seg acc:  0.8863168889603086\n",
      "Epoch:  254 Seg loss:  0.3101100306300556 Seg acc:  0.886485594237695\n",
      "Epoch:  255 Seg loss:  0.30968879477586597 Seg acc:  0.8866619499362245\n",
      "Epoch:  256 Seg loss:  0.30924953143420386 Seg acc:  0.8868637338203764\n",
      "Epoch:  257 Seg loss:  0.30877693892680397 Seg acc:  0.8870451669039708\n",
      "Epoch:  258 Seg loss:  0.30830251422628013 Seg acc:  0.8872557324087937\n",
      "Epoch:  259 Seg loss:  0.30779199531445134 Seg acc:  0.8874754709576138\n",
      "Epoch:  260 Seg loss:  0.30773801650580773 Seg acc:  0.8875420283055752\n",
      "Epoch:  260 F1 (val):  0.6907388400707107 Acc (val):  0.7371836734693877\n",
      "Epoch:  261 Seg loss:  0.3074047929458036 Seg acc:  0.8877200498520019\n",
      "Epoch:  262 Seg loss:  0.3069396936281552 Seg acc:  0.8879054473500426\n",
      "Epoch:  263 Seg loss:  0.3070507754543514 Seg acc:  0.8879657544836116\n",
      "Epoch:  264 Seg loss:  0.30682843546822386 Seg acc:  0.8880747015787448\n",
      "Epoch:  265 Seg loss:  0.30632822882187993 Seg acc:  0.8882643470922204\n",
      "Epoch:  266 Seg loss:  0.30590027911163004 Seg acc:  0.8884191316976229\n",
      "Epoch:  267 Seg loss:  0.3054172106420816 Seg acc:  0.8886089323789218\n",
      "Epoch:  268 Seg loss:  0.30493681033083053 Seg acc:  0.8888475836431228\n",
      "Epoch:  269 Seg loss:  0.30483090695407655 Seg acc:  0.8889767573696146\n",
      "Epoch:  270 Seg loss:  0.30453587920023506 Seg acc:  0.889093681753144\n",
      "Epoch:  270 F1 (val):  0.6942508447448383 Acc (val):  0.7392755102040817\n",
      "Epoch:  271 Seg loss:  0.3044333267299568 Seg acc:  0.8891197103841536\n",
      "Epoch:  272 Seg loss:  0.30420365432898205 Seg acc:  0.8892081557897884\n",
      "Epoch:  273 Seg loss:  0.30412137383309595 Seg acc:  0.8892819901683302\n",
      "Epoch:  274 Seg loss:  0.3038684332370758 Seg acc:  0.8893877551020408\n",
      "Epoch:  275 Seg loss:  0.3034251507209695 Seg acc:  0.8895583776989057\n",
      "Epoch:  276 Seg loss:  0.30329909942210365 Seg acc:  0.8896448832240478\n",
      "Epoch:  277 Seg loss:  0.30317575768601124 Seg acc:  0.8896839671120247\n",
      "Epoch:  278 Seg loss:  0.30290887470100086 Seg acc:  0.8897566015653573\n",
      "Epoch:  279 Seg loss:  0.30270108718957217 Seg acc:  0.8898979591836735\n",
      "Epoch:  280 Seg loss:  0.30254261179750924 Seg acc:  0.8899311859975306\n",
      "Epoch:  280 F1 (val):  0.6886558856445476 Acc (val):  0.7342244897959184\n",
      "Epoch:  281 Seg loss:  0.30233060114138516 Seg acc:  0.890035641916341\n",
      "Epoch:  282 Seg loss:  0.3018566160446342 Seg acc:  0.8902601499963942\n",
      "Epoch:  283 Seg loss:  0.30175265638341364 Seg acc:  0.8903240873814313\n",
      "Epoch:  284 Seg loss:  0.3015574407682084 Seg acc:  0.8904027926960257\n",
      "Epoch:  285 Seg loss:  0.3014964885957591 Seg acc:  0.8903988868274583\n",
      "Epoch:  286 Seg loss:  0.3012220507507125 Seg acc:  0.8904998933371258\n",
      "Epoch:  287 Seg loss:  0.3010037966693441 Seg acc:  0.8905824829931972\n",
      "Epoch:  288 Seg loss:  0.3005594214662961 Seg acc:  0.8907563025210085\n",
      "Epoch:  289 Seg loss:  0.3003922625348486 Seg acc:  0.8908435960591132\n",
      "Epoch:  290 Seg loss:  0.30006261902166803 Seg acc:  0.890984641279192\n",
      "Epoch:  290 F1 (val):  0.7044080714786759 Acc (val):  0.74\n",
      "Epoch:  291 Seg loss:  0.29964502252740405 Seg acc:  0.8911421931786414\n",
      "Epoch:  292 Seg loss:  0.299199031023849 Seg acc:  0.8912951870167863\n",
      "Epoch:  293 Seg loss:  0.29883563503318905 Seg acc:  0.8914323892822436\n",
      "Epoch:  294 Seg loss:  0.29853590681391245 Seg acc:  0.8915928744379109\n",
      "Epoch:  295 Seg loss:  0.29808812739478574 Seg acc:  0.8917591698841699\n",
      "Epoch:  296 Seg loss:  0.29794554818760266 Seg acc:  0.891830722187865\n",
      "Epoch:  297 Seg loss:  0.2977189578665983 Seg acc:  0.8919026503218735\n",
      "Epoch:  298 Seg loss:  0.2975314999603508 Seg acc:  0.892020169271722\n",
      "Epoch:  299 Seg loss:  0.297217639485995 Seg acc:  0.8921709183673469\n",
      "Epoch:  300 Seg loss:  0.2967466220903238 Seg acc:  0.8923732117431691\n",
      "Epoch:  300 F1 (val):  0.7001133287336132 Acc (val):  0.7385918367346939\n",
      "Epoch:  301 Seg loss:  0.2965783103313667 Seg acc:  0.8924677321259629\n",
      "Epoch:  302 Seg loss:  0.29623548253731363 Seg acc:  0.8926020408163264\n",
      "Epoch:  303 Seg loss:  0.2958812186200368 Seg acc:  0.8927488923200858\n",
      "Epoch:  304 Seg loss:  0.2955852590623449 Seg acc:  0.8928839076614253\n",
      "Epoch:  305 Seg loss:  0.29535536589770534 Seg acc:  0.8929413432039481\n",
      "Epoch:  306 Seg loss:  0.29493749452336215 Seg acc:  0.8930723592368542\n",
      "Epoch:  307 Seg loss:  0.2947641828811014 Seg acc:  0.8931056188709251\n",
      "Epoch:  308 Seg loss:  0.29428538733122805 Seg acc:  0.8932897430816986\n",
      "Epoch:  309 Seg loss:  0.2941585540290802 Seg acc:  0.8933829822251482\n",
      "Epoch:  310 Seg loss:  0.2941631313018094 Seg acc:  0.8934017980182427\n",
      "Epoch:  310 F1 (val):  0.6907136412476661 Acc (val):  0.7354897959183674\n",
      "Epoch:  311 Seg loss:  0.29388737664199793 Seg acc:  0.8935104330193616\n",
      "Epoch:  312 Seg loss:  0.2936998739981423 Seg acc:  0.8936248940470758\n",
      "Epoch:  313 Seg loss:  0.2934416658274687 Seg acc:  0.8937028792408683\n",
      "Epoch:  314 Seg loss:  0.29306961827807954 Seg acc:  0.8938824101068998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  315 Seg loss:  0.29264195857546 Seg acc:  0.8940979398088349\n",
      "Epoch:  316 Seg loss:  0.29220799852620916 Seg acc:  0.8942477306379966\n",
      "Epoch:  317 Seg loss:  0.2917952781203408 Seg acc:  0.8944575471698113\n",
      "Epoch:  318 Seg loss:  0.2914807040209307 Seg acc:  0.8946012731111254\n",
      "Epoch:  319 Seg loss:  0.291096200235188 Seg acc:  0.8947576530612246\n",
      "Epoch:  320 Seg loss:  0.29095454026605483 Seg acc:  0.8947906732786574\n",
      "Epoch:  320 F1 (val):  0.6769334109653181 Acc (val):  0.7251530612244897\n",
      "Epoch:  321 Seg loss:  0.290529131102636 Seg acc:  0.8949835213588541\n",
      "Epoch:  322 Seg loss:  0.29049097453662115 Seg acc:  0.8950061603588805\n",
      "Epoch:  323 Seg loss:  0.29011561956118653 Seg acc:  0.8951719576719577\n",
      "Epoch:  324 Seg loss:  0.2897683388911761 Seg acc:  0.8953076923076924\n",
      "Epoch:  325 Seg loss:  0.28956246883408426 Seg acc:  0.8953956429197446\n",
      "Epoch:  326 Seg loss:  0.2893411485700432 Seg acc:  0.8955626287212132\n",
      "Epoch:  327 Seg loss:  0.2890327390646789 Seg acc:  0.895671042807367\n",
      "Epoch:  328 Seg loss:  0.28865631916602696 Seg acc:  0.8958074871285902\n",
      "Epoch:  329 Seg loss:  0.2883335781819893 Seg acc:  0.8959168212739641\n",
      "Epoch:  330 Seg loss:  0.28793167932876285 Seg acc:  0.8960648005425735\n",
      "Epoch:  330 F1 (val):  0.6821536438558495 Acc (val):  0.7278979591836735\n",
      "Epoch:  331 Seg loss:  0.2878209522151085 Seg acc:  0.896099704942218\n",
      "Epoch:  332 Seg loss:  0.28740692505607374 Seg acc:  0.8963014034442605\n",
      "Epoch:  333 Seg loss:  0.2871633031946456 Seg acc:  0.8963827447146525\n",
      "Epoch:  334 Seg loss:  0.2868565679930929 Seg acc:  0.8965237587572343\n",
      "Epoch:  335 Seg loss:  0.28648923333024695 Seg acc:  0.8966722849854227\n",
      "Epoch:  336 Seg loss:  0.28633574991091776 Seg acc:  0.8967699691152423\n",
      "Epoch:  337 Seg loss:  0.2860212106941014 Seg acc:  0.8968814152880086\n",
      "Epoch:  338 Seg loss:  0.285772778115793 Seg acc:  0.8970072542291253\n",
      "Epoch:  339 Seg loss:  0.2854088662301793 Seg acc:  0.8971503601440575\n",
      "Epoch:  340 Seg loss:  0.2852096270955553 Seg acc:  0.8972559698366148\n",
      "Epoch:  340 F1 (val):  0.6972926649205605 Acc (val):  0.7395510204081632\n",
      "Epoch:  341 Seg loss:  0.2850021702940004 Seg acc:  0.8973169530970283\n",
      "Epoch:  342 Seg loss:  0.28463511164612393 Seg acc:  0.8974712917236866\n",
      "Epoch:  343 Seg loss:  0.2844982770553162 Seg acc:  0.8975275866160419\n",
      "Epoch:  344 Seg loss:  0.28423566282659335 Seg acc:  0.897633836143153\n",
      "Epoch:  345 Seg loss:  0.28396896462392257 Seg acc:  0.8977615901852071\n",
      "Epoch:  346 Seg loss:  0.2836767320845931 Seg acc:  0.8978724342763044\n",
      "Epoch:  347 Seg loss:  0.28328293296454965 Seg acc:  0.8980310227539291\n",
      "Epoch:  348 Seg loss:  0.2828939938784329 Seg acc:  0.8981718905327174\n",
      "Epoch:  349 Seg loss:  0.28261272000414983 Seg acc:  0.8982798833819242\n",
      "Epoch:  350 Seg loss:  0.28228540243076805 Seg acc:  0.8984148787720219\n",
      "Epoch:  350 F1 (val):  0.6926309219691074 Acc (val):  0.734265306122449\n",
      "Epoch:  351 Seg loss:  0.28213147031651303 Seg acc:  0.8984527191558442\n",
      "Epoch:  352 Seg loss:  0.2818923034090496 Seg acc:  0.8985474359715558\n",
      "Epoch:  353 Seg loss:  0.28155564238964503 Seg acc:  0.8986906203159231\n",
      "Epoch:  354 Seg loss:  0.2813641441120228 Seg acc:  0.8987517964932453\n",
      "Epoch:  355 Seg loss:  0.2810796783044097 Seg acc:  0.8988685221279524\n",
      "Epoch:  356 Seg loss:  0.28082010429613397 Seg acc:  0.8989867375521639\n",
      "Epoch:  357 Seg loss:  0.2806977489390853 Seg acc:  0.8990266218219132\n",
      "Epoch:  358 Seg loss:  0.28048830726352575 Seg acc:  0.899100392246035\n",
      "Epoch:  359 Seg loss:  0.28029397800564765 Seg acc:  0.8991652494331066\n",
      "Epoch:  360 Seg loss:  0.2801273013168425 Seg acc:  0.8992339872236984\n",
      "Epoch:  360 F1 (val):  0.697268413669431 Acc (val):  0.7334183673469388\n",
      "Epoch:  361 Seg loss:  0.2800383885180094 Seg acc:  0.8992558349306575\n",
      "Epoch:  362 Seg loss:  0.27974172925817736 Seg acc:  0.8993759487265982\n",
      "Epoch:  363 Seg loss:  0.279808620257037 Seg acc:  0.8994743776631533\n",
      "Epoch:  364 Seg loss:  0.2795290176182577 Seg acc:  0.8995645792563601\n",
      "Epoch:  365 Seg loss:  0.27925746598856044 Seg acc:  0.8996577729452436\n",
      "Epoch:  366 Seg loss:  0.2789756261035597 Seg acc:  0.8997706166935441\n",
      "Epoch:  367 Seg loss:  0.27877092418139393 Seg acc:  0.8998509594055014\n",
      "Epoch:  368 Seg loss:  0.27855683927775077 Seg acc:  0.8999419279907085\n",
      "Epoch:  369 Seg loss:  0.27829816430001647 Seg acc:  0.9000248207391064\n",
      "Epoch:  370 Seg loss:  0.27801263581389046 Seg acc:  0.9001375213158038\n",
      "Epoch:  370 F1 (val):  0.6808596629692447 Acc (val):  0.7301326530612244\n",
      "Epoch:  371 Seg loss:  0.2778152887539197 Seg acc:  0.9002064132104454\n",
      "Epoch:  372 Seg loss:  0.2776430750180825 Seg acc:  0.90027493571155\n",
      "Epoch:  373 Seg loss:  0.27736648602441033 Seg acc:  0.9003962948815889\n",
      "Epoch:  374 Seg loss:  0.2771791579325994 Seg acc:  0.9004721088435373\n",
      "Epoch:  375 Seg loss:  0.27689287577696303 Seg acc:  0.9006024750325662\n",
      "Epoch:  376 Seg loss:  0.2767385265713345 Seg acc:  0.9006624533102365\n",
      "Epoch:  377 Seg loss:  0.27654070580604845 Seg acc:  0.9007443850556095\n",
      "Epoch:  378 Seg loss:  0.2763007939412286 Seg acc:  0.9008009800226159\n",
      "Epoch:  379 Seg loss:  0.2760937849549871 Seg acc:  0.9009009129967777\n",
      "Epoch:  380 Seg loss:  0.2759700795327585 Seg acc:  0.9010016605067225\n",
      "Epoch:  380 F1 (val):  0.6869094065836834 Acc (val):  0.7304693877551021\n",
      "Epoch:  381 Seg loss:  0.2758132020372371 Seg acc:  0.9010765038999892\n",
      "Epoch:  382 Seg loss:  0.2755216073740867 Seg acc:  0.9011895881067832\n",
      "Epoch:  383 Seg loss:  0.2753215867560357 Seg acc:  0.901267538265306\n",
      "Epoch:  384 Seg loss:  0.27507838982266264 Seg acc:  0.9013749006095945\n",
      "Epoch:  385 Seg loss:  0.27487775648659374 Seg acc:  0.901454610341546\n",
      "Epoch:  386 Seg loss:  0.2748593386522559 Seg acc:  0.9014976533248958\n",
      "Epoch:  387 Seg loss:  0.27465937613058333 Seg acc:  0.901572690932043\n",
      "Epoch:  388 Seg loss:  0.2745516394818044 Seg acc:  0.9016270132731755\n",
      "Epoch:  389 Seg loss:  0.2744085859411802 Seg acc:  0.901736002093145\n",
      "Epoch:  390 Seg loss:  0.2743187841704434 Seg acc:  0.9017713607182004\n",
      "Epoch:  390 F1 (val):  0.6990230787126248 Acc (val):  0.7379081632653062\n",
      "Epoch:  391 Seg loss:  0.27410369107917865 Seg acc:  0.9018657590587255\n",
      "Epoch:  392 Seg loss:  0.27392938501810604 Seg acc:  0.9019415017915563\n",
      "Epoch:  393 Seg loss:  0.27389448226859725 Seg acc:  0.9019780120169896\n",
      "Epoch:  394 Seg loss:  0.27354703866228275 Seg acc:  0.9021073366055282\n",
      "Epoch:  395 Seg loss:  0.2731887385098621 Seg acc:  0.9022501803751803\n",
      "Epoch:  396 Seg loss:  0.27292357377651655 Seg acc:  0.9023486094689765\n",
      "Epoch:  397 Seg loss:  0.2727822508269818 Seg acc:  0.9023773202748436\n",
      "Epoch:  398 Seg loss:  0.27270011674790157 Seg acc:  0.902402690399468\n",
      "Epoch:  399 Seg loss:  0.27243780564516784 Seg acc:  0.9025089285714284\n",
      "Epoch:  400 Seg loss:  0.2720704824475576 Seg acc:  0.9026470812764007\n",
      "Epoch:  400 F1 (val):  0.6902707823276683 Acc (val):  0.7298877551020408\n",
      "Epoch:  401 Seg loss:  0.2720791962535227 Seg acc:  0.9026918976545841\n",
      "Epoch:  402 Seg loss:  0.27199258694134043 Seg acc:  0.9027643439509799\n",
      "Epoch:  403 Seg loss:  0.2716951426671873 Seg acc:  0.9028894726207314\n",
      "Epoch:  404 Seg loss:  0.2715425473672372 Seg acc:  0.9029446963970772\n",
      "Epoch:  405 Seg loss:  0.2717322338684439 Seg acc:  0.9029801699004725\n",
      "Epoch:  406 Seg loss:  0.27147794029782973 Seg acc:  0.9030994584566012\n",
      "Epoch:  407 Seg loss:  0.271213753441093 Seg acc:  0.9032012805122048\n",
      "Epoch:  408 Seg loss:  0.2710977706757618 Seg acc:  0.9032489646225238\n",
      "Epoch:  409 Seg loss:  0.2708579861536259 Seg acc:  0.903330637132902\n",
      "Epoch:  410 Seg loss:  0.2706327051504395 Seg acc:  0.9034125328963701\n",
      "Epoch:  410 F1 (val):  0.6928172631420204 Acc (val):  0.7314387755102041\n",
      "Epoch:  411 Seg loss:  0.2704607960451575 Seg acc:  0.9034816475133742\n",
      "Epoch:  412 Seg loss:  0.2703935564574549 Seg acc:  0.9035386915056579\n",
      "Epoch:  413 Seg loss:  0.2701465847411593 Seg acc:  0.9036398254954155\n",
      "Epoch:  414 Seg loss:  0.2698911338685507 Seg acc:  0.9037466191295794\n",
      "Epoch:  415 Seg loss:  0.26963438476937324 Seg acc:  0.9038504464285715\n",
      "Epoch:  416 Seg loss:  0.2694575269516709 Seg acc:  0.9039072823373954\n",
      "Epoch:  417 Seg loss:  0.2692226859513652 Seg acc:  0.9039858168147642\n",
      "Epoch:  418 Seg loss:  0.2689890734904706 Seg acc:  0.9040816326530614\n",
      "Epoch:  419 Seg loss:  0.2686797746235416 Seg acc:  0.9041867103984451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  420 Seg loss:  0.26838260209475445 Seg acc:  0.9043034078239373\n",
      "Epoch:  420 F1 (val):  0.6874217399095552 Acc (val):  0.7276224489795918\n",
      "Epoch:  421 Seg loss:  0.2681967247789505 Seg acc:  0.9043488248379922\n",
      "Epoch:  422 Seg loss:  0.2679898231235238 Seg acc:  0.9044175471607083\n",
      "Epoch:  423 Seg loss:  0.2677747211858349 Seg acc:  0.9044937668463613\n",
      "Epoch:  424 Seg loss:  0.2677439191411523 Seg acc:  0.904499399759904\n",
      "Epoch:  425 Seg loss:  0.26754627667122605 Seg acc:  0.9045762671265689\n",
      "Epoch:  426 Seg loss:  0.26741256325808843 Seg acc:  0.9046300721693831\n",
      "Epoch:  427 Seg loss:  0.2671927363724909 Seg acc:  0.9047146194926569\n",
      "Epoch:  428 Seg loss:  0.2671440307980095 Seg acc:  0.9047387136672851\n",
      "Epoch:  429 Seg loss:  0.26701507315386175 Seg acc:  0.9047876127195065\n",
      "Epoch:  430 Seg loss:  0.2667344128864271 Seg acc:  0.904888962545575\n",
      "Epoch:  430 F1 (val):  0.6898739721054938 Acc (val):  0.7309183673469388\n",
      "Epoch:  431 Seg loss:  0.2663776846947493 Seg acc:  0.9050211404006048\n",
      "Epoch:  432 Seg loss:  0.2662628982689309 Seg acc:  0.9050902578121318\n",
      "Epoch:  433 Seg loss:  0.2660599549725858 Seg acc:  0.905181980626352\n",
      "Epoch:  434 Seg loss:  0.2658477800330897 Seg acc:  0.9052644851043867\n",
      "Epoch:  435 Seg loss:  0.26567806279577244 Seg acc:  0.9053448558322413\n",
      "Epoch:  436 Seg loss:  0.2653855505810722 Seg acc:  0.9054773969084202\n",
      "Epoch:  437 Seg loss:  0.2652536504412895 Seg acc:  0.9055516727238841\n",
      "Epoch:  438 Seg loss:  0.26518319968074766 Seg acc:  0.9055785412114733\n",
      "Epoch:  439 Seg loss:  0.26506452794102103 Seg acc:  0.9056354359925789\n",
      "Epoch:  440 Seg loss:  0.2648827187598698 Seg acc:  0.9057400851497062\n",
      "Epoch:  440 F1 (val):  0.688170555983026 Acc (val):  0.7303061224489796\n",
      "Epoch:  441 Seg loss:  0.26484352390690624 Seg acc:  0.9057640363837843\n",
      "Epoch:  442 Seg loss:  0.264551246004772 Seg acc:  0.9058800156631502\n",
      "Epoch:  443 Seg loss:  0.2644082976018523 Seg acc:  0.905951806398235\n",
      "Epoch:  444 Seg loss:  0.264152661032891 Seg acc:  0.9060387525796836\n",
      "Epoch:  445 Seg loss:  0.2640627565472115 Seg acc:  0.9060623913242427\n",
      "Epoch:  446 Seg loss:  0.2640023277176573 Seg acc:  0.906142423412318\n",
      "Epoch:  447 Seg loss:  0.263783301692456 Seg acc:  0.9062289313046648\n",
      "Epoch:  448 Seg loss:  0.2636815348021968 Seg acc:  0.9062900549975001\n",
      "Epoch:  449 Seg loss:  0.26354521267943914 Seg acc:  0.9063486394557823\n",
      "Epoch:  450 Seg loss:  0.2633525219368036 Seg acc:  0.9064250644825557\n",
      "Epoch:  450 F1 (val):  0.6898869120635305 Acc (val):  0.7281020408163266\n",
      "Epoch:  451 Seg loss:  0.2632723083406423 Seg acc:  0.9064373758352898\n",
      "Epoch:  452 Seg loss:  0.2630180047442581 Seg acc:  0.9065380456818488\n",
      "Epoch:  453 Seg loss:  0.26275760716541224 Seg acc:  0.9066343387575294\n",
      "Epoch:  454 Seg loss:  0.26264894087236007 Seg acc:  0.9066791881587799\n",
      "Epoch:  455 Seg loss:  0.2624648923805931 Seg acc:  0.9067473370927318\n",
      "Epoch:  456 Seg loss:  0.26218494635963857 Seg acc:  0.9068486803911936\n",
      "Epoch:  457 Seg loss:  0.2620555986873968 Seg acc:  0.9068949959896622\n",
      "Epoch:  458 Seg loss:  0.2617934660454461 Seg acc:  0.9070000222311145\n",
      "Epoch:  459 Seg loss:  0.26161814843830855 Seg acc:  0.9070718722271517\n",
      "Epoch:  460 Seg loss:  0.26140838683685874 Seg acc:  0.9071478374430032\n",
      "Epoch:  460 F1 (val):  0.6945260855245026 Acc (val):  0.7292857142857143\n",
      "Epoch:  461 Seg loss:  0.2612773460291681 Seg acc:  0.9071864784874989\n",
      "Epoch:  462 Seg loss:  0.2610798282126371 Seg acc:  0.9072491955745581\n",
      "Epoch:  463 Seg loss:  0.26095556686150617 Seg acc:  0.9072880014074596\n",
      "Epoch:  464 Seg loss:  0.2608204395540299 Seg acc:  0.9073167654158438\n",
      "Epoch:  465 Seg loss:  0.2605805034097684 Seg acc:  0.9073952220373127\n",
      "Epoch:  466 Seg loss:  0.2603777172861569 Seg acc:  0.9074706113708867\n",
      "Epoch:  467 Seg loss:  0.2602898345416428 Seg acc:  0.9075162436769579\n",
      "Epoch:  468 Seg loss:  0.26011028965271865 Seg acc:  0.9075839824202603\n",
      "Epoch:  469 Seg loss:  0.25987568500828234 Seg acc:  0.9076726009552757\n",
      "Epoch:  470 Seg loss:  0.25962037079020417 Seg acc:  0.9077733004029637\n",
      "Epoch:  470 F1 (val):  0.6787927832481482 Acc (val):  0.7267653061224489\n",
      "Epoch:  471 Seg loss:  0.25953522469785256 Seg acc:  0.907807635766171\n",
      "Epoch:  472 Seg loss:  0.25937259792651485 Seg acc:  0.9078515338482117\n",
      "Epoch:  473 Seg loss:  0.2591685396835271 Seg acc:  0.9079269999138896\n",
      "Epoch:  474 Seg loss:  0.25893045717164087 Seg acc:  0.9080064446831364\n",
      "Epoch:  475 Seg loss:  0.25885196831546914 Seg acc:  0.9080282112845138\n",
      "Epoch:  476 Seg loss:  0.25863498758594944 Seg acc:  0.9081049715483678\n",
      "Epoch:  477 Seg loss:  0.25845702821739547 Seg acc:  0.9081798095807362\n",
      "Epoch:  478 Seg loss:  0.2583300301451275 Seg acc:  0.9082346299688978\n",
      "Epoch:  479 Seg loss:  0.2582915110824009 Seg acc:  0.9082493622448979\n",
      "Epoch:  480 Seg loss:  0.258115737391113 Seg acc:  0.908312826169969\n",
      "Epoch:  480 F1 (val):  0.6871164001447401 Acc (val):  0.7295612244897959\n",
      "Epoch:  481 Seg loss:  0.25783934306616113 Seg acc:  0.908419955118977\n",
      "Epoch:  482 Seg loss:  0.2576666799977453 Seg acc:  0.908505514006845\n",
      "Epoch:  483 Seg loss:  0.2574480373781821 Seg acc:  0.9086154916512059\n",
      "Epoch:  484 Seg loss:  0.25741297174053096 Seg acc:  0.9086776772564695\n",
      "Epoch:  485 Seg loss:  0.2572708142607055 Seg acc:  0.9087222852103805\n",
      "Epoch:  486 Seg loss:  0.2570160349383491 Seg acc:  0.9088232829065918\n",
      "Epoch:  487 Seg loss:  0.25687724234322545 Seg acc:  0.9088768191702911\n",
      "Epoch:  488 Seg loss:  0.25679499399991124 Seg acc:  0.9089071825049038\n",
      "Epoch:  489 Seg loss:  0.25683541147380456 Seg acc:  0.908938983756768\n",
      "Epoch:  490 Seg loss:  0.2567751782580209 Seg acc:  0.908965459911052\n",
      "Epoch:  490 F1 (val):  0.688245521320647 Acc (val):  0.7253367346938776\n",
      "Epoch:  491 Seg loss:  0.2565491292928535 Seg acc:  0.90905093744815\n",
      "Epoch:  492 Seg loss:  0.2563909579211993 Seg acc:  0.9091236494597839\n",
      "Epoch:  493 Seg loss:  0.2562771636072682 Seg acc:  0.9091785094604643\n",
      "Epoch:  494 Seg loss:  0.25622209203664703 Seg acc:  0.9092372706658421\n",
      "Epoch:  495 Seg loss:  0.25609124249087706 Seg acc:  0.9092978522053983\n",
      "Epoch:  496 Seg loss:  0.25591168120893193 Seg acc:  0.909358189956063\n",
      "Epoch:  497 Seg loss:  0.2558121449766628 Seg acc:  0.9094152118678798\n",
      "Epoch:  498 Seg loss:  0.255627005560723 Seg acc:  0.9094914318432784\n",
      "Epoch:  499 Seg loss:  0.2555038433521986 Seg acc:  0.9095357142857143\n",
      "Epoch:  500 F1 (val):  0.6900893769859762 Acc (val):  0.7308571428571429\n",
      "Epoch:  501 Seg loss:  0.2558750635581816 Seg acc:  0.9094092427390119 Disc loss:  0.5714116 Gen loss:  1.0355289\n",
      "Epoch:  502 Seg loss:  0.2560885391120179 Seg acc:  0.9093864338564112 Disc loss:  0.48213363 Gen loss:  0.6823586\n",
      "Epoch:  503 Seg loss:  0.25607800648120005 Seg acc:  0.9094250821601007 Disc loss:  0.44969535 Gen loss:  0.54385614\n",
      "Epoch:  504 Seg loss:  0.2560414295673134 Seg acc:  0.9094225785552316 Disc loss:  0.47980222 Gen loss:  0.51543695\n",
      "Epoch:  505 Seg loss:  0.2559515208448514 Seg acc:  0.909438270357648 Disc loss:  0.45063218 Gen loss:  0.5308254\n",
      "Epoch:  506 Seg loss:  0.25594765349869203 Seg acc:  0.9093671856094216 Disc loss:  0.3838339 Gen loss:  0.5707246\n",
      "Epoch:  507 Seg loss:  0.25603532492820563 Seg acc:  0.9093527351769111 Disc loss:  0.4236331 Gen loss:  0.6276388\n",
      "Epoch:  508 Seg loss:  0.2562639775033307 Seg acc:  0.9092730596175479 Disc loss:  0.3930462 Gen loss:  0.72388625\n",
      "Epoch:  509 Seg loss:  0.2565584438752332 Seg acc:  0.9092132432540797 Disc loss:  0.43583727 Gen loss:  0.75817597\n",
      "Epoch:  510 Seg loss:  0.25645635982646664 Seg acc:  0.9092757102841137 Disc loss:  0.38580483 Gen loss:  0.563509\n",
      "Epoch:  510 F1 (val):  0.7265672405124737 Acc (val):  0.7477551020408163\n",
      "Epoch:  511 Seg loss:  0.2566020822484199 Seg acc:  0.9092725348456409 Disc loss:  0.5226356 Gen loss:  0.64213496\n",
      "Epoch:  512 Seg loss:  0.25676996530091856 Seg acc:  0.9092599051339286 Disc loss:  0.42637804 Gen loss:  0.6856909\n",
      "Epoch:  513 Seg loss:  0.2566366888306759 Seg acc:  0.9092990412539286 Disc loss:  0.39723927 Gen loss:  0.55982924\n",
      "Epoch:  514 Seg loss:  0.25658199833234924 Seg acc:  0.909334550940999 Disc loss:  0.4641521 Gen loss:  0.5548863\n",
      "Epoch:  515 Seg loss:  0.2565788103394138 Seg acc:  0.9093719041014465 Disc loss:  0.39384952 Gen loss:  0.65137583\n",
      "Epoch:  516 Seg loss:  0.2566623129672551 Seg acc:  0.9093339661445974 Disc loss:  0.3685016 Gen loss:  0.6721165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  517 Seg loss:  0.2567149995460501 Seg acc:  0.9093395965736392 Disc loss:  0.4480587 Gen loss:  0.60609406\n",
      "Epoch:  518 Seg loss:  0.25673195804580756 Seg acc:  0.9093304310141045 Disc loss:  0.39712194 Gen loss:  0.64236736\n",
      "Epoch:  519 Seg loss:  0.25670238991980376 Seg acc:  0.9093188431441941 Disc loss:  0.39306962 Gen loss:  0.5804027\n",
      "Epoch:  520 Seg loss:  0.2567051205640802 Seg acc:  0.9092930729984302 Disc loss:  0.40883648 Gen loss:  0.6724162\n",
      "Epoch:  520 F1 (val):  0.7090916025448084 Acc (val):  0.7235714285714285\n",
      "Epoch:  521 Seg loss:  0.25669306300709205 Seg acc:  0.9092913941008266 Disc loss:  0.43812495 Gen loss:  0.6033593\n",
      "Epoch:  522 Seg loss:  0.2566880127736207 Seg acc:  0.9093224646180311 Disc loss:  0.37030786 Gen loss:  0.5948539\n",
      "Epoch:  523 Seg loss:  0.25656854811464624 Seg acc:  0.9093675615561712 Disc loss:  0.37694466 Gen loss:  0.60853004\n",
      "Epoch:  524 Seg loss:  0.2565071221213532 Seg acc:  0.9093706184763982 Disc loss:  0.35064706 Gen loss:  0.60935783\n",
      "Epoch:  525 Seg loss:  0.2563857212378865 Seg acc:  0.9094285714285715 Disc loss:  0.34595358 Gen loss:  0.5919156\n",
      "Epoch:  526 Seg loss:  0.25628134198911745 Seg acc:  0.9094824241483667 Disc loss:  0.36748952 Gen loss:  0.60172564\n",
      "Epoch:  527 Seg loss:  0.2561439664670367 Seg acc:  0.9095259071370483 Disc loss:  0.46262062 Gen loss:  0.5286404\n",
      "Epoch:  528 Seg loss:  0.2562542351555418 Seg acc:  0.9094566519789734 Disc loss:  0.36759692 Gen loss:  0.70239645\n",
      "Epoch:  529 Seg loss:  0.25628414168418695 Seg acc:  0.9094204505998997 Disc loss:  0.44150633 Gen loss:  0.61923397\n",
      "Epoch:  530 Seg loss:  0.2561824662364879 Seg acc:  0.9094551405467847 Disc loss:  0.33305097 Gen loss:  0.61258113\n",
      "Epoch:  530 F1 (val):  0.7278768222840881 Acc (val):  0.7542244897959184\n",
      "Epoch:  531 Seg loss:  0.2561619236447941 Seg acc:  0.9094776893808371 Disc loss:  0.40288287 Gen loss:  0.64813316\n",
      "Epoch:  532 Seg loss:  0.25616246222385336 Seg acc:  0.9094766572042351 Disc loss:  0.34431374 Gen loss:  0.6660887\n",
      "Epoch:  533 Seg loss:  0.2563889140846805 Seg acc:  0.909381820270322 Disc loss:  0.38037544 Gen loss:  0.7376937\n",
      "Epoch:  534 Seg loss:  0.25632305567463237 Seg acc:  0.9094244439348774 Disc loss:  0.39376703 Gen loss:  0.5566063\n",
      "Epoch:  535 Seg loss:  0.25631432980298996 Seg acc:  0.9094316231165365 Disc loss:  0.46284062 Gen loss:  0.60392946\n",
      "Epoch:  536 Seg loss:  0.2563046921016787 Seg acc:  0.9094730429485227 Disc loss:  0.36025786 Gen loss:  0.72961295\n",
      "Epoch:  537 Seg loss:  0.25639516610506524 Seg acc:  0.9094877056968039 Disc loss:  0.3109474 Gen loss:  0.7358148\n",
      "Epoch:  538 Seg loss:  0.2563847651961346 Seg acc:  0.9095046847735377 Disc loss:  0.40322083 Gen loss:  0.69414514\n",
      "Epoch:  539 Seg loss:  0.25635424512049704 Seg acc:  0.9095126083828708 Disc loss:  0.52961147 Gen loss:  0.6327133\n",
      "Epoch:  540 Seg loss:  0.2564124381238664 Seg acc:  0.9095148337112623 Disc loss:  0.39490354 Gen loss:  0.67711365\n",
      "Epoch:  540 F1 (val):  0.7093656655801064 Acc (val):  0.7504387755102041\n",
      "Epoch:  541 Seg loss:  0.2563430882728695 Seg acc:  0.9095675053755329 Disc loss:  0.468902 Gen loss:  0.6318869\n",
      "Epoch:  542 Seg loss:  0.25632625992832586 Seg acc:  0.9095785638978838 Disc loss:  0.47699243 Gen loss:  0.670621\n",
      "Epoch:  543 Seg loss:  0.25622078464889614 Seg acc:  0.9095891118878491 Disc loss:  0.31851184 Gen loss:  0.6535123\n",
      "Epoch:  544 Seg loss:  0.25621168179821 Seg acc:  0.9095724227190876 Disc loss:  0.37133992 Gen loss:  0.6839423\n",
      "Epoch:  545 Seg loss:  0.2561669585218123 Seg acc:  0.9095829432690506 Disc loss:  0.3498996 Gen loss:  0.6770981\n",
      "Epoch:  546 Seg loss:  0.2562780175426286 Seg acc:  0.9095611871122076 Disc loss:  0.29522777 Gen loss:  0.7834063\n",
      "Epoch:  547 Seg loss:  0.2562884213147477 Seg acc:  0.9095740215647501 Disc loss:  0.32454792 Gen loss:  0.7237079\n",
      "Epoch:  548 Seg loss:  0.2562960103344526 Seg acc:  0.909542585282288 Disc loss:  0.3546449 Gen loss:  0.68995893\n",
      "Epoch:  549 Seg loss:  0.25624806493629304 Seg acc:  0.9095344968588528 Disc loss:  0.369879 Gen loss:  0.76444525\n",
      "Epoch:  550 Seg loss:  0.25640069751576944 Seg acc:  0.9094740259740259 Disc loss:  0.3982191 Gen loss:  0.7327877\n",
      "Epoch:  550 F1 (val):  0.7400484339669703 Acc (val):  0.7682959183673469\n",
      "Epoch:  551 Seg loss:  0.25634129141235956 Seg acc:  0.909499425904663 Disc loss:  0.31901625 Gen loss:  0.6682965\n",
      "Epoch:  552 Seg loss:  0.25639174213174026 Seg acc:  0.909492846051464 Disc loss:  0.31847766 Gen loss:  0.7533661\n",
      "Epoch:  553 Seg loss:  0.2563708924013064 Seg acc:  0.9095028969996678 Disc loss:  0.25863466 Gen loss:  0.77241427\n",
      "Epoch:  554 Seg loss:  0.2563562063022856 Seg acc:  0.9095106092978709 Disc loss:  0.33077273 Gen loss:  0.68502367\n",
      "Epoch:  555 Seg loss:  0.2562377556889981 Seg acc:  0.9095706931421216 Disc loss:  0.31590694 Gen loss:  0.71769494\n",
      "Epoch:  556 Seg loss:  0.2561706832924978 Seg acc:  0.9096071612098077 Disc loss:  0.31769258 Gen loss:  0.6786048\n",
      "Epoch:  557 Seg loss:  0.2559735722692693 Seg acc:  0.9096879236434251 Disc loss:  0.37392324 Gen loss:  0.59562665\n",
      "Epoch:  558 Seg loss:  0.25594298732483683 Seg acc:  0.9096966205837174 Disc loss:  0.33739346 Gen loss:  0.6667572\n",
      "Epoch:  559 Seg loss:  0.25579749806142665 Seg acc:  0.9097408820415465 Disc loss:  0.38756403 Gen loss:  0.7154292\n",
      "Epoch:  560 Seg loss:  0.25564888546775494 Seg acc:  0.9098200619533527 Disc loss:  0.27828294 Gen loss:  0.7171177\n",
      "Epoch:  560 F1 (val):  0.7302153074613323 Acc (val):  0.7611632653061224\n",
      "Epoch:  561 Seg loss:  0.2555632644769555 Seg acc:  0.9098607624868129 Disc loss:  0.3047526 Gen loss:  0.61308587\n",
      "Epoch:  562 Seg loss:  0.255548528730339 Seg acc:  0.9098622812114169 Disc loss:  0.21982834 Gen loss:  0.8479914\n",
      "Epoch:  563 Seg loss:  0.2555125393436603 Seg acc:  0.9098814659078551 Disc loss:  0.33479238 Gen loss:  0.66713256\n",
      "Epoch:  564 Seg loss:  0.2556492921017797 Seg acc:  0.9098268562744247 Disc loss:  0.32099187 Gen loss:  0.9427831\n",
      "Epoch:  565 Seg loss:  0.2556759033187301 Seg acc:  0.9098148817048943 Disc loss:  0.28425962 Gen loss:  0.85392964\n",
      "Epoch:  566 Seg loss:  0.2556427654155362 Seg acc:  0.9098263863849427 Disc loss:  0.38771272 Gen loss:  0.7746643\n",
      "Epoch:  567 Seg loss:  0.2556143243135178 Seg acc:  0.9098729438865494 Disc loss:  0.28619665 Gen loss:  0.7796938\n",
      "Epoch:  568 Seg loss:  0.2555596106095423 Seg acc:  0.9098901444380568 Disc loss:  0.34656954 Gen loss:  0.7732627\n",
      "Epoch:  569 Seg loss:  0.25554063616349953 Seg acc:  0.9098880061690756 Disc loss:  0.29440045 Gen loss:  0.7506663\n",
      "Epoch:  570 Seg loss:  0.2555640023397772 Seg acc:  0.9098899033297528 Disc loss:  0.24874866 Gen loss:  0.7144606\n",
      "Epoch:  570 F1 (val):  0.732094579419714 Acc (val):  0.7604489795918368\n",
      "Epoch:  571 Seg loss:  0.25549295057922655 Seg acc:  0.9099110046820829 Disc loss:  0.31997228 Gen loss:  0.771793\n",
      "Epoch:  572 Seg loss:  0.2555550929627844 Seg acc:  0.9098927857856428 Disc loss:  0.37057477 Gen loss:  0.7567832\n",
      "Epoch:  573 Seg loss:  0.25557536280748105 Seg acc:  0.9098937742636319 Disc loss:  0.3418454 Gen loss:  0.7717507\n",
      "Epoch:  574 Seg loss:  0.25562238177927116 Seg acc:  0.90987076015075 Disc loss:  0.30336156 Gen loss:  0.82497644\n",
      "Epoch:  575 Seg loss:  0.25557046909695086 Seg acc:  0.9098930789707186 Disc loss:  0.28747505 Gen loss:  0.7705506\n",
      "Epoch:  576 Seg loss:  0.25546842770806205 Seg acc:  0.9099432220804987 Disc loss:  0.31193084 Gen loss:  0.76324\n",
      "Epoch:  577 Seg loss:  0.2553806526124787 Seg acc:  0.9099967283273795 Disc loss:  0.28048843 Gen loss:  0.81098753\n",
      "Epoch:  578 Seg loss:  0.2553442268919161 Seg acc:  0.9099970870701222 Disc loss:  0.37635636 Gen loss:  0.7419712\n",
      "Epoch:  579 Seg loss:  0.2552218853989825 Seg acc:  0.9100234394275846 Disc loss:  0.31260628 Gen loss:  0.69295883\n",
      "Epoch:  580 Seg loss:  0.2552380507233842 Seg acc:  0.9100149542575651 Disc loss:  0.32230374 Gen loss:  0.8624753\n",
      "Epoch:  580 F1 (val):  0.7326704272676817 Acc (val):  0.7653877551020408\n",
      "Epoch:  581 Seg loss:  0.25518301348626715 Seg acc:  0.9100578699638202 Disc loss:  0.31995824 Gen loss:  0.7896159\n",
      "Epoch:  582 Seg loss:  0.25506261061505764 Seg acc:  0.9101037064310262 Disc loss:  0.3454122 Gen loss:  0.7580961\n",
      "Epoch:  583 Seg loss:  0.2551761120685582 Seg acc:  0.9100850631847935 Disc loss:  0.22186467 Gen loss:  0.861729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  584 Seg loss:  0.2551533100259018 Seg acc:  0.9100918192619513 Disc loss:  0.3671937 Gen loss:  0.8512797\n",
      "Epoch:  585 Seg loss:  0.2550637194361442 Seg acc:  0.9101177394034536 Disc loss:  0.38951427 Gen loss:  0.73044485\n",
      "Epoch:  586 Seg loss:  0.2549423917543156 Seg acc:  0.9101662081214736 Disc loss:  0.28628212 Gen loss:  0.84273845\n",
      "Epoch:  587 Seg loss:  0.25480405820035446 Seg acc:  0.910232329729166 Disc loss:  0.32650536 Gen loss:  0.71220326\n",
      "Epoch:  588 Seg loss:  0.254925445723189 Seg acc:  0.910153755379703 Disc loss:  0.29161397 Gen loss:  0.97054005\n",
      "Epoch:  589 Seg loss:  0.2548822310131758 Seg acc:  0.9101798274488063 Disc loss:  0.23142049 Gen loss:  0.9163048\n",
      "Epoch:  590 Seg loss:  0.2547268817864232 Seg acc:  0.9102499135247318 Disc loss:  0.35759938 Gen loss:  0.7191134\n",
      "Epoch:  590 F1 (val):  0.735526135011649 Acc (val):  0.7703775510204082\n",
      "Epoch:  591 Seg loss:  0.254763561444335 Seg acc:  0.9102178942643048 Disc loss:  0.20065133 Gen loss:  0.82145774\n",
      "Epoch:  592 Seg loss:  0.2546440055467994 Seg acc:  0.9102725972145617 Disc loss:  0.2334207 Gen loss:  0.85196185\n",
      "Epoch:  593 Seg loss:  0.25449651357848163 Seg acc:  0.9103322779364696 Disc loss:  0.3600759 Gen loss:  0.69492525\n",
      "Epoch:  594 Seg loss:  0.2545019479888658 Seg acc:  0.9103427987356559 Disc loss:  0.2634653 Gen loss:  0.7379738\n",
      "Epoch:  595 Seg loss:  0.25444462155344105 Seg acc:  0.9103665752015092 Disc loss:  0.23660156 Gen loss:  0.70572704\n",
      "Epoch:  596 Seg loss:  0.2543371769680873 Seg acc:  0.9104018285166414 Disc loss:  0.25967795 Gen loss:  0.71323395\n",
      "Epoch:  597 Seg loss:  0.25441624105625615 Seg acc:  0.9103873961644959 Disc loss:  0.31614816 Gen loss:  0.8804114\n",
      "Epoch:  598 Seg loss:  0.2543850321958097 Seg acc:  0.9103926353149957 Disc loss:  0.21211532 Gen loss:  0.965567\n",
      "Epoch:  599 Seg loss:  0.254337873216563 Seg acc:  0.9104451296378319 Disc loss:  0.28436705 Gen loss:  0.8967534\n",
      "Epoch:  600 Seg loss:  0.2542613013709585 Seg acc:  0.9104638605442176 Disc loss:  0.20134512 Gen loss:  0.8653394\n",
      "Epoch:  600 F1 (val):  0.7219674446582715 Acc (val):  0.7611530612244898\n",
      "Epoch:  601 Seg loss:  0.25417456344489053 Seg acc:  0.9104905939081124 Disc loss:  0.23955572 Gen loss:  0.7083301\n",
      "Epoch:  602 Seg loss:  0.2542287893098256 Seg acc:  0.9104913892467287 Disc loss:  0.30508304 Gen loss:  0.8728024\n",
      "Epoch:  603 Seg loss:  0.25417889060319754 Seg acc:  0.9105184113446373 Disc loss:  0.19113135 Gen loss:  0.7837174\n",
      "Epoch:  604 Seg loss:  0.2540001917926484 Seg acc:  0.9105871570482497 Disc loss:  0.25959456 Gen loss:  0.88196063\n",
      "Epoch:  605 Seg loss:  0.2541145791569032 Seg acc:  0.9105304435823915 Disc loss:  0.31250733 Gen loss:  0.839038\n",
      "Epoch:  606 Seg loss:  0.25404252344281364 Seg acc:  0.9105303259917827 Disc loss:  0.18526249 Gen loss:  0.85540813\n",
      "Epoch:  607 Seg loss:  0.25403523507729003 Seg acc:  0.910529788521669 Disc loss:  0.3454487 Gen loss:  0.89661837\n",
      "Epoch:  608 Seg loss:  0.254041681446037 Seg acc:  0.9105401617883995 Disc loss:  0.18776546 Gen loss:  0.8918829\n",
      "Epoch:  609 Seg loss:  0.2539180248168302 Seg acc:  0.9105961596461244 Disc loss:  0.21999387 Gen loss:  0.85375875\n",
      "Epoch:  610 Seg loss:  0.2538974609164918 Seg acc:  0.9105925894948143 Disc loss:  0.25651067 Gen loss:  0.75840867\n",
      "Epoch:  610 F1 (val):  0.6987983453974664 Acc (val):  0.7544693877551021\n",
      "Epoch:  611 Seg loss:  0.25381062094445317 Seg acc:  0.9106195096696615 Disc loss:  0.22981116 Gen loss:  0.9023714\n",
      "Epoch:  612 Seg loss:  0.2536392236871073 Seg acc:  0.9106838568760836 Disc loss:  0.2582188 Gen loss:  0.74059653\n",
      "Epoch:  613 Seg loss:  0.25359564634316506 Seg acc:  0.9106976395778538 Disc loss:  0.2072266 Gen loss:  0.8938467\n",
      "Epoch:  614 Seg loss:  0.2534741199293238 Seg acc:  0.9107471082895697 Disc loss:  0.29563567 Gen loss:  0.61223084\n",
      "Epoch:  615 Seg loss:  0.2534651138070153 Seg acc:  0.9107462253193959 Disc loss:  0.21881971 Gen loss:  0.9397125\n",
      "Epoch:  616 Seg loss:  0.2533946606850663 Seg acc:  0.9107672939305591 Disc loss:  0.28770253 Gen loss:  0.84070385\n",
      "Epoch:  617 Seg loss:  0.2533198450986338 Seg acc:  0.9107986306353983 Disc loss:  0.3060999 Gen loss:  0.946278\n",
      "Epoch:  618 Seg loss:  0.25333432774858183 Seg acc:  0.91080138366026 Disc loss:  0.16082528 Gen loss:  0.9599316\n",
      "Epoch:  619 Seg loss:  0.2531868978275621 Seg acc:  0.910851933665227 Disc loss:  0.32713127 Gen loss:  0.8332221\n",
      "Epoch:  620 Seg loss:  0.2531274289493599 Seg acc:  0.9108772218564843 Disc loss:  0.23800853 Gen loss:  0.8754935\n",
      "Epoch:  620 F1 (val):  0.7298388409218213 Acc (val):  0.7495306122448979\n",
      "Epoch:  621 Seg loss:  0.2531598670207168 Seg acc:  0.9108506687699233 Disc loss:  0.27127606 Gen loss:  0.9547496\n",
      "Epoch:  622 Seg loss:  0.25301727119509815 Seg acc:  0.9108959741452851 Disc loss:  0.25002006 Gen loss:  0.8524852\n",
      "Epoch:  623 Seg loss:  0.253037486219387 Seg acc:  0.9109026435614372 Disc loss:  0.19098546 Gen loss:  0.91355246\n",
      "Epoch:  624 Seg loss:  0.25293804259779745 Seg acc:  0.9109419969911042 Disc loss:  0.2354623 Gen loss:  0.7729529\n",
      "Epoch:  625 Seg loss:  0.2529497193217278 Seg acc:  0.9109367346938776 Disc loss:  0.21201304 Gen loss:  0.84084857\n",
      "Epoch:  626 Seg loss:  0.25296316197076546 Seg acc:  0.9109355643215753 Disc loss:  0.27416587 Gen loss:  0.83637726\n",
      "Epoch:  627 Seg loss:  0.25290693362886635 Seg acc:  0.9109763043973571 Disc loss:  0.22317335 Gen loss:  0.8835385\n",
      "Epoch:  628 Seg loss:  0.25276991038043406 Seg acc:  0.9110388502534772 Disc loss:  0.20940161 Gen loss:  0.752704\n",
      "Epoch:  629 Seg loss:  0.25266110002757636 Seg acc:  0.9110699685279516 Disc loss:  0.2672594 Gen loss:  0.7611035\n",
      "Epoch:  630 Seg loss:  0.2526006254530142 Seg acc:  0.9110957240038874 Disc loss:  0.13293125 Gen loss:  1.067662\n",
      "Epoch:  630 F1 (val):  0.7318807973277053 Acc (val):  0.765030612244898\n",
      "Epoch:  631 Seg loss:  0.25254831583535803 Seg acc:  0.9111084608169733 Disc loss:  0.14966315 Gen loss:  0.9402286\n",
      "Epoch:  632 Seg loss:  0.2525083625547682 Seg acc:  0.9111276156032033 Disc loss:  0.11704708 Gen loss:  0.9906305\n",
      "Epoch:  633 Seg loss:  0.2524199713298118 Seg acc:  0.9111588000128961 Disc loss:  0.23126107 Gen loss:  0.82676053\n",
      "Epoch:  634 Seg loss:  0.25246073391394286 Seg acc:  0.9111343591064187 Disc loss:  0.23968436 Gen loss:  0.91151804\n",
      "Epoch:  635 Seg loss:  0.2524045035947026 Seg acc:  0.9111525791418931 Disc loss:  0.15033203 Gen loss:  0.96925706\n",
      "Epoch:  636 Seg loss:  0.25239593375169633 Seg acc:  0.911164725324092 Disc loss:  0.21355006 Gen loss:  0.94853187\n",
      "Epoch:  637 Seg loss:  0.25240835780204746 Seg acc:  0.9111624163009003 Disc loss:  0.2870043 Gen loss:  0.8346618\n",
      "Epoch:  638 Seg loss:  0.2523895009628097 Seg acc:  0.9111613140554028 Disc loss:  0.2608422 Gen loss:  0.97682166\n",
      "Epoch:  639 Seg loss:  0.25231439172522 Seg acc:  0.9111825716201973 Disc loss:  0.29515713 Gen loss:  0.8155826\n",
      "Epoch:  640 Seg loss:  0.25229565367335455 Seg acc:  0.9112053571428571 Disc loss:  0.26894253 Gen loss:  0.9426658\n",
      "Epoch:  640 F1 (val):  0.7159733771354293 Acc (val):  0.762765306122449\n",
      "Epoch:  641 Seg loss:  0.25228080975237577 Seg acc:  0.9112173262440701 Disc loss:  0.19891714 Gen loss:  0.99842256\n",
      "Epoch:  642 Seg loss:  0.2523785138682599 Seg acc:  0.9111827674995232 Disc loss:  0.26151782 Gen loss:  0.9890437\n",
      "Epoch:  643 Seg loss:  0.25227880240367323 Seg acc:  0.9112280604310153 Disc loss:  0.23730189 Gen loss:  0.8439375\n",
      "Epoch:  644 Seg loss:  0.25224154924985415 Seg acc:  0.911238354037267 Disc loss:  0.15120736 Gen loss:  1.0566187\n",
      "Epoch:  645 Seg loss:  0.2522336472721063 Seg acc:  0.9112434741338397 Disc loss:  0.1387513 Gen loss:  1.0320363\n",
      "Epoch:  646 Seg loss:  0.25220360721089524 Seg acc:  0.9112517375371201 Disc loss:  0.21857578 Gen loss:  0.933874\n",
      "Epoch:  647 Seg loss:  0.2521273858234908 Seg acc:  0.9112769296281109 Disc loss:  0.15082324 Gen loss:  0.9510075\n",
      "Epoch:  648 Seg loss:  0.2520571803950049 Seg acc:  0.9112977135298563 Disc loss:  0.17717877 Gen loss:  0.88891566\n",
      "Epoch:  649 Seg loss:  0.2519842094766157 Seg acc:  0.9113247224930033 Disc loss:  0.14757812 Gen loss:  0.885101\n",
      "Epoch:  650 Seg loss:  0.2518527692900254 Seg acc:  0.9113854003139719 Disc loss:  0.22652382 Gen loss:  0.86020637\n",
      "Epoch:  650 F1 (val):  0.7030240494265778 Acc (val):  0.7502448979591837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  651 Seg loss:  0.2518704956463222 Seg acc:  0.9113628170162075 Disc loss:  0.20087186 Gen loss:  0.9463082\n",
      "Epoch:  652 Seg loss:  0.2518050292952478 Seg acc:  0.911409164892951 Disc loss:  0.1410816 Gen loss:  0.8884348\n",
      "Epoch:  653 Seg loss:  0.251717548925789 Seg acc:  0.911435447073163 Disc loss:  0.16067113 Gen loss:  1.0222408\n",
      "Epoch:  654 Seg loss:  0.2515759242852347 Seg acc:  0.9114838825438433 Disc loss:  0.2715004 Gen loss:  0.8502557\n",
      "Epoch:  655 Seg loss:  0.2514385959460535 Seg acc:  0.9115352858700732 Disc loss:  0.22580263 Gen loss:  0.8407305\n",
      "Epoch:  656 Seg loss:  0.2513848116235217 Seg acc:  0.9115387008461922 Disc loss:  0.1744969 Gen loss:  0.88832784\n",
      "Epoch:  657 Seg loss:  0.2512611172628366 Seg acc:  0.9115844282918647 Disc loss:  0.24210271 Gen loss:  0.93949443\n",
      "Epoch:  658 Seg loss:  0.25118257742839384 Seg acc:  0.9116183859562064 Disc loss:  0.17418055 Gen loss:  0.9006351\n",
      "Epoch:  659 Seg loss:  0.2510734891832689 Seg acc:  0.9116634666006008 Disc loss:  0.16188866 Gen loss:  1.1234604\n",
      "Epoch:  660 Seg loss:  0.25109922230017906 Seg acc:  0.91164695423624 Disc loss:  0.21121539 Gen loss:  0.9641586\n",
      "Epoch:  660 F1 (val):  0.7313774007089826 Acc (val):  0.7661632653061224\n",
      "Epoch:  661 Seg loss:  0.2512202251494021 Seg acc:  0.9115930562845411 Disc loss:  0.14523648 Gen loss:  1.034932\n",
      "Epoch:  662 Seg loss:  0.251086017077513 Seg acc:  0.9116476046612 Disc loss:  0.2143663 Gen loss:  0.8223531\n",
      "Epoch:  663 Seg loss:  0.25115560434567624 Seg acc:  0.9116181087819744 Disc loss:  0.15940332 Gen loss:  1.1508188\n",
      "Epoch:  664 Seg loss:  0.2511113851656576 Seg acc:  0.9116501721170396 Disc loss:  0.22758195 Gen loss:  0.894135\n",
      "Epoch:  665 Seg loss:  0.25122025453282476 Seg acc:  0.9116084854994629 Disc loss:  0.13420294 Gen loss:  1.0637804\n",
      "Epoch:  666 Seg loss:  0.2510727408702846 Seg acc:  0.9116592357663788 Disc loss:  0.2893448 Gen loss:  0.84223324\n",
      "Epoch:  667 Seg loss:  0.2510812288929319 Seg acc:  0.9116482575039011 Disc loss:  0.10768896 Gen loss:  0.9572498\n",
      "Epoch:  668 Seg loss:  0.2509541110788098 Seg acc:  0.9116892490529146 Disc loss:  0.125278 Gen loss:  0.9661086\n",
      "Epoch:  669 Seg loss:  0.25093696930171483 Seg acc:  0.9116919862115249 Disc loss:  0.2368114 Gen loss:  0.8444644\n",
      "Epoch:  670 Seg loss:  0.2509417455254206 Seg acc:  0.9116848157173318 Disc loss:  0.21659496 Gen loss:  1.0228448\n",
      "Epoch:  670 F1 (val):  0.7380215133995169 Acc (val):  0.7635102040816326\n",
      "Epoch:  671 Seg loss:  0.250940604432418 Seg acc:  0.9116924936889808 Disc loss:  0.10115957 Gen loss:  1.038486\n",
      "Epoch:  672 Seg loss:  0.25084822226892267 Seg acc:  0.9117358327259475 Disc loss:  0.21991841 Gen loss:  0.8427943\n",
      "Epoch:  673 Seg loss:  0.25071005796651075 Seg acc:  0.9117991327288717 Disc loss:  0.17924279 Gen loss:  0.91450286\n",
      "Epoch:  674 Seg loss:  0.25065070592994504 Seg acc:  0.9118032005086901 Disc loss:  0.21476355 Gen loss:  0.87343425\n",
      "Epoch:  675 Seg loss:  0.250615798400508 Seg acc:  0.9118102796674226 Disc loss:  0.23475586 Gen loss:  0.9742013\n",
      "Epoch:  676 Seg loss:  0.2504827534151677 Seg acc:  0.9118641317473735 Disc loss:  0.15227333 Gen loss:  0.9445327\n",
      "Epoch:  677 Seg loss:  0.2503853910980936 Seg acc:  0.9119065203629457 Disc loss:  0.11490096 Gen loss:  1.0328345\n",
      "Epoch:  678 Seg loss:  0.2502776254353094 Seg acc:  0.9119408825477094 Disc loss:  0.08978886 Gen loss:  0.95430696\n",
      "Epoch:  679 Seg loss:  0.25021235292588134 Seg acc:  0.9119649995491569 Disc loss:  0.20279878 Gen loss:  1.0356517\n",
      "Epoch:  680 Seg loss:  0.2501635062891771 Seg acc:  0.9119714135654262 Disc loss:  0.1976906 Gen loss:  0.9047724\n",
      "Epoch:  680 F1 (val):  0.6927084379500577 Acc (val):  0.7324183673469388\n",
      "Epoch:  681 Seg loss:  0.2501597008319153 Seg acc:  0.9119972879019449 Disc loss:  0.12725621 Gen loss:  1.1716183\n",
      "Epoch:  682 Seg loss:  0.2501296486563522 Seg acc:  0.9120047579148961 Disc loss:  0.15608853 Gen loss:  1.0316495\n",
      "Epoch:  683 Seg loss:  0.2503534855967385 Seg acc:  0.9119345175844861 Disc loss:  0.11622204 Gen loss:  1.0575855\n",
      "Epoch:  684 Seg loss:  0.25029460344006094 Seg acc:  0.9119398197875642 Disc loss:  0.108940125 Gen loss:  1.0160993\n",
      "Epoch:  685 Seg loss:  0.25029158330094203 Seg acc:  0.9119391479219425 Disc loss:  0.20658576 Gen loss:  0.8242495\n",
      "Epoch:  686 Seg loss:  0.2502464064377911 Seg acc:  0.9119578151960492 Disc loss:  0.1984246 Gen loss:  0.99419975\n",
      "Epoch:  687 Seg loss:  0.25022545301801424 Seg acc:  0.9119727148501321 Disc loss:  0.16323668 Gen loss:  0.9162579\n",
      "Epoch:  688 Seg loss:  0.25012874968219984 Seg acc:  0.9120101892501187 Disc loss:  0.17873102 Gen loss:  0.9236586\n",
      "Epoch:  689 Seg loss:  0.25018811949321945 Seg acc:  0.9119905364177602 Disc loss:  0.12870486 Gen loss:  1.0722508\n",
      "Epoch:  690 Seg loss:  0.25006937353291375 Seg acc:  0.9120474711623782 Disc loss:  0.102768034 Gen loss:  1.0446973\n",
      "Epoch:  690 F1 (val):  0.7297436240217535 Acc (val):  0.7663367346938775\n",
      "Epoch:  691 Seg loss:  0.25005923937224445 Seg acc:  0.9120503411205293 Disc loss:  0.1701901 Gen loss:  0.9156799\n",
      "Epoch:  692 Seg loss:  0.2500977016490147 Seg acc:  0.9120410375132711 Disc loss:  0.10305701 Gen loss:  1.1062782\n",
      "Epoch:  693 Seg loss:  0.2500190002599148 Seg acc:  0.9120704125806167 Disc loss:  0.1409401 Gen loss:  1.0026093\n",
      "Epoch:  694 Seg loss:  0.2500390351698962 Seg acc:  0.9120695612538964 Disc loss:  0.20378041 Gen loss:  1.0059004\n",
      "Epoch:  695 Seg loss:  0.24984848155177755 Seg acc:  0.9121450594626341 Disc loss:  0.18373746 Gen loss:  0.84501696\n",
      "Epoch:  696 Seg loss:  0.24984116731318592 Seg acc:  0.9121367728125733 Disc loss:  0.12785763 Gen loss:  1.1162369\n",
      "Epoch:  697 Seg loss:  0.24974647024312355 Seg acc:  0.912176455948233 Disc loss:  0.08429919 Gen loss:  1.0271951\n",
      "Epoch:  698 Seg loss:  0.24971163184261938 Seg acc:  0.9121838635167535 Disc loss:  0.16385926 Gen loss:  0.9235543\n",
      "Epoch:  699 Seg loss:  0.24961480814883638 Seg acc:  0.9122244605996905 Disc loss:  0.15988931 Gen loss:  1.0432706\n",
      "Epoch:  700 Seg loss:  0.2495486383246524 Seg acc:  0.9122481778425656 Disc loss:  0.17665353 Gen loss:  0.95445657\n",
      "Epoch:  700 F1 (val):  0.7065541422628348 Acc (val):  0.751061224489796\n",
      "Epoch:  701 Seg loss:  0.24949592816379032 Seg acc:  0.9122703717721041 Disc loss:  0.14552087 Gen loss:  0.986708\n",
      "Epoch:  702 Seg loss:  0.24941908170142743 Seg acc:  0.9122808738880168 Disc loss:  0.1302673 Gen loss:  0.93825364\n",
      "Epoch:  703 Seg loss:  0.24930618596322845 Seg acc:  0.9123374314163788 Disc loss:  0.1555107 Gen loss:  0.9542693\n",
      "Epoch:  704 Seg loss:  0.24918687308672816 Seg acc:  0.9123829574443415 Disc loss:  0.08850123 Gen loss:  0.96397245\n",
      "Epoch:  705 Seg loss:  0.2491111731381281 Seg acc:  0.9124410189607758 Disc loss:  0.10736298 Gen loss:  1.1193893\n",
      "Epoch:  706 Seg loss:  0.24910989295026398 Seg acc:  0.91243748915997 Disc loss:  0.10291809 Gen loss:  0.9819629\n",
      "Epoch:  707 Seg loss:  0.24905741839673598 Seg acc:  0.9124552579164622 Disc loss:  0.15350884 Gen loss:  0.8606467\n",
      "Epoch:  708 Seg loss:  0.2489545812230494 Seg acc:  0.912499639686383 Disc loss:  0.20508434 Gen loss:  0.8705957\n",
      "Epoch:  709 Seg loss:  0.24891300784221657 Seg acc:  0.9125071961083445 Disc loss:  0.23001733 Gen loss:  0.9331193\n",
      "Epoch:  710 Seg loss:  0.24885108388015922 Seg acc:  0.9125258695027305 Disc loss:  0.1300014 Gen loss:  0.9753032\n",
      "Epoch:  710 F1 (val):  0.7148391313746637 Acc (val):  0.751\n",
      "Epoch:  711 Seg loss:  0.24887976118490499 Seg acc:  0.9125208100117684 Disc loss:  0.1055609 Gen loss:  1.0418649\n",
      "Epoch:  712 Seg loss:  0.2489637363429987 Seg acc:  0.9124638127722999 Disc loss:  0.1292847 Gen loss:  1.1074505\n",
      "Epoch:  713 Seg loss:  0.24891722654769666 Seg acc:  0.9124785327875891 Disc loss:  0.0787887 Gen loss:  1.1504862\n",
      "Epoch:  714 Seg loss:  0.24887560859990387 Seg acc:  0.9125010718573144 Disc loss:  0.1466632 Gen loss:  0.94100153\n",
      "Epoch:  715 Seg loss:  0.24874327888230344 Seg acc:  0.9125435279006708 Disc loss:  0.14360246 Gen loss:  0.9695896\n",
      "Epoch:  716 Seg loss:  0.24859335168405286 Seg acc:  0.9125940599703568 Disc loss:  0.17170565 Gen loss:  0.96416533\n",
      "Epoch:  717 Seg loss:  0.2484282295594987 Seg acc:  0.9126433837133181 Disc loss:  0.13253587 Gen loss:  1.0341548\n",
      "Epoch:  718 Seg loss:  0.2483222801186414 Seg acc:  0.9126755158888068 Disc loss:  0.14661881 Gen loss:  0.8741654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  719 Seg loss:  0.248258654292419 Seg acc:  0.9126923022338281 Disc loss:  0.1609464 Gen loss:  0.89024305\n",
      "Epoch:  720 Seg loss:  0.24819259679772787 Seg acc:  0.9127178996598642 Disc loss:  0.10735384 Gen loss:  0.90690655\n",
      "Epoch:  720 F1 (val):  0.7396404923909863 Acc (val):  0.7768979591836734\n",
      "Epoch:  721 Seg loss:  0.24809343975435183 Seg acc:  0.9127575787596591 Disc loss:  0.21549425 Gen loss:  0.90550745\n",
      "Epoch:  722 Seg loss:  0.248022621884488 Seg acc:  0.9128028011758722 Disc loss:  0.15870918 Gen loss:  1.0615872\n",
      "Epoch:  723 Seg loss:  0.2480570352732888 Seg acc:  0.9127748609817371 Disc loss:  0.16790336 Gen loss:  1.055477\n",
      "Epoch:  724 Seg loss:  0.2480459444698214 Seg acc:  0.9127695484271056 Disc loss:  0.0949565 Gen loss:  1.0787317\n",
      "Epoch:  725 Seg loss:  0.24805880535265495 Seg acc:  0.9128004926108375 Disc loss:  0.11782646 Gen loss:  1.0582014\n",
      "Epoch:  726 Seg loss:  0.24808993308545801 Seg acc:  0.9127853207398663 Disc loss:  0.1238801 Gen loss:  1.0768923\n",
      "Epoch:  727 Seg loss:  0.24797589143294907 Seg acc:  0.9128270359037701 Disc loss:  0.07978654 Gen loss:  1.0652355\n",
      "Epoch:  728 Seg loss:  0.24806787043932702 Seg acc:  0.9128234329446065 Disc loss:  0.18635532 Gen loss:  1.2801632\n",
      "Epoch:  729 Seg loss:  0.24802775330463392 Seg acc:  0.9128348870412363 Disc loss:  0.096563384 Gen loss:  1.1282506\n",
      "Epoch:  730 Seg loss:  0.24796393022757687 Seg acc:  0.91283862175007 Disc loss:  0.11520378 Gen loss:  1.011428\n",
      "Epoch:  730 F1 (val):  0.7288250196286024 Acc (val):  0.7511836734693877\n",
      "Epoch:  731 Seg loss:  0.24796801979784763 Seg acc:  0.9128245484240207 Disc loss:  0.14792761 Gen loss:  1.0612228\n",
      "Epoch:  732 Seg loss:  0.2480517213278618 Seg acc:  0.9127794970447195 Disc loss:  0.060144734 Gen loss:  1.1455172\n",
      "Epoch:  733 Seg loss:  0.24797168610894502 Seg acc:  0.9128069577080492 Disc loss:  0.12800673 Gen loss:  0.9374865\n",
      "Epoch:  734 Seg loss:  0.2479254367383202 Seg acc:  0.9128214841795028 Disc loss:  0.11557615 Gen loss:  0.9549759\n",
      "Epoch:  735 Seg loss:  0.24783638664046112 Seg acc:  0.9128592253227821 Disc loss:  0.10157467 Gen loss:  1.0259776\n",
      "Epoch:  736 Seg loss:  0.24777753589391385 Seg acc:  0.9128836928793256 Disc loss:  0.12035985 Gen loss:  1.0084606\n",
      "Epoch:  737 Seg loss:  0.24767819359352664 Seg acc:  0.9129132860742668 Disc loss:  0.08589943 Gen loss:  1.043488\n",
      "Epoch:  738 Seg loss:  0.2476973722317839 Seg acc:  0.9128836900613904 Disc loss:  0.11294147 Gen loss:  1.0285357\n",
      "Epoch:  739 Seg loss:  0.24764235540518742 Seg acc:  0.912888348844274 Disc loss:  0.19981313 Gen loss:  0.9182367\n",
      "Epoch:  740 Seg loss:  0.2475168039569178 Seg acc:  0.9129464285714285 Disc loss:  0.14934689 Gen loss:  0.82394886\n",
      "Epoch:  740 F1 (val):  0.7291564356156364 Acc (val):  0.7646428571428572\n",
      "Epoch:  741 Seg loss:  0.24747249328213342 Seg acc:  0.9129595967941833 Disc loss:  0.18232176 Gen loss:  0.9236555\n",
      "Epoch:  742 Seg loss:  0.24741930589883154 Seg acc:  0.9129751361461026 Disc loss:  0.08155262 Gen loss:  1.1047873\n",
      "Epoch:  743 Seg loss:  0.24727575481940728 Seg acc:  0.9130356112835444 Disc loss:  0.067225605 Gen loss:  1.0520508\n",
      "Epoch:  744 Seg loss:  0.24719903276612362 Seg acc:  0.9130698650427913 Disc loss:  0.1451277 Gen loss:  1.1731944\n",
      "Epoch:  745 Seg loss:  0.24716431017490043 Seg acc:  0.913063621421723 Disc loss:  0.14902458 Gen loss:  1.1016525\n",
      "Epoch:  746 Seg loss:  0.24709557287454925 Seg acc:  0.9130991136400941 Disc loss:  0.16790111 Gen loss:  1.0980775\n",
      "Epoch:  747 Seg loss:  0.24694074701313354 Seg acc:  0.9131495369232031 Disc loss:  0.07745859 Gen loss:  1.0853952\n",
      "Epoch:  748 Seg loss:  0.24690645573571085 Seg acc:  0.9131544663319873 Disc loss:  0.15929714 Gen loss:  1.0719545\n",
      "Epoch:  749 Seg loss:  0.24678787679594255 Seg acc:  0.9132057028418844 Disc loss:  0.14772911 Gen loss:  0.88693684\n",
      "Epoch:  750 Seg loss:  0.24686517770091693 Seg acc:  0.9131795918367346 Disc loss:  0.082160175 Gen loss:  1.1243414\n",
      "Epoch:  750 F1 (val):  0.7265682294253821 Acc (val):  0.7679897959183674\n",
      "Epoch:  751 Seg loss:  0.2467883747820054 Seg acc:  0.9132085790374739 Disc loss:  0.1793414 Gen loss:  0.86717916\n",
      "Epoch:  752 Seg loss:  0.24673109789913955 Seg acc:  0.9132371499131567 Disc loss:  0.12257485 Gen loss:  1.0703933\n",
      "Epoch:  753 Seg loss:  0.24665325002405905 Seg acc:  0.9132537875708052 Disc loss:  0.12341564 Gen loss:  1.0561672\n",
      "Epoch:  754 Seg loss:  0.24657602603263185 Seg acc:  0.9132852676879769 Disc loss:  0.17018767 Gen loss:  0.9452594\n",
      "Epoch:  755 Seg loss:  0.2464678276157537 Seg acc:  0.91331666441411 Disc loss:  0.09078189 Gen loss:  0.98389435\n",
      "Epoch:  756 Seg loss:  0.24648856116389786 Seg acc:  0.9132936507936507 Disc loss:  0.08360196 Gen loss:  1.0574615\n",
      "Epoch:  757 Seg loss:  0.2464318541487583 Seg acc:  0.9133222575688134 Disc loss:  0.12601021 Gen loss:  1.1723254\n",
      "Epoch:  758 Seg loss:  0.2464565336999132 Seg acc:  0.9133194900651552 Disc loss:  0.060400654 Gen loss:  1.2564026\n",
      "Epoch:  759 Seg loss:  0.24634859161218323 Seg acc:  0.9133654647629803 Disc loss:  0.06780876 Gen loss:  1.1140852\n",
      "Epoch:  760 Seg loss:  0.2463871881267742 Seg acc:  0.9133475429645542 Disc loss:  0.111922294 Gen loss:  1.0980271\n",
      "Epoch:  760 F1 (val):  0.7239482728908267 Acc (val):  0.7675102040816326\n",
      "Epoch:  761 Seg loss:  0.24634942707070853 Seg acc:  0.9133538040709056 Disc loss:  0.14789337 Gen loss:  1.136427\n",
      "Epoch:  762 Seg loss:  0.24629149154767277 Seg acc:  0.9133633965397182 Disc loss:  0.049038183 Gen loss:  1.1006701\n",
      "Epoch:  763 Seg loss:  0.24619811737170225 Seg acc:  0.9133926899724503 Disc loss:  0.14527282 Gen loss:  0.9115107\n",
      "Epoch:  764 Seg loss:  0.2463144557306748 Seg acc:  0.913351119243509 Disc loss:  0.07203116 Gen loss:  1.2065513\n",
      "Epoch:  765 Seg loss:  0.24623087629968043 Seg acc:  0.913391356542617 Disc loss:  0.12449493 Gen loss:  0.9507365\n",
      "Epoch:  766 Seg loss:  0.24624312741988322 Seg acc:  0.9133898598603932 Disc loss:  0.14300129 Gen loss:  1.1538618\n",
      "Epoch:  767 Seg loss:  0.24618155454835494 Seg acc:  0.9134202964106112 Disc loss:  0.09265861 Gen loss:  1.0296158\n",
      "Epoch:  768 Seg loss:  0.24613023334920095 Seg acc:  0.9134184337797618 Disc loss:  0.07785541 Gen loss:  1.11096\n",
      "Epoch:  769 Seg loss:  0.24610743464318302 Seg acc:  0.9134248692975239 Disc loss:  0.10854349 Gen loss:  0.95984185\n",
      "Epoch:  770 Seg loss:  0.2459824799039921 Seg acc:  0.9134799893983568 Disc loss:  0.06485981 Gen loss:  1.0148906\n",
      "Epoch:  770 F1 (val):  0.7161195024997349 Acc (val):  0.7566836734693878\n",
      "Epoch:  771 Seg loss:  0.24591004605925657 Seg acc:  0.9135114746287619 Disc loss:  0.120564446 Gen loss:  1.1123629\n",
      "Epoch:  772 Seg loss:  0.2459034997236389 Seg acc:  0.9135104948715237 Disc loss:  0.07922749 Gen loss:  1.0382757\n",
      "Epoch:  773 Seg loss:  0.24583169853587045 Seg acc:  0.9135266784592233 Disc loss:  0.08093199 Gen loss:  0.97544014\n",
      "Epoch:  774 Seg loss:  0.24571606673743066 Seg acc:  0.9135649027052682 Disc loss:  0.15377057 Gen loss:  0.93964887\n",
      "Epoch:  775 Seg loss:  0.24576159849282234 Seg acc:  0.9135497037524686 Disc loss:  0.15515387 Gen loss:  1.0569832\n",
      "Epoch:  776 Seg loss:  0.2458113875796961 Seg acc:  0.9135565695350304 Disc loss:  0.06183161 Gen loss:  1.1968496\n",
      "Epoch:  777 Seg loss:  0.24573137026227426 Seg acc:  0.9135827883276862 Disc loss:  0.09549664 Gen loss:  1.1141502\n",
      "Epoch:  778 Seg loss:  0.24567680102042797 Seg acc:  0.9135984470909185 Disc loss:  0.12517148 Gen loss:  1.1855309\n",
      "Epoch:  779 Seg loss:  0.24559618929575588 Seg acc:  0.9136268371276624 Disc loss:  0.08524831 Gen loss:  0.93307614\n",
      "Epoch:  780 Seg loss:  0.24556829462257715 Seg acc:  0.9136338958660388 Disc loss:  0.0667512 Gen loss:  1.1935973\n",
      "Epoch:  780 F1 (val):  0.7283660430476433 Acc (val):  0.7601734693877551\n",
      "Epoch:  781 Seg loss:  0.24553220612253332 Seg acc:  0.9136507355823251 Disc loss:  0.19842985 Gen loss:  1.0012227\n",
      "Epoch:  782 Seg loss:  0.24545184579080023 Seg acc:  0.9136717730570489 Disc loss:  0.1089955 Gen loss:  1.0727875\n",
      "Epoch:  783 Seg loss:  0.24534476065049532 Seg acc:  0.9137136080485834 Disc loss:  0.088057876 Gen loss:  0.965198\n",
      "Epoch:  784 Seg loss:  0.24530710894804525 Seg acc:  0.9137306070387339 Disc loss:  0.07777324 Gen loss:  1.0560831\n",
      "Epoch:  785 Seg loss:  0.2453299960418112 Seg acc:  0.91373456388925 Disc loss:  0.13174537 Gen loss:  1.114151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  786 Seg loss:  0.24524901552320133 Seg acc:  0.913760905125409 Disc loss:  0.050035175 Gen loss:  1.0768372\n",
      "Epoch:  787 Seg loss:  0.24512393447881733 Seg acc:  0.9138066281150325 Disc loss:  0.103351764 Gen loss:  0.91257215\n",
      "Epoch:  788 Seg loss:  0.24505674752978807 Seg acc:  0.9138256889050036 Disc loss:  0.1159828 Gen loss:  1.0224129\n",
      "Epoch:  789 Seg loss:  0.24497988836129203 Seg acc:  0.9138463179948786 Disc loss:  0.050023906 Gen loss:  1.1566724\n",
      "Epoch:  790 Seg loss:  0.2448666295201718 Seg acc:  0.9138791655902867 Disc loss:  0.171426 Gen loss:  0.8979317\n",
      "Epoch:  790 F1 (val):  0.731971812998437 Acc (val):  0.7585204081632653\n",
      "Epoch:  791 Seg loss:  0.24489343561015448 Seg acc:  0.9138738744549653 Disc loss:  0.11969288 Gen loss:  1.058008\n",
      "Epoch:  792 Seg loss:  0.2447597205055633 Seg acc:  0.9139169114615542 Disc loss:  0.09495248 Gen loss:  0.92432415\n",
      "Epoch:  793 Seg loss:  0.24481944081198523 Seg acc:  0.9138810252978872 Disc loss:  0.038450245 Gen loss:  1.2951424\n",
      "Epoch:  794 Seg loss:  0.24474653953531528 Seg acc:  0.9139120572662315 Disc loss:  0.06933695 Gen loss:  1.1050503\n",
      "Epoch:  795 Seg loss:  0.24464808802747126 Seg acc:  0.913934026440765 Disc loss:  0.048328906 Gen loss:  1.0497415\n",
      "Epoch:  796 Seg loss:  0.24458882490631623 Seg acc:  0.9139536970567121 Disc loss:  0.15490389 Gen loss:  1.0316446\n",
      "Epoch:  797 Seg loss:  0.24452260608692541 Seg acc:  0.9139771592451283 Disc loss:  0.11379872 Gen loss:  1.0640736\n",
      "Epoch:  798 Seg loss:  0.24446114312325204 Seg acc:  0.9140037593984962 Disc loss:  0.06944956 Gen loss:  1.1622335\n",
      "Epoch:  799 Seg loss:  0.24440987425878438 Seg acc:  0.9140120941993818 Disc loss:  0.076282315 Gen loss:  1.1492127\n",
      "Epoch:  800 Seg loss:  0.24434704552404582 Seg acc:  0.914029974489796 Disc loss:  0.072386384 Gen loss:  1.0893285\n",
      "Epoch:  800 F1 (val):  0.724459398584299 Acc (val):  0.7609387755102041\n",
      "Epoch:  801 Seg loss:  0.24429054060641597 Seg acc:  0.914050039491452 Disc loss:  0.11009663 Gen loss:  1.1616554\n",
      "Epoch:  802 Seg loss:  0.244193721989964 Seg acc:  0.9140856404906101 Disc loss:  0.09577469 Gen loss:  0.9818985\n",
      "Epoch:  803 Seg loss:  0.24411874331283392 Seg acc:  0.9141020916461229 Disc loss:  0.1115049 Gen loss:  1.0565768\n",
      "Epoch:  804 Seg loss:  0.24399688920534368 Seg acc:  0.9141426160016244 Disc loss:  0.105775364 Gen loss:  0.9619748\n",
      "Epoch:  805 Seg loss:  0.2438918027911127 Seg acc:  0.9141767017365952 Disc loss:  0.1309004 Gen loss:  0.89878464\n",
      "Epoch:  806 Seg loss:  0.24385566036066703 Seg acc:  0.9141800020256241 Disc loss:  0.06585141 Gen loss:  1.0653782\n",
      "Epoch:  807 Seg loss:  0.24388686054221168 Seg acc:  0.914147889639127 Disc loss:  0.054164514 Gen loss:  1.1815888\n",
      "Epoch:  808 Seg loss:  0.24377021319832248 Seg acc:  0.9141976283087491 Disc loss:  0.1033851 Gen loss:  0.96909964\n",
      "Epoch:  809 Seg loss:  0.24374850642290635 Seg acc:  0.9141971065311166 Disc loss:  0.06626667 Gen loss:  1.0562727\n",
      "Epoch:  810 Seg loss:  0.2437219718448174 Seg acc:  0.9142088687326783 Disc loss:  0.034239504 Gen loss:  1.1159694\n",
      "Epoch:  810 F1 (val):  0.7359686929212437 Acc (val):  0.7617142857142857\n",
      "Epoch:  811 Seg loss:  0.24360724623084215 Seg acc:  0.9142489116485064 Disc loss:  0.12570196 Gen loss:  0.9597782\n",
      "Epoch:  812 Seg loss:  0.24348133111491874 Seg acc:  0.9142948250728863 Disc loss:  0.04090682 Gen loss:  0.9959191\n",
      "Epoch:  813 Seg loss:  0.24345483691380032 Seg acc:  0.9143039134472977 Disc loss:  0.0729729 Gen loss:  1.1639764\n",
      "Epoch:  814 Seg loss:  0.24339822642230577 Seg acc:  0.9143273955773955 Disc loss:  0.06794679 Gen loss:  1.1177437\n",
      "Epoch:  815 Seg loss:  0.24339804646610483 Seg acc:  0.9143373607111556 Disc loss:  0.12223197 Gen loss:  1.218219\n",
      "Epoch:  816 Seg loss:  0.24342857623545855 Seg acc:  0.9143219787915167 Disc loss:  0.066940516 Gen loss:  1.2217075\n",
      "Epoch:  817 Seg loss:  0.24334577281333533 Seg acc:  0.9143615891889192 Disc loss:  0.05635353 Gen loss:  1.1482928\n",
      "Epoch:  818 Seg loss:  0.24324303159540323 Seg acc:  0.9144054687889824 Disc loss:  0.075285815 Gen loss:  1.0201191\n",
      "Epoch:  819 Seg loss:  0.2431770346885927 Seg acc:  0.9144224539632703 Disc loss:  0.12142055 Gen loss:  1.0740635\n",
      "Epoch:  820 Seg loss:  0.24323044429283316 Seg acc:  0.9143899328023892 Disc loss:  0.061594546 Gen loss:  1.1516641\n",
      "Epoch:  820 F1 (val):  0.7319863875166095 Acc (val):  0.7632857142857142\n",
      "Epoch:  821 Seg loss:  0.24313285065662846 Seg acc:  0.9144233637425737 Disc loss:  0.086602025 Gen loss:  1.0624964\n",
      "Epoch:  822 Seg loss:  0.24309869927247654 Seg acc:  0.9144402651571576 Disc loss:  0.092533685 Gen loss:  1.061259\n",
      "Epoch:  823 Seg loss:  0.24307016811966173 Seg acc:  0.9144747935626255 Disc loss:  0.057514302 Gen loss:  1.0083153\n",
      "Epoch:  824 Seg loss:  0.24315243958522684 Seg acc:  0.9144494873191995 Disc loss:  0.104766615 Gen loss:  1.2078571\n",
      "Epoch:  825 Seg loss:  0.24314965082840487 Seg acc:  0.9144461966604823 Disc loss:  0.11422321 Gen loss:  1.0219952\n",
      "Epoch:  826 Seg loss:  0.24305149349079583 Seg acc:  0.9144867692839846 Disc loss:  0.07532537 Gen loss:  0.9793499\n",
      "Epoch:  827 Seg loss:  0.24304382417445602 Seg acc:  0.9144967055746118 Disc loss:  0.05151535 Gen loss:  1.166662\n",
      "Epoch:  828 Seg loss:  0.24300532650364481 Seg acc:  0.9145109311840677 Disc loss:  0.048655476 Gen loss:  1.1533009\n",
      "Epoch:  829 Seg loss:  0.2429832605368697 Seg acc:  0.9145186602988601 Disc loss:  0.14979343 Gen loss:  1.0119743\n",
      "Epoch:  830 Seg loss:  0.24290142929159014 Seg acc:  0.9145497295303663 Disc loss:  0.07204594 Gen loss:  1.0177507\n",
      "Epoch:  830 F1 (val):  0.7276671823426242 Acc (val):  0.7622448979591837\n",
      "Epoch:  831 Seg loss:  0.24287175227552832 Seg acc:  0.9145491048404921 Disc loss:  0.09023924 Gen loss:  1.1741056\n",
      "Epoch:  832 Seg loss:  0.24280775267666635 Seg acc:  0.9145714776295134 Disc loss:  0.062873535 Gen loss:  1.0631821\n",
      "Epoch:  833 Seg loss:  0.24267991963161284 Seg acc:  0.9146143151138006 Disc loss:  0.039955806 Gen loss:  1.0580823\n",
      "Epoch:  834 Seg loss:  0.24257697383884333 Seg acc:  0.9146533793373465 Disc loss:  0.04846628 Gen loss:  1.1082796\n",
      "Epoch:  835 Seg loss:  0.24254008844762506 Seg acc:  0.9146526335084931 Disc loss:  0.0814441 Gen loss:  1.0973345\n",
      "Epoch:  836 Seg loss:  0.2424796867188797 Seg acc:  0.9146744702665756 Disc loss:  0.0784886 Gen loss:  0.9596708\n",
      "Epoch:  837 Seg loss:  0.24240649082078158 Seg acc:  0.9146919879062736 Disc loss:  0.07336434 Gen loss:  1.0301429\n",
      "Epoch:  838 Seg loss:  0.24236383898125913 Seg acc:  0.9147036798012761 Disc loss:  0.058341514 Gen loss:  1.2186441\n",
      "Epoch:  839 Seg loss:  0.24232790235505486 Seg acc:  0.9147110870569921 Disc loss:  0.13468279 Gen loss:  0.9882231\n",
      "Epoch:  840 Seg loss:  0.24230199274385258 Seg acc:  0.9147303206997085 Disc loss:  0.05433035 Gen loss:  1.0634845\n",
      "Epoch:  840 F1 (val):  0.7233063793652866 Acc (val):  0.7628265306122449\n",
      "Epoch:  841 Seg loss:  0.24230560849063038 Seg acc:  0.9147370719988351 Disc loss:  0.13651519 Gen loss:  0.96412736\n",
      "Epoch:  842 Seg loss:  0.2422823871169549 Seg acc:  0.9147607736681372 Disc loss:  0.041238017 Gen loss:  1.0775129\n",
      "Epoch:  843 Seg loss:  0.24220348769977848 Seg acc:  0.9147880504514972 Disc loss:  0.058647707 Gen loss:  1.1118057\n",
      "Epoch:  844 Seg loss:  0.24217068832102828 Seg acc:  0.9147892687880839 Disc loss:  0.061946403 Gen loss:  1.2259922\n",
      "Epoch:  845 Seg loss:  0.24210781787450497 Seg acc:  0.9148209757275693 Disc loss:  0.07481399 Gen loss:  1.0387032\n",
      "Epoch:  846 Seg loss:  0.24200497811602925 Seg acc:  0.9148691923577942 Disc loss:  0.104367964 Gen loss:  1.0475643\n",
      "Epoch:  847 Seg loss:  0.24197256894960315 Seg acc:  0.9148925981254368 Disc loss:  0.071637176 Gen loss:  1.1309686\n",
      "Epoch:  848 Seg loss:  0.24189396978373517 Seg acc:  0.9149315917404698 Disc loss:  0.10431281 Gen loss:  1.1424454\n",
      "Epoch:  849 Seg loss:  0.24181297525886372 Seg acc:  0.9149599769236316 Disc loss:  0.03224834 Gen loss:  1.0977776\n",
      "Epoch:  850 Seg loss:  0.2416725151766749 Seg acc:  0.9150171068427371 Disc loss:  0.048929337 Gen loss:  0.9651815\n",
      "Epoch:  850 F1 (val):  0.7215691694916697 Acc (val):  0.7567755102040816\n",
      "Epoch:  851 Seg loss:  0.24162938811769216 Seg acc:  0.9150405285498454 Disc loss:  0.08482532 Gen loss:  1.0610628\n",
      "Epoch:  852 Seg loss:  0.2416173157854959 Seg acc:  0.9150474274216729 Disc loss:  0.03898196 Gen loss:  1.1100186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  853 Seg loss:  0.24152069629671147 Seg acc:  0.9150863100222504 Disc loss:  0.11893638 Gen loss:  0.8222753\n",
      "Epoch:  854 Seg loss:  0.2414469442284498 Seg acc:  0.9151143478468672 Disc loss:  0.17402384 Gen loss:  1.05964\n",
      "Epoch:  855 Seg loss:  0.24134127319033383 Seg acc:  0.9151602219835303 Disc loss:  0.11272661 Gen loss:  0.98859954\n",
      "Epoch:  856 Seg loss:  0.24128953666017156 Seg acc:  0.9151770813465573 Disc loss:  0.07172017 Gen loss:  1.067044\n",
      "Epoch:  857 Seg loss:  0.2413337048373534 Seg acc:  0.9151671111851976 Disc loss:  0.07059951 Gen loss:  1.1287534\n",
      "Epoch:  858 Seg loss:  0.24126878432009047 Seg acc:  0.9151874910803482 Disc loss:  0.08064293 Gen loss:  1.044976\n",
      "Epoch:  859 Seg loss:  0.24119809373120352 Seg acc:  0.9152093084032217 Disc loss:  0.030118994 Gen loss:  1.1412632\n",
      "Epoch:  860 Seg loss:  0.2411800529287998 Seg acc:  0.9152055647840531 Disc loss:  0.05741757 Gen loss:  1.1547343\n",
      "Epoch:  860 F1 (val):  0.7172412618578318 Acc (val):  0.761969387755102\n",
      "Epoch:  861 Seg loss:  0.24121144759218868 Seg acc:  0.9151956078598688 Disc loss:  0.07543073 Gen loss:  1.1805451\n",
      "Epoch:  862 Seg loss:  0.24112248354161422 Seg acc:  0.9152167479520811 Disc loss:  0.08211231 Gen loss:  0.9938818\n",
      "Epoch:  863 Seg loss:  0.24106171405156546 Seg acc:  0.9152523234090856 Disc loss:  0.06015347 Gen loss:  1.0216831\n",
      "Epoch:  864 Seg loss:  0.24092610051027602 Seg acc:  0.9153132086167801 Disc loss:  0.060906474 Gen loss:  1.080716\n",
      "Epoch:  865 Seg loss:  0.24098739698098573 Seg acc:  0.915290197003657 Disc loss:  0.08324325 Gen loss:  1.2160965\n",
      "Epoch:  866 Seg loss:  0.2410325959118354 Seg acc:  0.9152775486638073 Disc loss:  0.056591794 Gen loss:  1.2747803\n",
      "Epoch:  867 Seg loss:  0.24093832828388081 Seg acc:  0.9153252477461573 Disc loss:  0.101875454 Gen loss:  1.0777417\n",
      "Epoch:  868 Seg loss:  0.240884309866324 Seg acc:  0.915339038841343 Disc loss:  0.06840668 Gen loss:  1.0628074\n",
      "Epoch:  869 Seg loss:  0.24088733736747153 Seg acc:  0.9153419365444682 Disc loss:  0.07419619 Gen loss:  1.0698643\n",
      "Epoch:  870 Seg loss:  0.24081175183427744 Seg acc:  0.9153671123621863 Disc loss:  0.112563275 Gen loss:  1.0294493\n",
      "Epoch:  870 F1 (val):  0.7355164693590381 Acc (val):  0.7657448979591837\n",
      "Epoch:  871 Seg loss:  0.24069163648050224 Seg acc:  0.9154197614751987 Disc loss:  0.056575224 Gen loss:  1.0269985\n",
      "Epoch:  872 Seg loss:  0.24063682226344532 Seg acc:  0.9154351362104476 Disc loss:  0.0430313 Gen loss:  1.1691264\n",
      "Epoch:  873 Seg loss:  0.24058868168487307 Seg acc:  0.9154455081001474 Disc loss:  0.1207916 Gen loss:  0.9292908\n",
      "Epoch:  874 Seg loss:  0.2405498530246846 Seg acc:  0.9154657801335638 Disc loss:  0.07259248 Gen loss:  1.063073\n",
      "Epoch:  875 Seg loss:  0.24047039931161063 Seg acc:  0.915495918367347 Disc loss:  0.04430389 Gen loss:  1.1203685\n",
      "Epoch:  876 Seg loss:  0.24039250081532623 Seg acc:  0.9155187074829931 Disc loss:  0.14374095 Gen loss:  0.913107\n",
      "Epoch:  877 Seg loss:  0.24029400538623402 Seg acc:  0.9155533707211505 Disc loss:  0.10666664 Gen loss:  1.049315\n",
      "Epoch:  878 Seg loss:  0.24023467039260887 Seg acc:  0.9155751708428246 Disc loss:  0.15131465 Gen loss:  1.1291819\n",
      "Epoch:  879 Seg loss:  0.2402497364019507 Seg acc:  0.9155684799517076 Disc loss:  0.058481924 Gen loss:  1.2271336\n",
      "Epoch:  880 Seg loss:  0.2402467692270875 Seg acc:  0.9155641233766234 Disc loss:  0.023843985 Gen loss:  1.1478908\n",
      "Epoch:  880 F1 (val):  0.7142375029771209 Acc (val):  0.7660816326530612\n",
      "Epoch:  881 Seg loss:  0.24023941416339895 Seg acc:  0.9155736755542172 Disc loss:  0.06264214 Gen loss:  1.1232119\n",
      "Epoch:  882 Seg loss:  0.24034152999351355 Seg acc:  0.9155253598037856 Disc loss:  0.044103656 Gen loss:  1.3276157\n",
      "Epoch:  883 Seg loss:  0.24032775624017078 Seg acc:  0.9155300228811798 Disc loss:  0.03535573 Gen loss:  1.0499605\n",
      "Epoch:  884 Seg loss:  0.2402777670971139 Seg acc:  0.9155421784098255 Disc loss:  0.09143988 Gen loss:  1.0520508\n",
      "Epoch:  885 Seg loss:  0.2401673454854448 Seg acc:  0.9155900495791538 Disc loss:  0.04158274 Gen loss:  1.0244966\n",
      "Epoch:  886 Seg loss:  0.24006293885594834 Seg acc:  0.9156363730593818 Disc loss:  0.09142419 Gen loss:  1.0293251\n",
      "Epoch:  887 Seg loss:  0.24004353478702106 Seg acc:  0.9156336999286749 Disc loss:  0.08575496 Gen loss:  1.1455445\n",
      "Epoch:  888 Seg loss:  0.23997789443478929 Seg acc:  0.9156511422136423 Disc loss:  0.056608036 Gen loss:  1.0196373\n",
      "Epoch:  889 Seg loss:  0.23994903256372874 Seg acc:  0.9156585018709396 Disc loss:  0.13081282 Gen loss:  0.93806225\n",
      "Epoch:  890 Seg loss:  0.2398795611068104 Seg acc:  0.9156813230910341 Disc loss:  0.045864765 Gen loss:  1.0920429\n",
      "Epoch:  890 F1 (val):  0.7382209647993844 Acc (val):  0.7702346938775511\n",
      "Epoch:  891 Seg loss:  0.239766408815796 Seg acc:  0.9157278567992855 Disc loss:  0.061378792 Gen loss:  1.0026195\n",
      "Epoch:  892 Seg loss:  0.23978687456971862 Seg acc:  0.9157225221927336 Disc loss:  0.060344517 Gen loss:  1.1216484\n",
      "Epoch:  893 Seg loss:  0.23964493872737563 Seg acc:  0.9157777612724821 Disc loss:  0.117681615 Gen loss:  0.9473773\n",
      "Epoch:  894 Seg loss:  0.23960469344785015 Seg acc:  0.9157929279094189 Disc loss:  0.08442125 Gen loss:  1.0851667\n",
      "Epoch:  895 Seg loss:  0.23954741753346429 Seg acc:  0.9158149013795464 Disc loss:  0.060042627 Gen loss:  1.1850224\n",
      "Epoch:  896 Seg loss:  0.23950726683584175 Seg acc:  0.915824583181487 Disc loss:  0.10511096 Gen loss:  1.0998862\n",
      "Epoch:  897 Seg loss:  0.23947171429992387 Seg acc:  0.9158305462653289 Disc loss:  0.075166434 Gen loss:  1.1512228\n",
      "Epoch:  898 Seg loss:  0.2394864854873687 Seg acc:  0.9158248488705059 Disc loss:  0.056618825 Gen loss:  1.2209029\n",
      "Epoch:  899 Seg loss:  0.2394942368595168 Seg acc:  0.9158325009647907 Disc loss:  0.1271584 Gen loss:  1.048\n",
      "Epoch:  900 Seg loss:  0.23943013270696004 Seg acc:  0.9158565759637187 Disc loss:  0.032570925 Gen loss:  1.1097351\n",
      "Epoch:  900 F1 (val):  0.729055534997775 Acc (val):  0.7628469387755102\n",
      "Epoch:  901 Seg loss:  0.23932342833273948 Seg acc:  0.9158998505062402 Disc loss:  0.095197484 Gen loss:  1.1070826\n",
      "Epoch:  902 Seg loss:  0.23925466381195115 Seg acc:  0.915925494366261 Disc loss:  0.084551275 Gen loss:  1.0604022\n",
      "Epoch:  903 Seg loss:  0.2392184085162111 Seg acc:  0.9159397812281059 Disc loss:  0.04961621 Gen loss:  1.0697297\n",
      "Epoch:  904 Seg loss:  0.2391987871708332 Seg acc:  0.9159404912407442 Disc loss:  0.10752981 Gen loss:  1.1288497\n",
      "Epoch:  905 Seg loss:  0.2391795248122505 Seg acc:  0.9159428909685422 Disc loss:  0.1012139 Gen loss:  0.9544104\n",
      "Epoch:  906 Seg loss:  0.23909655535721094 Seg acc:  0.9159765396224714 Disc loss:  0.07065423 Gen loss:  0.9815428\n",
      "Epoch:  907 Seg loss:  0.23899888119926263 Seg acc:  0.9160118016335532 Disc loss:  0.0621939 Gen loss:  0.9778757\n",
      "Epoch:  908 Seg loss:  0.23899790181856323 Seg acc:  0.9160096197069136 Disc loss:  0.10297804 Gen loss:  1.1931334\n",
      "Epoch:  909 Seg loss:  0.23896307341664275 Seg acc:  0.9160374710940481 Disc loss:  0.057374083 Gen loss:  1.1857529\n",
      "Epoch:  910 Seg loss:  0.23898199369291684 Seg acc:  0.91602741646109 Disc loss:  0.053423624 Gen loss:  1.121687\n",
      "Epoch:  910 F1 (val):  0.7261415820286323 Acc (val):  0.7638979591836734\n",
      "Epoch:  911 Seg loss:  0.23889769818204426 Seg acc:  0.9160633078698001 Disc loss:  0.056700688 Gen loss:  1.0442315\n",
      "Epoch:  912 Seg loss:  0.2388332107251412 Seg acc:  0.9160921276405299 Disc loss:  0.024629777 Gen loss:  1.1467894\n",
      "Epoch:  913 Seg loss:  0.23873585212857412 Seg acc:  0.9161312224780382 Disc loss:  0.04872091 Gen loss:  1.0073248\n",
      "Epoch:  914 Seg loss:  0.2387080044695533 Seg acc:  0.9161426003661859 Disc loss:  0.09937436 Gen loss:  1.2305758\n",
      "Epoch:  915 Seg loss:  0.23862777453302686 Seg acc:  0.9161712389873983 Disc loss:  0.071673855 Gen loss:  1.0308192\n",
      "Epoch:  916 Seg loss:  0.2386081511374384 Seg acc:  0.9161842193209162 Disc loss:  0.11410985 Gen loss:  1.1503369\n",
      "Epoch:  917 Seg loss:  0.23856488464962824 Seg acc:  0.9162035697594195 Disc loss:  0.086957395 Gen loss:  1.1450865\n",
      "Epoch:  918 Seg loss:  0.23853933541733197 Seg acc:  0.9162137077053043 Disc loss:  0.077121 Gen loss:  1.1245028\n",
      "Epoch:  919 Seg loss:  0.2384398218013257 Seg acc:  0.9162576891474762 Disc loss:  0.06660922 Gen loss:  0.9899534\n",
      "Epoch:  920 Seg loss:  0.23843305820356245 Seg acc:  0.9162552684117126 Disc loss:  0.050012894 Gen loss:  1.0726433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  920 F1 (val):  0.7211385406702642 Acc (val):  0.7612959183673469\n",
      "Epoch:  921 Seg loss:  0.2384144782405205 Seg acc:  0.9162664251368301 Disc loss:  0.03705456 Gen loss:  1.1936166\n",
      "Epoch:  922 Seg loss:  0.23836699027947902 Seg acc:  0.9162648302271017 Disc loss:  0.057419803 Gen loss:  1.1442223\n",
      "Epoch:  923 Seg loss:  0.23834830698509774 Seg acc:  0.9162707011298561 Disc loss:  0.12544183 Gen loss:  1.1356035\n",
      "Epoch:  924 Seg loss:  0.2382340432019719 Seg acc:  0.9163204567541302 Disc loss:  0.022954356 Gen loss:  1.0491283\n",
      "Epoch:  925 Seg loss:  0.23814749165161236 Seg acc:  0.9163582460011033 Disc loss:  0.06709175 Gen loss:  1.0148475\n",
      "Epoch:  926 Seg loss:  0.23806014275640958 Seg acc:  0.9163874134967162 Disc loss:  0.032112435 Gen loss:  1.0182372\n",
      "Epoch:  927 Seg loss:  0.23798200780648374 Seg acc:  0.9164170684455012 Disc loss:  0.049552143 Gen loss:  1.0936521\n",
      "Epoch:  928 Seg loss:  0.2379758588263187 Seg acc:  0.9164235683497537 Disc loss:  0.043112755 Gen loss:  1.188683\n",
      "Epoch:  929 Seg loss:  0.23795059968118903 Seg acc:  0.9164240130928584 Disc loss:  0.05570651 Gen loss:  1.1508654\n",
      "Epoch:  930 Seg loss:  0.23789032434904447 Seg acc:  0.9164422865920562 Disc loss:  0.051941197 Gen loss:  1.0272136\n",
      "Epoch:  930 F1 (val):  0.7013598338944431 Acc (val):  0.7546020408163265\n",
      "Epoch:  931 Seg loss:  0.23784111901141392 Seg acc:  0.9164586027751596 Disc loss:  0.07415694 Gen loss:  0.99054044\n",
      "Epoch:  932 Seg loss:  0.23785856466884264 Seg acc:  0.9164486073399317 Disc loss:  0.048118964 Gen loss:  1.2021333\n",
      "Epoch:  933 Seg loss:  0.2377769882528217 Seg acc:  0.9164714438830194 Disc loss:  0.13556111 Gen loss:  0.81403863\n",
      "Epoch:  934 Seg loss:  0.23766037860059636 Seg acc:  0.9165229100205393 Disc loss:  0.048974425 Gen loss:  1.0467196\n",
      "Epoch:  935 Seg loss:  0.2375433620603327 Seg acc:  0.9165709920331769 Disc loss:  0.06795147 Gen loss:  0.9048188\n",
      "Epoch:  936 Seg loss:  0.23750995631273994 Seg acc:  0.916590899180185 Disc loss:  0.086396195 Gen loss:  1.3121461\n",
      "Epoch:  937 Seg loss:  0.23742104250949628 Seg acc:  0.916623832030144 Disc loss:  0.06822829 Gen loss:  1.0475494\n",
      "Epoch:  938 Seg loss:  0.2373306057028679 Seg acc:  0.9166651255384884 Disc loss:  0.033366125 Gen loss:  1.1697147\n",
      "Epoch:  939 Seg loss:  0.2372241268079248 Seg acc:  0.9167030710047598 Disc loss:  0.0735416 Gen loss:  1.0379686\n",
      "Epoch:  940 Seg loss:  0.23732018600753013 Seg acc:  0.9166722752930959 Disc loss:  0.0352327 Gen loss:  1.2026511\n",
      "Epoch:  940 F1 (val):  0.7384486058670799 Acc (val):  0.7656326530612245\n",
      "Epoch:  941 Seg loss:  0.23724480329613884 Seg acc:  0.9167022707063697 Disc loss:  0.047946196 Gen loss:  1.0981148\n",
      "Epoch:  942 Seg loss:  0.23714582206020943 Seg acc:  0.916740868321851 Disc loss:  0.06963759 Gen loss:  0.9134162\n",
      "Epoch:  943 Seg loss:  0.23706222508075003 Seg acc:  0.9167666695522323 Disc loss:  0.030861773 Gen loss:  1.1098132\n",
      "Epoch:  944 Seg loss:  0.2369562672387998 Seg acc:  0.9168091707021792 Disc loss:  0.018653397 Gen loss:  1.0815709\n",
      "Epoch:  945 Seg loss:  0.23688659412520272 Seg acc:  0.9168307958103877 Disc loss:  0.09523699 Gen loss:  1.0839075\n",
      "Epoch:  946 Seg loss:  0.236782224813425 Seg acc:  0.9168752966302801 Disc loss:  0.04034742 Gen loss:  1.0928029\n",
      "Epoch:  947 Seg loss:  0.23675407881532828 Seg acc:  0.9168922267956813 Disc loss:  0.07311256 Gen loss:  1.0515578\n",
      "Epoch:  948 Seg loss:  0.23679104040255022 Seg acc:  0.9168754843709636 Disc loss:  0.093598284 Gen loss:  1.0877904\n",
      "Epoch:  949 Seg loss:  0.23672094374298422 Seg acc:  0.9168958732070278 Disc loss:  0.06754605 Gen loss:  1.0485988\n",
      "Epoch:  950 Seg loss:  0.23668756906923494 Seg acc:  0.9168979591836736 Disc loss:  0.10452577 Gen loss:  1.0096132\n",
      "Epoch:  950 F1 (val):  0.7264851919073149 Acc (val):  0.7657244897959183\n",
      "Epoch:  951 Seg loss:  0.236703209179433 Seg acc:  0.916883141269126 Disc loss:  0.03974268 Gen loss:  1.2254878\n",
      "Epoch:  952 Seg loss:  0.23664442817641407 Seg acc:  0.9169034578116961 Disc loss:  0.05494192 Gen loss:  1.0932571\n",
      "Epoch:  953 Seg loss:  0.2366323851181853 Seg acc:  0.9169111506092469 Disc loss:  0.033183467 Gen loss:  1.141036\n",
      "Epoch:  954 Seg loss:  0.2365561048470953 Seg acc:  0.9169370106533179 Disc loss:  0.09146002 Gen loss:  1.1069839\n",
      "Epoch:  955 Seg loss:  0.23646939576296283 Seg acc:  0.9169585425793354 Disc loss:  0.05476685 Gen loss:  1.063159\n",
      "Epoch:  956 Seg loss:  0.23645461656184377 Seg acc:  0.9169672209888139 Disc loss:  0.08844738 Gen loss:  1.1353035\n",
      "Epoch:  957 Seg loss:  0.23642955287559156 Seg acc:  0.9169694837182523 Disc loss:  0.06485523 Gen loss:  1.0923226\n",
      "Epoch:  958 Seg loss:  0.23637112116515013 Seg acc:  0.9169858548847514 Disc loss:  0.07722773 Gen loss:  0.9995307\n",
      "Epoch:  959 Seg loss:  0.2363550044106741 Seg acc:  0.9169899555233981 Disc loss:  0.049601607 Gen loss:  1.1206505\n",
      "Epoch:  960 Seg loss:  0.23632768844254315 Seg acc:  0.9170073341836734 Disc loss:  0.057201207 Gen loss:  1.1733972\n",
      "Epoch:  960 F1 (val):  0.7247810364430535 Acc (val):  0.762969387755102\n",
      "Epoch:  961 Seg loss:  0.23628778515323515 Seg acc:  0.9170111384824481 Disc loss:  0.036177635 Gen loss:  1.0588902\n",
      "Epoch:  962 Seg loss:  0.23620162735424022 Seg acc:  0.9170459607959608 Disc loss:  0.05381553 Gen loss:  1.1032466\n",
      "Epoch:  963 Seg loss:  0.23614921508238942 Seg acc:  0.9170568694767627 Disc loss:  0.060518228 Gen loss:  1.0403788\n",
      "Epoch:  964 Seg loss:  0.2360815263944543 Seg acc:  0.9170857502752139 Disc loss:  0.041611806 Gen loss:  1.130091\n",
      "Epoch:  965 Seg loss:  0.23604253183065918 Seg acc:  0.9171116633181771 Disc loss:  0.0864176 Gen loss:  1.0163664\n",
      "Epoch:  966 Seg loss:  0.23594769482225117 Seg acc:  0.9171504626695399 Disc loss:  0.05099106 Gen loss:  1.0857518\n",
      "Epoch:  967 Seg loss:  0.23589494681099454 Seg acc:  0.9171815313509064 Disc loss:  0.045596227 Gen loss:  1.1255572\n",
      "Epoch:  968 Seg loss:  0.23597376641224732 Seg acc:  0.917147706189914 Disc loss:  0.02929064 Gen loss:  1.2551582\n",
      "Epoch:  969 Seg loss:  0.23600808390338354 Seg acc:  0.9171381710578969 Disc loss:  0.07654297 Gen loss:  1.1333299\n",
      "Epoch:  970 Seg loss:  0.23597179480741934 Seg acc:  0.9171591626341258 Disc loss:  0.06411066 Gen loss:  1.0763903\n",
      "Epoch:  970 F1 (val):  0.7350510510834802 Acc (val):  0.7699591836734694\n",
      "Epoch:  971 Seg loss:  0.2359530696171565 Seg acc:  0.9171541015994451 Disc loss:  0.07866483 Gen loss:  1.0651871\n",
      "Epoch:  972 Seg loss:  0.23593310347984356 Seg acc:  0.9171608612580834 Disc loss:  0.043324225 Gen loss:  1.219124\n",
      "Epoch:  973 Seg loss:  0.23586620912644993 Seg acc:  0.9171817647922478 Disc loss:  0.10443413 Gen loss:  0.9622929\n",
      "Epoch:  974 Seg loss:  0.2358945712783743 Seg acc:  0.9171651720236349 Disc loss:  0.041108087 Gen loss:  1.2144285\n",
      "Epoch:  975 Seg loss:  0.23577667742967606 Seg acc:  0.9172106227106227 Disc loss:  0.051282756 Gen loss:  0.94793403\n",
      "Epoch:  976 Seg loss:  0.23565916275055926 Seg acc:  0.9172580712612914 Disc loss:  0.04225071 Gen loss:  1.0627021\n",
      "Epoch:  977 Seg loss:  0.235625659209984 Seg acc:  0.9172649510162305 Disc loss:  0.0269 Gen loss:  1.1658512\n",
      "Epoch:  978 Seg loss:  0.23551990136747955 Seg acc:  0.9173052042903052 Disc loss:  0.027554883 Gen loss:  1.0473812\n",
      "Epoch:  979 Seg loss:  0.2354671922307823 Seg acc:  0.9173253111254717 Disc loss:  0.03856128 Gen loss:  1.1200743\n",
      "Epoch:  980 Seg loss:  0.23537757350321936 Seg acc:  0.9173563098708871 Disc loss:  0.055781912 Gen loss:  1.0577369\n",
      "Epoch:  980 F1 (val):  0.719046340052895 Acc (val):  0.7630408163265306\n",
      "Epoch:  981 Seg loss:  0.2353668973366298 Seg acc:  0.917354740061162 Disc loss:  0.03302275 Gen loss:  1.2208145\n",
      "Epoch:  982 Seg loss:  0.2352507546498552 Seg acc:  0.9173983748285465 Disc loss:  0.03485021 Gen loss:  1.0529828\n",
      "Epoch:  983 Seg loss:  0.23519399523401552 Seg acc:  0.9174201216600577 Disc loss:  0.10007371 Gen loss:  1.018177\n",
      "Epoch:  984 Seg loss:  0.23510569530137912 Seg acc:  0.9174568607930977 Disc loss:  0.079236865 Gen loss:  1.0252848\n",
      "Epoch:  985 Seg loss:  0.23505080486765972 Seg acc:  0.9174813529472703 Disc loss:  0.07539877 Gen loss:  1.0007598\n",
      "Epoch:  986 Seg loss:  0.2349602112255643 Seg acc:  0.9175117460777414 Disc loss:  0.088887185 Gen loss:  1.0207639\n",
      "Epoch:  987 Seg loss:  0.2349240059804892 Seg acc:  0.9175301883671402 Disc loss:  0.033371232 Gen loss:  1.1025984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  988 Seg loss:  0.23482973646628952 Seg acc:  0.9175733805668016 Disc loss:  0.05433958 Gen loss:  1.0111169\n",
      "Epoch:  989 Seg loss:  0.23480266184217408 Seg acc:  0.9175816636057861 Disc loss:  0.07083988 Gen loss:  1.1208289\n",
      "Epoch:  990 Seg loss:  0.23472741585638787 Seg acc:  0.9176123479694908 Disc loss:  0.032426387 Gen loss:  1.1362662\n",
      "Epoch:  990 F1 (val):  0.7434581486141456 Acc (val):  0.7725510204081633\n",
      "Epoch:  991 Seg loss:  0.2346492110855885 Seg acc:  0.917648633620956 Disc loss:  0.0695189 Gen loss:  1.1300163\n",
      "Epoch:  992 Seg loss:  0.2345583046290783 Seg acc:  0.917681245885451 Disc loss:  0.042033352 Gen loss:  1.0715462\n",
      "Epoch:  993 Seg loss:  0.23451874649746782 Seg acc:  0.9176968370429742 Disc loss:  0.09022302 Gen loss:  0.9897605\n",
      "Epoch:  994 Seg loss:  0.23443891366632652 Seg acc:  0.917722662505646 Disc loss:  0.04233382 Gen loss:  1.0229089\n",
      "Epoch:  995 Seg loss:  0.23437416756422674 Seg acc:  0.9177522818172494 Disc loss:  0.10628677 Gen loss:  1.0962021\n",
      "Epoch:  996 Seg loss:  0.234311518996176 Seg acc:  0.9177790242603066 Disc loss:  0.063594505 Gen loss:  1.048788\n",
      "Epoch:  997 Seg loss:  0.23430706555380626 Seg acc:  0.9177668208707755 Disc loss:  0.04265868 Gen loss:  1.1084261\n",
      "Epoch:  998 Seg loss:  0.23426614323246456 Seg acc:  0.9177850599157499 Disc loss:  0.069758415 Gen loss:  1.0456824\n",
      "Epoch:  999 Seg loss:  0.23413562063161317 Seg acc:  0.9178313517599231 Disc loss:  0.04623109 Gen loss:  1.0165511\n",
      "Epoch:  1000 Seg loss:  0.23410412573814393 Seg acc:  0.9178385204081633 Disc loss:  0.02740712 Gen loss:  1.1123598\n",
      "Epoch:  1000 F1 (val):  0.7327846193449837 Acc (val):  0.7716632653061225\n",
      "Epoch:  1001 Seg loss:  0.23409307296280857 Seg acc:  0.9178413423311382 Disc loss:  0.0719111 Gen loss:  1.1395761\n",
      "Epoch:  1002 Seg loss:  0.23401271633640258 Seg acc:  0.9178714000570287 Disc loss:  0.06811783 Gen loss:  1.1041709\n",
      "Epoch:  1003 Seg loss:  0.23393617439662234 Seg acc:  0.9178978371009421 Disc loss:  0.03510528 Gen loss:  1.1706079\n",
      "Epoch:  1004 Seg loss:  0.23387494045068544 Seg acc:  0.9179290491096836 Disc loss:  0.0628182 Gen loss:  0.97915035\n",
      "Epoch:  1005 Seg loss:  0.23382427633105227 Seg acc:  0.9179424307036247 Disc loss:  0.020495784 Gen loss:  1.1046519\n",
      "Epoch:  1006 Seg loss:  0.2337858945605295 Seg acc:  0.9179560392745567 Disc loss:  0.057544686 Gen loss:  1.0246278\n",
      "Epoch:  1007 Seg loss:  0.23373095046029663 Seg acc:  0.9179858338568794 Disc loss:  0.08273139 Gen loss:  1.0050894\n",
      "Epoch:  1008 Seg loss:  0.233661545677081 Seg acc:  0.9180100016196956 Disc loss:  0.022836387 Gen loss:  1.1236496\n",
      "Epoch:  1009 Seg loss:  0.23360616267022813 Seg acc:  0.9180379138771465 Disc loss:  0.047132783 Gen loss:  1.1459665\n",
      "Epoch:  1010 Seg loss:  0.23357778392215767 Seg acc:  0.9180463224893918 Disc loss:  0.016204232 Gen loss:  1.2182046\n",
      "Epoch:  1010 F1 (val):  0.7317736587778441 Acc (val):  0.770734693877551\n",
      "Epoch:  1011 Seg loss:  0.23345773840280715 Seg acc:  0.9180955913522679 Disc loss:  0.026664548 Gen loss:  1.0786455\n",
      "Epoch:  1012 Seg loss:  0.23338254775277711 Seg acc:  0.9181195551343067 Disc loss:  0.03022471 Gen loss:  1.0423075\n",
      "Epoch:  1013 Seg loss:  0.23329377652450234 Seg acc:  0.9181467453713964 Disc loss:  0.062124036 Gen loss:  1.1307275\n",
      "Epoch:  1014 Seg loss:  0.23322004267920168 Seg acc:  0.9181846999154691 Disc loss:  0.029259004 Gen loss:  1.0769788\n",
      "Epoch:  1015 Seg loss:  0.23315640558750172 Seg acc:  0.9182087564089675 Disc loss:  0.034288157 Gen loss:  1.1467252\n",
      "Epoch:  1016 Seg loss:  0.2331082183339699 Seg acc:  0.9182244797525309 Disc loss:  0.02786297 Gen loss:  1.1235774\n",
      "Epoch:  1017 Seg loss:  0.2330100465576909 Seg acc:  0.9182617442257138 Disc loss:  0.07357696 Gen loss:  1.0574453\n",
      "Epoch:  1018 Seg loss:  0.23295897211740435 Seg acc:  0.9182934224770458 Disc loss:  0.04293321 Gen loss:  1.1411695\n",
      "Epoch:  1019 Seg loss:  0.23301573787926458 Seg acc:  0.9182604494201999 Disc loss:  0.024483621 Gen loss:  1.1951187\n",
      "Epoch:  1020 Seg loss:  0.2329131305802102 Seg acc:  0.9183023209283714 Disc loss:  0.024418276 Gen loss:  1.0821128\n",
      "Epoch:  1020 F1 (val):  0.7313386766027064 Acc (val):  0.7697551020408163\n",
      "Epoch:  1021 Seg loss:  0.2328747739024774 Seg acc:  0.9183128785304523 Disc loss:  0.048647624 Gen loss:  1.1296543\n",
      "Epoch:  1022 Seg loss:  0.2328441317125776 Seg acc:  0.9183261611885458 Disc loss:  0.061577477 Gen loss:  1.1186236\n",
      "Epoch:  1023 Seg loss:  0.23279461602544738 Seg acc:  0.9183461507770263 Disc loss:  0.06515697 Gen loss:  1.0846651\n",
      "Epoch:  1024 Seg loss:  0.2326973294839263 Seg acc:  0.9183860311702807 Disc loss:  0.047189288 Gen loss:  0.98569524\n",
      "Epoch:  1025 Seg loss:  0.232726481164374 Seg acc:  0.9183678446988552 Disc loss:  0.06172384 Gen loss:  1.1842507\n",
      "Epoch:  1026 Seg loss:  0.2326312107388039 Seg acc:  0.9184051398337113 Disc loss:  0.06707546 Gen loss:  1.06599\n",
      "Epoch:  1027 Seg loss:  0.23256798590576055 Seg acc:  0.9184244778729408 Disc loss:  0.06613369 Gen loss:  1.1106988\n",
      "Epoch:  1028 Seg loss:  0.23257435590086745 Seg acc:  0.9184122627650283 Disc loss:  0.022907892 Gen loss:  1.2183735\n",
      "Epoch:  1029 Seg loss:  0.23253168702936497 Seg acc:  0.9184305646456834 Disc loss:  0.023588585 Gen loss:  1.1813272\n",
      "Epoch:  1030 Seg loss:  0.2324818070507744 Seg acc:  0.9184443728947891 Disc loss:  0.060050864 Gen loss:  1.0288258\n",
      "Epoch:  1030 F1 (val):  0.7308847290818417 Acc (val):  0.7649795918367347\n",
      "Epoch:  1031 Seg loss:  0.232424095287471 Seg acc:  0.9184707733723947 Disc loss:  0.013635431 Gen loss:  1.1437081\n",
      "Epoch:  1032 Seg loss:  0.2323476094319377 Seg acc:  0.9185037968675842 Disc loss:  0.051544502 Gen loss:  1.0162815\n",
      "Epoch:  1033 Seg loss:  0.23232674461655095 Seg acc:  0.918512555070431 Disc loss:  0.047341723 Gen loss:  1.1744574\n",
      "Epoch:  1034 Seg loss:  0.23225410725035106 Seg acc:  0.9185378261556074 Disc loss:  0.036128923 Gen loss:  1.0833509\n",
      "Epoch:  1035 Seg loss:  0.23228789258406357 Seg acc:  0.91852385881889 Disc loss:  0.04847028 Gen loss:  1.1668477\n",
      "Epoch:  1036 Seg loss:  0.23223311446866013 Seg acc:  0.9185468540698133 Disc loss:  0.011752967 Gen loss:  1.1458979\n",
      "Epoch:  1037 Seg loss:  0.23212099065977215 Seg acc:  0.9185944049751048 Disc loss:  0.039212078 Gen loss:  1.0729641\n",
      "Epoch:  1038 Seg loss:  0.23213573788545724 Seg acc:  0.9185983642011718 Disc loss:  0.06011548 Gen loss:  1.1173272\n",
      "Epoch:  1039 Seg loss:  0.23204095136012104 Seg acc:  0.9186374260965214 Disc loss:  0.08299284 Gen loss:  1.047483\n",
      "Epoch:  1040 Seg loss:  0.23199253211944149 Seg acc:  0.9186553178963893 Disc loss:  0.017697737 Gen loss:  1.1692598\n",
      "Epoch:  1040 F1 (val):  0.7000390448421265 Acc (val):  0.7553571428571428\n",
      "Epoch:  1041 Seg loss:  0.23196038660324045 Seg acc:  0.918668274226117 Disc loss:  0.031522233 Gen loss:  1.1456686\n",
      "Epoch:  1042 Seg loss:  0.23190976415480166 Seg acc:  0.9186865917192213 Disc loss:  0.031815104 Gen loss:  1.0964155\n",
      "Epoch:  1043 Seg loss:  0.23190235329411515 Seg acc:  0.9186850627115659 Disc loss:  0.0244191 Gen loss:  1.205861\n",
      "Epoch:  1044 Seg loss:  0.2318776763647338 Seg acc:  0.9187082160450387 Disc loss:  0.07117934 Gen loss:  1.0941036\n",
      "Epoch:  1045 Seg loss:  0.231779609292603 Seg acc:  0.9187454838394687 Disc loss:  0.031582326 Gen loss:  1.0291493\n",
      "Epoch:  1046 Seg loss:  0.23171337894083893 Seg acc:  0.9187739005736137 Disc loss:  0.031929456 Gen loss:  1.0889981\n",
      "Epoch:  1047 Seg loss:  0.2317288780038769 Seg acc:  0.9187715630664873 Disc loss:  0.027688488 Gen loss:  1.1453063\n",
      "Epoch:  1048 Seg loss:  0.231642751016064 Seg acc:  0.9188001441034429 Disc loss:  0.07853499 Gen loss:  1.0302864\n",
      "Epoch:  1049 Seg loss:  0.23151364057432253 Seg acc:  0.9188539619851754 Disc loss:  0.10286066 Gen loss:  0.88879603\n",
      "Epoch:  1050 Seg loss:  0.2314387429895855 Seg acc:  0.9188809523809525 Disc loss:  0.121652596 Gen loss:  0.9492011\n",
      "Epoch:  1050 F1 (val):  0.7359948753010674 Acc (val):  0.7665102040816326\n",
      "Epoch:  1051 Seg loss:  0.23134531558524077 Seg acc:  0.9189156585564768 Disc loss:  0.031414174 Gen loss:  1.0029697\n",
      "Epoch:  1052 Seg loss:  0.23123976029455662 Seg acc:  0.9189556335842322 Disc loss:  0.046677776 Gen loss:  1.0078224\n",
      "Epoch:  1053 Seg loss:  0.231219788173042 Seg acc:  0.9189587088396612 Disc loss:  0.07070129 Gen loss:  1.1254741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1054 Seg loss:  0.231177320990153 Seg acc:  0.9189719436161561 Disc loss:  0.06216547 Gen loss:  1.0312896\n",
      "Epoch:  1055 Seg loss:  0.2311562795845253 Seg acc:  0.9189783828223232 Disc loss:  0.02434807 Gen loss:  1.1644146\n",
      "Epoch:  1056 Seg loss:  0.23115268751103996 Seg acc:  0.9189828772418058 Disc loss:  0.030412339 Gen loss:  1.1896093\n",
      "Epoch:  1057 Seg loss:  0.231161250881745 Seg acc:  0.9189745718533393 Disc loss:  0.08204152 Gen loss:  1.0744951\n",
      "Epoch:  1058 Seg loss:  0.23112071442835047 Seg acc:  0.918996180702905 Disc loss:  0.019771881 Gen loss:  1.1152246\n",
      "Epoch:  1059 Seg loss:  0.23100911781571742 Seg acc:  0.9190418376982521 Disc loss:  0.023361398 Gen loss:  1.0562208\n",
      "Epoch:  1060 Seg loss:  0.23091254003767697 Seg acc:  0.9190801886792453 Disc loss:  0.050564937 Gen loss:  1.0985548\n",
      "Epoch:  1060 F1 (val):  0.7306429734489672 Acc (val):  0.7698877551020408\n",
      "Epoch:  1061 Seg loss:  0.23082077720893318 Seg acc:  0.9191199099809575 Disc loss:  0.07885295 Gen loss:  1.1254426\n",
      "Epoch:  1062 Seg loss:  0.23072698869498662 Seg acc:  0.9191609977324262 Disc loss:  0.039578874 Gen loss:  1.0146735\n",
      "Epoch:  1063 Seg loss:  0.23075663749047975 Seg acc:  0.919142252385432 Disc loss:  0.09698258 Gen loss:  1.054943\n",
      "Epoch:  1064 Seg loss:  0.23076246461754008 Seg acc:  0.9191472782722111 Disc loss:  0.030992065 Gen loss:  1.1353267\n",
      "Epoch:  1065 Seg loss:  0.23066080124445365 Seg acc:  0.9191932547666953 Disc loss:  0.047286753 Gen loss:  1.0395851\n",
      "Epoch:  1066 Seg loss:  0.23057091487728856 Seg acc:  0.9192247865375043 Disc loss:  0.05141373 Gen loss:  1.0449508\n",
      "Epoch:  1067 Seg loss:  0.2305049327845426 Seg acc:  0.9192443050322285 Disc loss:  0.0620263 Gen loss:  1.0892563\n",
      "Epoch:  1068 Seg loss:  0.23042279144239783 Seg acc:  0.919275968814492 Disc loss:  0.017874703 Gen loss:  1.1603112\n",
      "Epoch:  1069 Seg loss:  0.23042137721523823 Seg acc:  0.9192732097516275 Disc loss:  0.03006091 Gen loss:  1.1403668\n",
      "Epoch:  1070 Seg loss:  0.23034259064175258 Seg acc:  0.919308601945451 Disc loss:  0.020494692 Gen loss:  1.0755535\n",
      "Epoch:  1070 F1 (val):  0.7141751735388089 Acc (val):  0.7590918367346938\n",
      "Epoch:  1071 Seg loss:  0.23026732183526766 Seg acc:  0.9193372587130091 Disc loss:  0.02714807 Gen loss:  1.0881331\n",
      "Epoch:  1072 Seg loss:  0.23019261986239634 Seg acc:  0.9193649101431617 Disc loss:  0.101511545 Gen loss:  1.0884526\n",
      "Epoch:  1073 Seg loss:  0.23009870904745172 Seg acc:  0.9194065370789508 Disc loss:  0.061114952 Gen loss:  0.98209286\n",
      "Epoch:  1074 Seg loss:  0.23005415028866444 Seg acc:  0.9194307471591989 Disc loss:  0.018096916 Gen loss:  1.1126691\n",
      "Epoch:  1075 Seg loss:  0.2299967852581379 Seg acc:  0.9194473184622686 Disc loss:  0.104026616 Gen loss:  0.96983695\n",
      "Epoch:  1076 Seg loss:  0.22991257786861583 Seg acc:  0.9194849594112738 Disc loss:  0.028936777 Gen loss:  1.0537214\n",
      "Epoch:  1077 Seg loss:  0.2298515509319394 Seg acc:  0.9195142402364845 Disc loss:  0.021918233 Gen loss:  1.0600039\n",
      "Epoch:  1078 Seg loss:  0.2298359463685961 Seg acc:  0.9195193290674339 Disc loss:  0.0636918 Gen loss:  1.1644989\n",
      "Epoch:  1079 Seg loss:  0.22972853755901212 Seg acc:  0.9195598721416278 Disc loss:  0.039761096 Gen loss:  1.044559\n",
      "Epoch:  1080 Seg loss:  0.22976468853238557 Seg acc:  0.9195582955404383 Disc loss:  0.02853679 Gen loss:  1.1587579\n",
      "Epoch:  1080 F1 (val):  0.7140801806060284 Acc (val):  0.7623061224489796\n",
      "Epoch:  1081 Seg loss:  0.22967123678583 Seg acc:  0.919605335196058 Disc loss:  0.024584632 Gen loss:  1.0405447\n",
      "Epoch:  1082 Seg loss:  0.22965335068525317 Seg acc:  0.9196126787128899 Disc loss:  0.017794972 Gen loss:  1.1594101\n",
      "Epoch:  1083 Seg loss:  0.22964834896563824 Seg acc:  0.919605168937381 Disc loss:  0.0128789805 Gen loss:  1.1602995\n",
      "Epoch:  1084 Seg loss:  0.229617667738417 Seg acc:  0.9196193237442579 Disc loss:  0.01534074 Gen loss:  1.15378\n",
      "Epoch:  1085 Seg loss:  0.22959685676520872 Seg acc:  0.9196360387472962 Disc loss:  0.032065056 Gen loss:  1.1013066\n",
      "Epoch:  1086 Seg loss:  0.2295461186511411 Seg acc:  0.9196588303829819 Disc loss:  0.05281333 Gen loss:  1.0819408\n",
      "Epoch:  1087 Seg loss:  0.2294550860967237 Seg acc:  0.9196928449392636 Disc loss:  0.047546808 Gen loss:  1.0539618\n",
      "Epoch:  1088 Seg loss:  0.2294120968059253 Seg acc:  0.9197071015906362 Disc loss:  0.0449515 Gen loss:  1.085828\n",
      "Epoch:  1089 Seg loss:  0.22939756153454136 Seg acc:  0.9197178182567793 Disc loss:  0.03589268 Gen loss:  1.211335\n",
      "Epoch:  1090 Seg loss:  0.22937843701844915 Seg acc:  0.9197537914248267 Disc loss:  0.021685358 Gen loss:  1.1723466\n",
      "Epoch:  1090 F1 (val):  0.7312840772306319 Acc (val):  0.7728775510204081\n",
      "Epoch:  1091 Seg loss:  0.229346174784312 Seg acc:  0.9197698236031351 Disc loss:  0.029370088 Gen loss:  1.1484462\n",
      "Epoch:  1092 Seg loss:  0.2292744623967907 Seg acc:  0.9198012446736936 Disc loss:  0.034587067 Gen loss:  1.0199798\n",
      "Epoch:  1093 Seg loss:  0.22920420298937363 Seg acc:  0.9198195380622514 Disc loss:  0.050813608 Gen loss:  0.996202\n",
      "Epoch:  1094 Seg loss:  0.2291453383944697 Seg acc:  0.9198394302876544 Disc loss:  0.042396538 Gen loss:  1.0795939\n",
      "Epoch:  1095 Seg loss:  0.22921688275658378 Seg acc:  0.9198406485882024 Disc loss:  0.031051386 Gen loss:  1.2549505\n",
      "Epoch:  1096 Seg loss:  0.2291502583513621 Seg acc:  0.9198649076418889 Disc loss:  0.03541428 Gen loss:  1.0637926\n",
      "Epoch:  1097 Seg loss:  0.22918596528911983 Seg acc:  0.9198533105129015 Disc loss:  0.057419863 Gen loss:  1.146249\n",
      "Epoch:  1098 Seg loss:  0.22916424231695348 Seg acc:  0.9198751905133637 Disc loss:  0.02212309 Gen loss:  1.196067\n",
      "Epoch:  1099 Seg loss:  0.22911875437372267 Seg acc:  0.9198905312807562 Disc loss:  0.011771306 Gen loss:  1.126018\n",
      "Epoch:  1100 Seg loss:  0.22902497164905072 Seg acc:  0.9199288033395177 Disc loss:  0.058473315 Gen loss:  1.1189079\n",
      "Epoch:  1100 F1 (val):  0.7143664481596381 Acc (val):  0.7551326530612245\n",
      "Epoch:  1101 Seg loss:  0.22900644027975664 Seg acc:  0.9199308606276297 Disc loss:  0.023088261 Gen loss:  1.0953506\n",
      "Epoch:  1102 Seg loss:  0.22896982110806904 Seg acc:  0.9199509704063112 Disc loss:  0.065746576 Gen loss:  1.1200119\n",
      "Epoch:  1103 Seg loss:  0.2289817472303443 Seg acc:  0.9199560105093714 Disc loss:  0.023210838 Gen loss:  1.1770214\n",
      "Epoch:  1104 Seg loss:  0.22893564598094943 Seg acc:  0.9199707464507542 Disc loss:  0.08084748 Gen loss:  0.9759637\n",
      "Epoch:  1105 Seg loss:  0.2288649008756849 Seg acc:  0.9199960753532181 Disc loss:  0.033791788 Gen loss:  1.0518442\n",
      "Epoch:  1106 Seg loss:  0.22880843822687702 Seg acc:  0.9200130549507325 Disc loss:  0.019514248 Gen loss:  1.0929295\n",
      "Epoch:  1107 Seg loss:  0.22881744155204287 Seg acc:  0.9199963589771951 Disc loss:  0.03200563 Gen loss:  1.138279\n",
      "Epoch:  1108 Seg loss:  0.22882066690615152 Seg acc:  0.9199815350327856 Disc loss:  0.030156782 Gen loss:  1.1416278\n",
      "Epoch:  1109 Seg loss:  0.22881443949703487 Seg acc:  0.9199842200180341 Disc loss:  0.012541182 Gen loss:  1.1734662\n",
      "Epoch:  1110 Seg loss:  0.22885138464269336 Seg acc:  0.919959091744806 Disc loss:  0.037387095 Gen loss:  1.1971354\n",
      "Epoch:  1110 F1 (val):  0.7217188848394401 Acc (val):  0.7603469387755102\n",
      "Epoch:  1111 Seg loss:  0.22884372497039482 Seg acc:  0.9199567405720163 Disc loss:  0.038515627 Gen loss:  1.1841002\n",
      "Epoch:  1112 Seg loss:  0.2288006866055963 Seg acc:  0.9199713698429012 Disc loss:  0.0150585435 Gen loss:  1.1585387\n",
      "Epoch:  1113 Seg loss:  0.22881240480699094 Seg acc:  0.9199669490437684 Disc loss:  0.041129243 Gen loss:  1.1473382\n",
      "Epoch:  1114 Seg loss:  0.2287354464416979 Seg acc:  0.9199975726376726 Disc loss:  0.07474011 Gen loss:  1.0357027\n",
      "Epoch:  1115 Seg loss:  0.22868783131174977 Seg acc:  0.9200162441658276 Disc loss:  0.022586785 Gen loss:  1.0603361\n",
      "Epoch:  1116 Seg loss:  0.22862699041042917 Seg acc:  0.9200431113305536 Disc loss:  0.014893968 Gen loss:  1.1152122\n",
      "Epoch:  1117 Seg loss:  0.2285484839080697 Seg acc:  0.920072442584912 Disc loss:  0.056345522 Gen loss:  1.0137446\n",
      "Epoch:  1118 Seg loss:  0.22846791096871355 Seg acc:  0.920111989339564 Disc loss:  0.037587028 Gen loss:  1.0433221\n",
      "Epoch:  1119 Seg loss:  0.2284363721088707 Seg acc:  0.9201181813207856 Disc loss:  0.036351793 Gen loss:  1.1154342\n",
      "Epoch:  1120 Seg loss:  0.2283912424862917 Seg acc:  0.9201409894314868 Disc loss:  0.011715543 Gen loss:  1.1669836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1120 F1 (val):  0.739555419926727 Acc (val):  0.7715306122448979\n",
      "Epoch:  1121 Seg loss:  0.22835343608916817 Seg acc:  0.9201523785250051 Disc loss:  0.046836395 Gen loss:  1.0840127\n",
      "Epoch:  1122 Seg loss:  0.2283606479498898 Seg acc:  0.9201553348612171 Disc loss:  0.029122522 Gen loss:  1.208079\n",
      "Epoch:  1123 Seg loss:  0.22838427795832006 Seg acc:  0.9201494266451015 Disc loss:  0.05000909 Gen loss:  1.0967741\n",
      "Epoch:  1124 Seg loss:  0.22829154969666987 Seg acc:  0.9201821119907038 Disc loss:  0.03526091 Gen loss:  1.0612478\n",
      "Epoch:  1125 Seg loss:  0.22824768124024072 Seg acc:  0.9202090702947846 Disc loss:  0.07468213 Gen loss:  1.112556\n",
      "Epoch:  1126 Seg loss:  0.2282471184818931 Seg acc:  0.9202126454489433 Disc loss:  0.032087468 Gen loss:  1.1431546\n",
      "Epoch:  1127 Seg loss:  0.22822103168098082 Seg acc:  0.9202223258424932 Disc loss:  0.031215146 Gen loss:  1.1133413\n",
      "Epoch:  1128 Seg loss:  0.2281677887992973 Seg acc:  0.9202401306267187 Disc loss:  0.011599775 Gen loss:  1.1144581\n",
      "Epoch:  1129 Seg loss:  0.2280626836487738 Seg acc:  0.920285018347463 Disc loss:  0.028056828 Gen loss:  1.031734\n",
      "Epoch:  1130 Seg loss:  0.22802237374460801 Seg acc:  0.9202998013364638 Disc loss:  0.023827953 Gen loss:  1.0658062\n",
      "Epoch:  1130 F1 (val):  0.6158472349743263 Acc (val):  0.715969387755102\n",
      "Epoch:  1131 Seg loss:  0.2279848995446421 Seg acc:  0.9203154604016672 Disc loss:  0.008893617 Gen loss:  1.1460155\n",
      "Epoch:  1132 Seg loss:  0.22791773667262846 Seg acc:  0.920331767866157 Disc loss:  0.015199853 Gen loss:  1.1173329\n",
      "Epoch:  1133 Seg loss:  0.22788091226820387 Seg acc:  0.9203448943566834 Disc loss:  0.03890941 Gen loss:  1.110225\n",
      "Epoch:  1134 Seg loss:  0.22780820708294813 Seg acc:  0.920376669186193 Disc loss:  0.052762344 Gen loss:  1.0805615\n",
      "Epoch:  1135 Seg loss:  0.22775717002836093 Seg acc:  0.9203915310617637 Disc loss:  0.052705545 Gen loss:  1.029133\n",
      "Epoch:  1136 Seg loss:  0.22769812343012488 Seg acc:  0.920420963279678 Disc loss:  0.03988467 Gen loss:  1.0317168\n",
      "Epoch:  1137 Seg loss:  0.22766165289185816 Seg acc:  0.9204238687559455 Disc loss:  0.0270919 Gen loss:  1.1075989\n",
      "Epoch:  1138 Seg loss:  0.22758196831823232 Seg acc:  0.9204556866683403 Disc loss:  0.014197139 Gen loss:  1.0721171\n",
      "Epoch:  1139 Seg loss:  0.2275057899405079 Seg acc:  0.9204923760548996 Disc loss:  0.036625415 Gen loss:  1.118926\n",
      "Epoch:  1140 Seg loss:  0.2275349611187713 Seg acc:  0.9204943161475118 Disc loss:  0.08373693 Gen loss:  1.0554787\n",
      "Epoch:  1140 F1 (val):  0.7378710144666385 Acc (val):  0.7691632653061224\n",
      "Epoch:  1141 Seg loss:  0.22747874957991732 Seg acc:  0.9205121268489865 Disc loss:  0.05697778 Gen loss:  1.0266595\n",
      "Epoch:  1142 Seg loss:  0.227386414822054 Seg acc:  0.9205502341041495 Disc loss:  0.016282542 Gen loss:  1.0910145\n",
      "Epoch:  1143 Seg loss:  0.2273638775394553 Seg acc:  0.9205628314317852 Disc loss:  0.028001169 Gen loss:  1.0901809\n",
      "Epoch:  1144 Seg loss:  0.2273205641422655 Seg acc:  0.9205789745968318 Disc loss:  0.029685274 Gen loss:  1.1482029\n",
      "Epoch:  1145 Seg loss:  0.22726782592883799 Seg acc:  0.9206006594777648 Disc loss:  0.04958776 Gen loss:  1.0352767\n",
      "Epoch:  1146 Seg loss:  0.2271917564420592 Seg acc:  0.9206372208569292 Disc loss:  0.005388395 Gen loss:  1.114249\n",
      "Epoch:  1147 Seg loss:  0.22710823502193458 Seg acc:  0.9206632653061225 Disc loss:  0.03395333 Gen loss:  1.0999742\n",
      "Epoch:  1148 Seg loss:  0.2270807560650106 Seg acc:  0.9206770425940413 Disc loss:  0.09116451 Gen loss:  1.1376641\n",
      "Epoch:  1149 Seg loss:  0.22706957624413016 Seg acc:  0.9206774746452107 Disc loss:  0.007036895 Gen loss:  1.1769819\n",
      "Epoch:  1150 Seg loss:  0.22709268673606542 Seg acc:  0.9206767968056787 Disc loss:  0.058646016 Gen loss:  1.1341993\n",
      "Epoch:  1150 F1 (val):  0.7335870147642095 Acc (val):  0.7651020408163265\n",
      "Epoch:  1151 Seg loss:  0.22705517023102706 Seg acc:  0.920692077873721 Disc loss:  0.029702082 Gen loss:  1.0817398\n",
      "Epoch:  1152 Seg loss:  0.22702506793818125 Seg acc:  0.9206902813208616 Disc loss:  0.037136797 Gen loss:  1.1246227\n",
      "Epoch:  1153 Seg loss:  0.22698979530764576 Seg acc:  0.9206980016638051 Disc loss:  0.033217207 Gen loss:  1.0841234\n",
      "Epoch:  1154 Seg loss:  0.22692557461753463 Seg acc:  0.920727151345807 Disc loss:  0.0503951 Gen loss:  1.0316362\n",
      "Epoch:  1155 Seg loss:  0.22688952320581907 Seg acc:  0.9207388020143121 Disc loss:  0.04066322 Gen loss:  1.0937946\n",
      "Epoch:  1156 Seg loss:  0.22680896899588793 Seg acc:  0.9207687486759408 Disc loss:  0.048973367 Gen loss:  1.0112168\n",
      "Epoch:  1157 Seg loss:  0.2267975243598918 Seg acc:  0.9207770359656394 Disc loss:  0.019507727 Gen loss:  1.1772527\n",
      "Epoch:  1158 Seg loss:  0.2267065767990184 Seg acc:  0.9208124052729898 Disc loss:  0.04778678 Gen loss:  1.0741454\n",
      "Epoch:  1159 Seg loss:  0.22668660313816705 Seg acc:  0.9208175591202831 Disc loss:  0.037377708 Gen loss:  1.0927646\n",
      "Epoch:  1160 Seg loss:  0.2266083854475412 Seg acc:  0.9208592100633356 Disc loss:  0.03519518 Gen loss:  1.049341\n",
      "Epoch:  1160 F1 (val):  0.7378714016613436 Acc (val):  0.7742653061224489\n",
      "Epoch:  1161 Seg loss:  0.22653627551572267 Seg acc:  0.92088562815307 Disc loss:  0.08613707 Gen loss:  1.0082511\n",
      "Epoch:  1162 Seg loss:  0.22653336408139302 Seg acc:  0.9208799483648882 Disc loss:  0.07061472 Gen loss:  1.1589962\n",
      "Epoch:  1163 Seg loss:  0.22651110131450491 Seg acc:  0.9208880972853457 Disc loss:  0.052405443 Gen loss:  1.1609291\n",
      "Epoch:  1164 Seg loss:  0.22649035430625336 Seg acc:  0.9208909723683287 Disc loss:  0.101192534 Gen loss:  1.0384429\n",
      "Epoch:  1165 Seg loss:  0.2264252243059899 Seg acc:  0.9209163966015591 Disc loss:  0.045779876 Gen loss:  1.0643514\n",
      "Epoch:  1166 Seg loss:  0.22641918361570373 Seg acc:  0.9209131165330626 Disc loss:  0.014253647 Gen loss:  1.1519823\n",
      "Epoch:  1167 Seg loss:  0.22648633222934417 Seg acc:  0.9209102792788066 Disc loss:  0.019381886 Gen loss:  1.2474864\n",
      "Epoch:  1168 Seg loss:  0.22639147747843846 Seg acc:  0.9209498182834778 Disc loss:  0.07460668 Gen loss:  0.92495286\n",
      "Epoch:  1169 Seg loss:  0.22639410765610565 Seg acc:  0.920943899373265 Disc loss:  0.012472002 Gen loss:  1.1552087\n",
      "Epoch:  1170 Seg loss:  0.22646137817929954 Seg acc:  0.9209249084249083 Disc loss:  0.016505923 Gen loss:  1.2674191\n",
      "Epoch:  1170 F1 (val):  0.7069204477690163 Acc (val):  0.7570714285714286\n",
      "Epoch:  1171 Seg loss:  0.2264113181312811 Seg acc:  0.9209525697554855 Disc loss:  0.052706096 Gen loss:  1.1289184\n",
      "Epoch:  1172 Seg loss:  0.2263167727700476 Seg acc:  0.9209878021174339 Disc loss:  0.027028518 Gen loss:  1.0546486\n",
      "Epoch:  1173 Seg loss:  0.2263373615059808 Seg acc:  0.9209792612697253 Disc loss:  0.020867953 Gen loss:  1.2413969\n",
      "Epoch:  1174 Seg loss:  0.226301259657898 Seg acc:  0.9210007214129263 Disc loss:  0.049126364 Gen loss:  1.0825057\n",
      "Epoch:  1175 Seg loss:  0.22618283731506225 Seg acc:  0.9210514546244029 Disc loss:  0.009705994 Gen loss:  1.0427299\n",
      "Epoch:  1176 Seg loss:  0.22608703866499621 Seg acc:  0.9210916892267111 Disc loss:  0.046321373 Gen loss:  1.0003903\n",
      "Epoch:  1177 Seg loss:  0.2259722144145933 Seg acc:  0.9211433426386698 Disc loss:  0.017263355 Gen loss:  1.025336\n",
      "Epoch:  1178 Seg loss:  0.22585761583139818 Seg acc:  0.9211940421329823 Disc loss:  0.038414814 Gen loss:  0.97020227\n",
      "Epoch:  1179 Seg loss:  0.22577769497600625 Seg acc:  0.9212342697893408 Disc loss:  0.091885865 Gen loss:  1.0139047\n",
      "Epoch:  1180 Seg loss:  0.22571148318633186 Seg acc:  0.9212642684192321 Disc loss:  0.031655617 Gen loss:  1.0831379\n",
      "Epoch:  1180 F1 (val):  0.7364460258844261 Acc (val):  0.7674897959183673\n",
      "Epoch:  1181 Seg loss:  0.225692851596672 Seg acc:  0.9212715357099657 Disc loss:  0.039851956 Gen loss:  1.1303191\n",
      "Epoch:  1182 Seg loss:  0.22565354957117648 Seg acc:  0.9212736109672295 Disc loss:  0.01129509 Gen loss:  1.1458083\n",
      "Epoch:  1183 Seg loss:  0.22559032446861468 Seg acc:  0.9213080287059877 Disc loss:  0.0190695 Gen loss:  1.1435659\n",
      "Epoch:  1184 Seg loss:  0.22554083628504462 Seg acc:  0.9213249362244899 Disc loss:  0.0052963323 Gen loss:  1.1463058\n",
      "Epoch:  1185 Seg loss:  0.22544936730766096 Seg acc:  0.9213687247050719 Disc loss:  0.01601454 Gen loss:  1.0322268\n",
      "Epoch:  1186 Seg loss:  0.22534617314250233 Seg acc:  0.9214096431152563 Disc loss:  0.022762615 Gen loss:  1.0222368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1187 Seg loss:  0.2253386231159702 Seg acc:  0.9214176108522601 Disc loss:  0.021612551 Gen loss:  1.1245215\n",
      "Epoch:  1188 Seg loss:  0.22534581227384834 Seg acc:  0.9214062392633822 Disc loss:  0.024756566 Gen loss:  1.1152074\n",
      "Epoch:  1189 Seg loss:  0.22533871999199998 Seg acc:  0.9214077599080002 Disc loss:  0.03149281 Gen loss:  1.203865\n",
      "Epoch:  1190 Seg loss:  0.22529390401699964 Seg acc:  0.9214251414851655 Disc loss:  0.036358707 Gen loss:  1.0044271\n",
      "Epoch:  1190 F1 (val):  0.7460855428734114 Acc (val):  0.7705510204081633\n",
      "Epoch:  1191 Seg loss:  0.22526491516583314 Seg acc:  0.9214289998115115 Disc loss:  0.008902349 Gen loss:  1.1257765\n",
      "Epoch:  1192 Seg loss:  0.2251955138631915 Seg acc:  0.9214658094781536 Disc loss:  0.026290523 Gen loss:  1.0428034\n",
      "Epoch:  1193 Seg loss:  0.2251129525979826 Seg acc:  0.9215029851001592 Disc loss:  0.008910402 Gen loss:  1.0809305\n",
      "Epoch:  1194 Seg loss:  0.2251875769577833 Seg acc:  0.9214862578197108 Disc loss:  0.051273603 Gen loss:  1.306305\n",
      "Epoch:  1195 Seg loss:  0.22514876937766454 Seg acc:  0.9214947485270261 Disc loss:  0.042155344 Gen loss:  1.1615087\n",
      "Epoch:  1196 Seg loss:  0.22514579330499357 Seg acc:  0.9215027984437921 Disc loss:  0.02256635 Gen loss:  1.1585382\n",
      "Epoch:  1197 Seg loss:  0.22512750589011007 Seg acc:  0.9215023101972618 Disc loss:  0.026672352 Gen loss:  1.1497244\n",
      "Epoch:  1198 Seg loss:  0.22506097311119802 Seg acc:  0.9215286531975061 Disc loss:  0.03688742 Gen loss:  1.0168973\n",
      "Epoch:  1199 Seg loss:  0.22498955741040005 Seg acc:  0.9215641010365783 Disc loss:  0.008835768 Gen loss:  1.0954251\n",
      "Epoch:  1200 Seg loss:  0.2249693229297797 Seg acc:  0.9215782312925171 Disc loss:  0.04621505 Gen loss:  1.0759896\n",
      "Epoch:  1200 F1 (val):  0.7429795981585925 Acc (val):  0.7776224489795919\n",
      "Epoch:  1201 Seg loss:  0.22491020046106286 Seg acc:  0.9215978606263487 Disc loss:  0.004307026 Gen loss:  1.1291143\n",
      "Epoch:  1202 Seg loss:  0.22481933546046448 Seg acc:  0.9216359214234779 Disc loss:  0.035604812 Gen loss:  0.9734938\n",
      "Epoch:  1203 Seg loss:  0.22485779348454274 Seg acc:  0.9216259945374659 Disc loss:  0.130345 Gen loss:  1.1480914\n",
      "Epoch:  1204 Seg loss:  0.2247908669106192 Seg acc:  0.9216529510475286 Disc loss:  0.07605606 Gen loss:  0.9933156\n",
      "Epoch:  1205 Seg loss:  0.22473811238880473 Seg acc:  0.9216658904225592 Disc loss:  0.007676874 Gen loss:  1.0900184\n",
      "Epoch:  1206 Seg loss:  0.22462707796870773 Seg acc:  0.9217128642501777 Disc loss:  0.056309354 Gen loss:  0.9544157\n",
      "Epoch:  1207 Seg loss:  0.22462663729154284 Seg acc:  0.9217107265441388 Disc loss:  0.019583726 Gen loss:  1.1780488\n",
      "Epoch:  1208 Seg loss:  0.22455925953926037 Seg acc:  0.9217352007027977 Disc loss:  0.06719955 Gen loss:  1.0074124\n",
      "Epoch:  1209 Seg loss:  0.22459659367996962 Seg acc:  0.9217182778818722 Disc loss:  0.049520195 Gen loss:  1.1582676\n",
      "Epoch:  1210 Seg loss:  0.2245034179657944 Seg acc:  0.921757041659639 Disc loss:  0.025360959 Gen loss:  1.0556151\n",
      "Epoch:  1210 F1 (val):  0.7172609279203414 Acc (val):  0.7604795918367347\n",
      "Epoch:  1211 Seg loss:  0.22444018979982144 Seg acc:  0.9217831021756347 Disc loss:  0.02526761 Gen loss:  1.0950513\n",
      "Epoch:  1212 Seg loss:  0.2243966697761328 Seg acc:  0.9218072253653935 Disc loss:  0.050347492 Gen loss:  1.0261843\n",
      "Epoch:  1213 Seg loss:  0.22430632544124018 Seg acc:  0.9218479230109191 Disc loss:  0.018425094 Gen loss:  1.0928544\n",
      "Epoch:  1214 Seg loss:  0.2243151539166441 Seg acc:  0.9218353898396261 Disc loss:  0.027532168 Gen loss:  1.1552379\n",
      "Epoch:  1215 Seg loss:  0.22426824191960779 Seg acc:  0.9218522717729066 Disc loss:  0.018375894 Gen loss:  1.1311052\n",
      "Epoch:  1216 Seg loss:  0.22423002436315934 Seg acc:  0.9218682867883995 Disc loss:  0.009364272 Gen loss:  1.1248728\n",
      "Epoch:  1217 Seg loss:  0.22419444322830942 Seg acc:  0.9218798735599417 Disc loss:  0.009305945 Gen loss:  1.1167017\n",
      "Epoch:  1218 Seg loss:  0.2240828182395358 Seg acc:  0.9219243239167587 Disc loss:  0.043771286 Gen loss:  0.9824122\n",
      "Epoch:  1219 Seg loss:  0.22406716015834707 Seg acc:  0.9219354271651237 Disc loss:  0.051961273 Gen loss:  1.0840034\n",
      "Epoch:  1220 Seg loss:  0.22402343081279857 Seg acc:  0.9219542489126796 Disc loss:  0.05992925 Gen loss:  1.0452024\n",
      "Epoch:  1220 F1 (val):  0.719485486997339 Acc (val):  0.7564693877551021\n",
      "Epoch:  1221 Seg loss:  0.22401747923347426 Seg acc:  0.9219529826672683 Disc loss:  0.011422849 Gen loss:  1.2196954\n",
      "Epoch:  1222 Seg loss:  0.22402077912674598 Seg acc:  0.9219473345803134 Disc loss:  0.04734318 Gen loss:  1.0764631\n",
      "Epoch:  1223 Seg loss:  0.22396964354414678 Seg acc:  0.921967143357752 Disc loss:  0.0044827415 Gen loss:  1.1461635\n",
      "Epoch:  1224 Seg loss:  0.2239536395345151 Seg acc:  0.9219746231826061 Disc loss:  0.013813543 Gen loss:  1.1146619\n",
      "Epoch:  1225 Seg loss:  0.22387586286481545 Seg acc:  0.9220035401915867 Disc loss:  0.009013633 Gen loss:  1.101812\n",
      "Epoch:  1226 Seg loss:  0.22388138454924011 Seg acc:  0.9220026550587608 Disc loss:  0.006955578 Gen loss:  1.2203242\n",
      "Epoch:  1227 Seg loss:  0.22381271441947567 Seg acc:  0.9220258885950467 Disc loss:  0.018182771 Gen loss:  1.1351281\n",
      "Epoch:  1228 Seg loss:  0.22369468408099796 Seg acc:  0.9220729741407964 Disc loss:  0.032726675 Gen loss:  1.009508\n",
      "Epoch:  1229 Seg loss:  0.2236501836953753 Seg acc:  0.9220929991199083 Disc loss:  0.008592174 Gen loss:  1.1337137\n",
      "Epoch:  1230 Seg loss:  0.22358692430747235 Seg acc:  0.9221119545379128 Disc loss:  0.027261896 Gen loss:  1.0827553\n",
      "Epoch:  1230 F1 (val):  0.7254367935568709 Acc (val):  0.7724795918367346\n",
      "Epoch:  1231 Seg loss:  0.22357691682203334 Seg acc:  0.922114715098062 Disc loss:  0.035039783 Gen loss:  1.0860023\n",
      "Epoch:  1232 Seg loss:  0.22349683177209906 Seg acc:  0.9221452176649879 Disc loss:  0.03967372 Gen loss:  1.0849576\n",
      "Epoch:  1233 Seg loss:  0.223412466829904 Seg acc:  0.9221736018008176 Disc loss:  0.046715945 Gen loss:  1.0390216\n",
      "Epoch:  1234 Seg loss:  0.22331951169155212 Seg acc:  0.9222128965038202 Disc loss:  0.06521556 Gen loss:  0.99943197\n",
      "Epoch:  1235 Seg loss:  0.2232741935834711 Seg acc:  0.9222279600099148 Disc loss:  0.028075367 Gen loss:  1.0925587\n",
      "Epoch:  1236 Seg loss:  0.22323783509385045 Seg acc:  0.9222483653655636 Disc loss:  0.019981248 Gen loss:  1.1200379\n",
      "Epoch:  1237 Seg loss:  0.2231906367377013 Seg acc:  0.9222710062197877 Disc loss:  0.0078403875 Gen loss:  1.1131207\n",
      "Epoch:  1238 Seg loss:  0.22312212674630286 Seg acc:  0.9222946407965447 Disc loss:  0.014663048 Gen loss:  1.116276\n",
      "Epoch:  1239 Seg loss:  0.22305826786860428 Seg acc:  0.9223190607962312 Disc loss:  0.012796116 Gen loss:  1.1127547\n",
      "Epoch:  1240 Seg loss:  0.22300512642269174 Seg acc:  0.9223401497695852 Disc loss:  0.06936512 Gen loss:  1.0031623\n",
      "Epoch:  1240 F1 (val):  0.7047302111439364 Acc (val):  0.7626632653061225\n",
      "Epoch:  1241 Seg loss:  0.2229324952008069 Seg acc:  0.9223673716061768 Disc loss:  0.00564229 Gen loss:  1.1016814\n",
      "Epoch:  1242 Seg loss:  0.2228301374328693 Seg acc:  0.922401738473167 Disc loss:  0.011966555 Gen loss:  1.0607692\n",
      "Epoch:  1243 Seg loss:  0.22284764584906142 Seg acc:  0.9224009555551906 Disc loss:  0.029678198 Gen loss:  1.2487731\n",
      "Epoch:  1244 Seg loss:  0.22279421099943747 Seg acc:  0.9224200652929981 Disc loss:  0.04504835 Gen loss:  1.1223485\n",
      "Epoch:  1245 Seg loss:  0.22276875826728393 Seg acc:  0.9224336119990164 Disc loss:  0.018859245 Gen loss:  1.1894972\n",
      "Epoch:  1246 Seg loss:  0.2227728015490558 Seg acc:  0.9224235922298294 Disc loss:  0.01971152 Gen loss:  1.1416883\n",
      "Epoch:  1247 Seg loss:  0.22267418987481424 Seg acc:  0.9224667774086378 Disc loss:  0.008350369 Gen loss:  1.0511477\n",
      "Epoch:  1248 Seg loss:  0.22263219095288944 Seg acc:  0.922493540685505 Disc loss:  0.016060632 Gen loss:  1.1412672\n",
      "Epoch:  1249 Seg loss:  0.2225888799294364 Seg acc:  0.922517605921472 Disc loss:  0.04105196 Gen loss:  1.1011088\n",
      "Epoch:  1250 Seg loss:  0.2225725883603096 Seg acc:  0.9225238775510205 Disc loss:  0.0031480514 Gen loss:  1.1794382\n",
      "Epoch:  1250 F1 (val):  0.7146067718769769 Acc (val):  0.758265306122449\n",
      "Epoch:  1251 Seg loss:  0.22250975053802097 Seg acc:  0.9225542015367298 Disc loss:  0.010958748 Gen loss:  1.1407928\n",
      "Epoch:  1252 Seg loss:  0.2224114828775771 Seg acc:  0.9225997587533417 Disc loss:  0.008336414 Gen loss:  1.0765498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1253 Seg loss:  0.2223898662880051 Seg acc:  0.9226024887209472 Disc loss:  0.0059555434 Gen loss:  1.143716\n",
      "Epoch:  1254 Seg loss:  0.2223091460051434 Seg acc:  0.9226332877648667 Disc loss:  0.022017483 Gen loss:  1.0034703\n",
      "Epoch:  1255 Seg loss:  0.22230177669529896 Seg acc:  0.9226335474428816 Disc loss:  0.041069437 Gen loss:  1.1074088\n",
      "Epoch:  1256 Seg loss:  0.22225568682595992 Seg acc:  0.9226593981541661 Disc loss:  0.022830676 Gen loss:  1.1014444\n",
      "Epoch:  1257 Seg loss:  0.22222490889052124 Seg acc:  0.922676278148491 Disc loss:  0.0060348515 Gen loss:  1.1562295\n",
      "Epoch:  1258 Seg loss:  0.2221567748922896 Seg acc:  0.9226933340903929 Disc loss:  0.025238654 Gen loss:  0.99187165\n",
      "Epoch:  1259 Seg loss:  0.22208070776900948 Seg acc:  0.9227168468658313 Disc loss:  0.021393336 Gen loss:  1.0631372\n",
      "Epoch:  1260 Seg loss:  0.22204314440134026 Seg acc:  0.9227405247813412 Disc loss:  0.027846282 Gen loss:  1.0653603\n",
      "Epoch:  1260 F1 (val):  0.7427356766447697 Acc (val):  0.7719387755102041\n",
      "Epoch:  1261 Seg loss:  0.22201673882074718 Seg acc:  0.92274292349771 Disc loss:  0.014422766 Gen loss:  1.1242765\n",
      "Epoch:  1262 Seg loss:  0.22196697554124517 Seg acc:  0.9227576490184031 Disc loss:  0.03652492 Gen loss:  1.0268837\n",
      "Epoch:  1263 Seg loss:  0.22188945452041883 Seg acc:  0.9227899235703784 Disc loss:  0.03056277 Gen loss:  1.0386759\n",
      "Epoch:  1264 Seg loss:  0.2218327804032383 Seg acc:  0.9228108450658745 Disc loss:  0.029281806 Gen loss:  1.0940452\n",
      "Epoch:  1265 Seg loss:  0.22177011725224055 Seg acc:  0.9228397999516011 Disc loss:  0.02219032 Gen loss:  1.081726\n",
      "Epoch:  1266 Seg loss:  0.22173928285803274 Seg acc:  0.9228467453332043 Disc loss:  0.025403358 Gen loss:  1.1166406\n",
      "Epoch:  1267 Seg loss:  0.22170560872263106 Seg acc:  0.9228695858769713 Disc loss:  0.028528733 Gen loss:  1.094474\n",
      "Epoch:  1268 Seg loss:  0.2216188327852954 Seg acc:  0.9229016448850835 Disc loss:  0.03227202 Gen loss:  1.03852\n",
      "Epoch:  1269 Seg loss:  0.22154094569437893 Seg acc:  0.9229370708094113 Disc loss:  0.0069412035 Gen loss:  1.0947379\n",
      "Epoch:  1270 Seg loss:  0.22145181272442885 Seg acc:  0.9229746504901174 Disc loss:  0.057268564 Gen loss:  1.0441333\n",
      "Epoch:  1270 F1 (val):  0.6963163118346388 Acc (val):  0.763030612244898\n",
      "Epoch:  1271 Seg loss:  0.22139162471170598 Seg acc:  0.922996716389152 Disc loss:  0.005735508 Gen loss:  1.0893404\n",
      "Epoch:  1272 Seg loss:  0.22138724547558986 Seg acc:  0.9229964863303812 Disc loss:  0.003061411 Gen loss:  1.2013254\n",
      "Epoch:  1273 Seg loss:  0.22134242398197596 Seg acc:  0.9230110858168876 Disc loss:  0.027167303 Gen loss:  1.091543\n",
      "Epoch:  1274 Seg loss:  0.2212902718403463 Seg acc:  0.923031068785442 Disc loss:  0.105268076 Gen loss:  0.96839005\n",
      "Epoch:  1275 Seg loss:  0.2211970863330598 Seg acc:  0.9230690276110445 Disc loss:  0.0056005684 Gen loss:  1.0817521\n",
      "Epoch:  1276 Seg loss:  0.22112762856189172 Seg acc:  0.923098130317958 Disc loss:  0.07831301 Gen loss:  1.0164094\n",
      "Epoch:  1277 Seg loss:  0.22103479356390476 Seg acc:  0.9231333802119124 Disc loss:  0.051631078 Gen loss:  1.0293243\n",
      "Epoch:  1278 Seg loss:  0.22101165782164706 Seg acc:  0.9231306489732044 Disc loss:  0.0042617978 Gen loss:  1.1818253\n",
      "Epoch:  1279 Seg loss:  0.22092270978127168 Seg acc:  0.9231733975842096 Disc loss:  0.03886424 Gen loss:  1.004422\n",
      "Epoch:  1280 Seg loss:  0.22087779148714617 Seg acc:  0.9231903698979591 Disc loss:  0.031473584 Gen loss:  1.0501547\n",
      "Epoch:  1280 F1 (val):  0.7177838379296559 Acc (val):  0.7593673469387755\n",
      "Epoch:  1281 Seg loss:  0.22082940985177477 Seg acc:  0.9232083114276155 Disc loss:  0.035584237 Gen loss:  1.0669003\n",
      "Epoch:  1282 Seg loss:  0.22077108312880564 Seg acc:  0.9232363733324843 Disc loss:  0.014938626 Gen loss:  1.0654051\n",
      "Epoch:  1283 Seg loss:  0.2207130325997331 Seg acc:  0.92326021601158 Disc loss:  0.008448668 Gen loss:  1.099134\n",
      "Epoch:  1284 Seg loss:  0.22064719021877396 Seg acc:  0.9232879951045838 Disc loss:  0.05274929 Gen loss:  1.0268644\n",
      "Epoch:  1285 Seg loss:  0.2206061628310133 Seg acc:  0.9233189073294688 Disc loss:  0.010352507 Gen loss:  1.1361791\n",
      "Epoch:  1286 Seg loss:  0.2206069039264882 Seg acc:  0.9233190243437965 Disc loss:  0.0017664685 Gen loss:  1.195949\n",
      "Epoch:  1287 Seg loss:  0.22052565849767514 Seg acc:  0.9233520447806163 Disc loss:  0.011730896 Gen loss:  1.0969886\n",
      "Epoch:  1288 Seg loss:  0.2204909878291236 Seg acc:  0.9233685749144378 Disc loss:  0.031239687 Gen loss:  1.1142861\n",
      "Epoch:  1289 Seg loss:  0.22044806816464158 Seg acc:  0.9233823087031553 Disc loss:  0.018343916 Gen loss:  1.1443914\n",
      "Epoch:  1290 Seg loss:  0.22036801942790202 Seg acc:  0.9234201471286189 Disc loss:  0.07446261 Gen loss:  0.9417303\n",
      "Epoch:  1290 F1 (val):  0.7303233857221163 Acc (val):  0.7667448979591837\n",
      "Epoch:  1291 Seg loss:  0.22030779435411155 Seg acc:  0.9234387597021769 Disc loss:  0.08030733 Gen loss:  0.968274\n",
      "Epoch:  1292 Seg loss:  0.2202541958713679 Seg acc:  0.9234642541227017 Disc loss:  0.044339765 Gen loss:  1.133307\n",
      "Epoch:  1293 Seg loss:  0.22019332804056627 Seg acc:  0.923480633552725 Disc loss:  0.038499884 Gen loss:  1.0647471\n",
      "Epoch:  1294 Seg loss:  0.22016982179152358 Seg acc:  0.9234930448222566 Disc loss:  0.046613764 Gen loss:  1.171499\n",
      "Epoch:  1295 Seg loss:  0.22010954807163666 Seg acc:  0.923520999133244 Disc loss:  0.1084098 Gen loss:  0.9982851\n",
      "Epoch:  1296 Seg loss:  0.220091439128198 Seg acc:  0.92352450239355 Disc loss:  0.034175158 Gen loss:  1.0893145\n",
      "Epoch:  1297 Seg loss:  0.22003671958893192 Seg acc:  0.9235457020124934 Disc loss:  0.037073404 Gen loss:  1.0426446\n",
      "Epoch:  1298 Seg loss:  0.21996192550875004 Seg acc:  0.92357315807679 Disc loss:  0.03786939 Gen loss:  1.0453912\n",
      "Epoch:  1299 Seg loss:  0.2199060126129621 Seg acc:  0.9235907526983079 Disc loss:  0.013210868 Gen loss:  1.1351718\n",
      "Epoch:  1300 Seg loss:  0.21981956557585644 Seg acc:  0.9236257849293563 Disc loss:  0.01780826 Gen loss:  1.0587997\n",
      "Epoch:  1300 F1 (val):  0.7366473096343366 Acc (val):  0.7713061224489796\n",
      "Epoch:  1301 Seg loss:  0.21976412864807107 Seg acc:  0.9236519396382687 Disc loss:  0.016808111 Gen loss:  1.1036843\n",
      "Epoch:  1302 Seg loss:  0.21966936434697812 Seg acc:  0.923691377472648 Disc loss:  0.022030598 Gen loss:  1.0471814\n",
      "Epoch:  1303 Seg loss:  0.21961601708636133 Seg acc:  0.9237078484502012 Disc loss:  0.027931545 Gen loss:  1.0661747\n",
      "Epoch:  1304 Seg loss:  0.21952300285063456 Seg acc:  0.9237458135094527 Disc loss:  0.016357102 Gen loss:  1.0794767\n",
      "Epoch:  1305 Seg loss:  0.21948097573728853 Seg acc:  0.9237610446477442 Disc loss:  0.0038997927 Gen loss:  1.1327565\n",
      "Epoch:  1306 Seg loss:  0.2194128583540504 Seg acc:  0.9237899256180266 Disc loss:  0.012157312 Gen loss:  1.0755764\n",
      "Epoch:  1307 Seg loss:  0.21931537454513164 Seg acc:  0.9238294973689551 Disc loss:  0.022321947 Gen loss:  1.0770361\n",
      "Epoch:  1308 Seg loss:  0.21925742227003114 Seg acc:  0.9238543812020221 Disc loss:  0.018370941 Gen loss:  1.0825715\n",
      "Epoch:  1309 Seg loss:  0.21923651724393536 Seg acc:  0.9238704572738186 Disc loss:  0.008580969 Gen loss:  1.170438\n",
      "Epoch:  1310 Seg loss:  0.21913209842475315 Seg acc:  0.9239118242716933 Disc loss:  0.013838217 Gen loss:  1.0213203\n",
      "Epoch:  1310 F1 (val):  0.7359517060413733 Acc (val):  0.7750612244897959\n",
      "Epoch:  1311 Seg loss:  0.2191002085964067 Seg acc:  0.9239184918818786 Disc loss:  0.026008334 Gen loss:  1.1265309\n",
      "Epoch:  1312 Seg loss:  0.2190232353864192 Seg acc:  0.9239401210179192 Disc loss:  0.019893192 Gen loss:  1.0772206\n",
      "Epoch:  1313 Seg loss:  0.2190200538407821 Seg acc:  0.923932185212242 Disc loss:  0.020476555 Gen loss:  1.1482134\n",
      "Epoch:  1314 Seg loss:  0.21896019571742872 Seg acc:  0.9239537710061194 Disc loss:  0.036325917 Gen loss:  1.0960804\n",
      "Epoch:  1315 Seg loss:  0.2189214178534515 Seg acc:  0.9239652362846279 Disc loss:  0.024567636 Gen loss:  1.1359547\n",
      "Epoch:  1316 Seg loss:  0.21883244749079359 Seg acc:  0.9240014964952546 Disc loss:  0.040613994 Gen loss:  1.0302031\n",
      "Epoch:  1317 Seg loss:  0.21885344966533243 Seg acc:  0.92398811460803 Disc loss:  0.05273507 Gen loss:  1.1763939\n",
      "Epoch:  1318 Seg loss:  0.2188714760863003 Seg acc:  0.9239977857607382 Disc loss:  0.01223064 Gen loss:  1.2081132\n",
      "Epoch:  1319 Seg loss:  0.21884288558054368 Seg acc:  0.924014598257802 Disc loss:  0.007075631 Gen loss:  1.1361241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1320 Seg loss:  0.21885757480155338 Seg acc:  0.9240097402597403 Disc loss:  0.002617044 Gen loss:  1.2155126\n",
      "Epoch:  1320 F1 (val):  0.7206925196413041 Acc (val):  0.7566224489795919\n",
      "Epoch:  1321 Seg loss:  0.2189289940567652 Seg acc:  0.9239824885290981 Disc loss:  0.016246116 Gen loss:  1.260541\n",
      "Epoch:  1322 Seg loss:  0.21888830838513626 Seg acc:  0.9239909768748649 Disc loss:  0.03326319 Gen loss:  1.1583585\n",
      "Epoch:  1323 Seg loss:  0.2188502569159863 Seg acc:  0.9240112144631096 Disc loss:  0.0022578267 Gen loss:  1.1444073\n",
      "Epoch:  1324 Seg loss:  0.2188433598265547 Seg acc:  0.9240162001356435 Disc loss:  0.0060111536 Gen loss:  1.1769917\n",
      "Epoch:  1325 Seg loss:  0.2188465846034716 Seg acc:  0.9240090489025797 Disc loss:  0.01787179 Gen loss:  1.1891625\n",
      "Epoch:  1326 Seg loss:  0.21877512583568084 Seg acc:  0.9240328823837226 Disc loss:  0.002825966 Gen loss:  1.0907724\n",
      "Epoch:  1327 Seg loss:  0.21866151236261563 Seg acc:  0.9240793642249666 Disc loss:  0.004768485 Gen loss:  1.0498377\n",
      "Epoch:  1328 Seg loss:  0.218625680762287 Seg acc:  0.9240846677526432 Disc loss:  0.008442224 Gen loss:  1.1258146\n",
      "Epoch:  1329 Seg loss:  0.21859097474607156 Seg acc:  0.9240980252146005 Disc loss:  0.0047070095 Gen loss:  1.1374698\n",
      "Epoch:  1330 Seg loss:  0.2185907804484206 Seg acc:  0.9240985115850853 Disc loss:  0.0478727 Gen loss:  1.1540843\n",
      "Epoch:  1330 F1 (val):  0.7422322189315355 Acc (val):  0.7699897959183674\n",
      "Epoch:  1331 Seg loss:  0.2185777419664464 Seg acc:  0.9241093469694415 Disc loss:  0.015904643 Gen loss:  1.139059\n",
      "Epoch:  1332 Seg loss:  0.21851877010687515 Seg acc:  0.9241377857449286 Disc loss:  0.0040016472 Gen loss:  1.1059644\n",
      "Epoch:  1333 Seg loss:  0.2185137142040903 Seg acc:  0.924131543089854 Disc loss:  0.0023028008 Gen loss:  1.2093232\n",
      "Epoch:  1334 Seg loss:  0.2184896146350804 Seg acc:  0.9241404170363798 Disc loss:  0.019631326 Gen loss:  1.1147101\n",
      "Epoch:  1335 Seg loss:  0.21845840879259038 Seg acc:  0.9241567301077734 Disc loss:  0.002461342 Gen loss:  1.1544433\n",
      "Epoch:  1336 Seg loss:  0.21844261513833335 Seg acc:  0.924166335695955 Disc loss:  0.0031833458 Gen loss:  1.1575948\n",
      "Epoch:  1337 Seg loss:  0.2183937817956854 Seg acc:  0.9241835589882925 Disc loss:  0.002687539 Gen loss:  1.1340718\n",
      "Epoch:  1338 Seg loss:  0.21833233679512512 Seg acc:  0.9242066669717214 Disc loss:  0.023620818 Gen loss:  1.0761322\n",
      "Epoch:  1339 Seg loss:  0.218315242146315 Seg acc:  0.9242164042614807 Disc loss:  0.0019076774 Gen loss:  1.1526294\n",
      "Epoch:  1340 Seg loss:  0.21830405216497273 Seg acc:  0.9242179409077065 Disc loss:  0.011824893 Gen loss:  1.1312934\n",
      "Epoch:  1340 F1 (val):  0.7161347430472459 Acc (val):  0.7647857142857143\n",
      "Epoch:  1341 Seg loss:  0.21828431541643242 Seg acc:  0.9242208068909891 Disc loss:  0.0017960039 Gen loss:  1.1767331\n",
      "Epoch:  1342 Seg loss:  0.21820350737489994 Seg acc:  0.9242580750631101 Disc loss:  0.008347857 Gen loss:  1.0649168\n",
      "Epoch:  1343 Seg loss:  0.2181802046050443 Seg acc:  0.9242590074004284 Disc loss:  0.0071369 Gen loss:  1.1762741\n",
      "Epoch:  1344 Seg loss:  0.21813057543754222 Seg acc:  0.9242732249149659 Disc loss:  0.01037909 Gen loss:  1.1064844\n",
      "Epoch:  1345 Seg loss:  0.21804204960405604 Seg acc:  0.924308094985206 Disc loss:  0.004083954 Gen loss:  1.0795615\n",
      "Epoch:  1346 Seg loss:  0.21801414754225099 Seg acc:  0.9243046289838371 Disc loss:  0.011021955 Gen loss:  1.1704243\n",
      "Epoch:  1347 Seg loss:  0.21795760053635174 Seg acc:  0.9243201066618183 Disc loss:  0.020240655 Gen loss:  1.1151657\n",
      "Epoch:  1348 Seg loss:  0.21792248601663183 Seg acc:  0.9243372645794224 Disc loss:  0.040804602 Gen loss:  1.1697001\n",
      "Epoch:  1349 Seg loss:  0.21794245228602147 Seg acc:  0.9243324609309995 Disc loss:  0.009836109 Gen loss:  1.1996812\n",
      "Epoch:  1350 Seg loss:  0.2179109476837847 Seg acc:  0.9243386243386242 Disc loss:  0.030154273 Gen loss:  1.1111519\n",
      "Epoch:  1350 F1 (val):  0.7206314305491983 Acc (val):  0.7635\n",
      "Epoch:  1351 Seg loss:  0.21787657446436842 Seg acc:  0.9243561080983095 Disc loss:  0.043178268 Gen loss:  1.1586604\n",
      "Epoch:  1352 Seg loss:  0.21778518003384037 Seg acc:  0.9243924344885883 Disc loss:  0.014483529 Gen loss:  1.0755897\n",
      "Epoch:  1353 Seg loss:  0.2177568799860814 Seg acc:  0.9244023108134606 Disc loss:  0.041559104 Gen loss:  1.073885\n",
      "Epoch:  1354 Seg loss:  0.21768021603916912 Seg acc:  0.9244377957977872 Disc loss:  0.016650956 Gen loss:  1.014489\n",
      "Epoch:  1355 Seg loss:  0.2175880945696602 Seg acc:  0.924471910535432 Disc loss:  0.016841754 Gen loss:  1.0721767\n",
      "Epoch:  1356 Seg loss:  0.2175446944009062 Seg acc:  0.9244978854373607 Disc loss:  0.0150551535 Gen loss:  1.084278\n",
      "Epoch:  1357 Seg loss:  0.21749861032187984 Seg acc:  0.9245183703547741 Disc loss:  0.014398412 Gen loss:  1.1297061\n",
      "Epoch:  1358 Seg loss:  0.21747460962439144 Seg acc:  0.9245318746055121 Disc loss:  0.028258638 Gen loss:  1.1779704\n",
      "Epoch:  1359 Seg loss:  0.21739572789341846 Seg acc:  0.9245611268790076 Disc loss:  0.013567769 Gen loss:  1.0928353\n",
      "Epoch:  1360 Seg loss:  0.21732792367282158 Seg acc:  0.924590523709484 Disc loss:  0.0007804996 Gen loss:  1.1090226\n",
      "Epoch:  1360 F1 (val):  0.7225271940703041 Acc (val):  0.7635510204081633\n",
      "Epoch:  1361 Seg loss:  0.21728567089844417 Seg acc:  0.9246060069876592 Disc loss:  0.072827145 Gen loss:  1.0581137\n",
      "Epoch:  1362 Seg loss:  0.21728103333829782 Seg acc:  0.9246229659264588 Disc loss:  0.004182484 Gen loss:  1.1891693\n",
      "Epoch:  1363 Seg loss:  0.2172589850825854 Seg acc:  0.9246421459266025 Disc loss:  0.048272356 Gen loss:  1.0940605\n",
      "Epoch:  1364 Seg loss:  0.21721381742692938 Seg acc:  0.9246569962295769 Disc loss:  0.019767625 Gen loss:  1.089644\n",
      "Epoch:  1365 Seg loss:  0.21720346067742113 Seg acc:  0.9246632279285341 Disc loss:  0.013536883 Gen loss:  1.1910218\n",
      "Epoch:  1366 Seg loss:  0.2171308076715487 Seg acc:  0.9246948486568859 Disc loss:  0.048585005 Gen loss:  1.0581006\n",
      "Epoch:  1367 Seg loss:  0.21706026508564835 Seg acc:  0.9247254900497142 Disc loss:  0.008515718 Gen loss:  1.1031538\n",
      "Epoch:  1368 Seg loss:  0.21698811420985656 Seg acc:  0.9247566460794845 Disc loss:  0.058681868 Gen loss:  1.0551137\n",
      "Epoch:  1369 Seg loss:  0.21697989917633045 Seg acc:  0.9247607370194243 Disc loss:  0.019634103 Gen loss:  1.1237786\n",
      "Epoch:  1370 Seg loss:  0.21693687438421005 Seg acc:  0.9247746908982571 Disc loss:  0.012389425 Gen loss:  1.1086056\n",
      "Epoch:  1370 F1 (val):  0.716121406308896 Acc (val):  0.7402448979591837\n",
      "Epoch:  1371 Seg loss:  0.2169460454870105 Seg acc:  0.9247700174161568 Disc loss:  0.014616303 Gen loss:  1.1617155\n",
      "Epoch:  1372 Seg loss:  0.21691980539297048 Seg acc:  0.924786733206402 Disc loss:  0.0014623471 Gen loss:  1.1603987\n",
      "Epoch:  1373 Seg loss:  0.21697045708019544 Seg acc:  0.9247748115998038 Disc loss:  0.012329371 Gen loss:  1.279556\n",
      "Epoch:  1374 Seg loss:  0.2169564927520103 Seg acc:  0.9247760894750914 Disc loss:  0.001597232 Gen loss:  1.1882206\n",
      "Epoch:  1375 Seg loss:  0.21693701833486556 Seg acc:  0.924778293135436 Disc loss:  0.004499271 Gen loss:  1.1722659\n",
      "Epoch:  1376 Seg loss:  0.21683644895918322 Seg acc:  0.9248188701352634 Disc loss:  0.03766061 Gen loss:  1.07471\n",
      "Epoch:  1377 Seg loss:  0.21679578564070928 Seg acc:  0.9248410475301232 Disc loss:  0.08654088 Gen loss:  1.0815128\n",
      "Epoch:  1378 Seg loss:  0.21678583974394466 Seg acc:  0.9248424587541839 Disc loss:  0.015787037 Gen loss:  1.1902115\n",
      "Epoch:  1379 Seg loss:  0.21667567729150325 Seg acc:  0.9248880806855013 Disc loss:  0.017530479 Gen loss:  1.0400462\n",
      "Epoch:  1380 Seg loss:  0.21663343473944974 Seg acc:  0.9249029503105591 Disc loss:  0.0025093106 Gen loss:  1.1326206\n",
      "Epoch:  1380 F1 (val):  0.7120083605057188 Acc (val):  0.7615102040816326\n",
      "Epoch:  1381 Seg loss:  0.2166210076812814 Seg acc:  0.9249107789386574 Disc loss:  0.0011593903 Gen loss:  1.1872652\n",
      "Epoch:  1382 Seg loss:  0.21660482521706656 Seg acc:  0.9249128739773768 Disc loss:  0.022720251 Gen loss:  1.132417\n",
      "Epoch:  1383 Seg loss:  0.21652909947945773 Seg acc:  0.924945770065076 Disc loss:  0.00085537083 Gen loss:  1.0940092\n",
      "Epoch:  1384 Seg loss:  0.2164756920823903 Seg acc:  0.9249682965671818 Disc loss:  0.013553415 Gen loss:  1.1353195\n",
      "Epoch:  1385 Seg loss:  0.21641569168236283 Seg acc:  0.9249939217564283 Disc loss:  0.0011329161 Gen loss:  1.1093892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1386 Seg loss:  0.21634214137066665 Seg acc:  0.925016381011279 Disc loss:  0.04072582 Gen loss:  1.0319455\n",
      "Epoch:  1387 Seg loss:  0.21636768407373008 Seg acc:  0.9250191280549712 Disc loss:  0.012777419 Gen loss:  1.207924\n",
      "Epoch:  1388 Seg loss:  0.21630086308554544 Seg acc:  0.9250452126095394 Disc loss:  0.00052026554 Gen loss:  1.1122822\n",
      "Epoch:  1389 Seg loss:  0.21628153876618056 Seg acc:  0.9250571178795493 Disc loss:  0.002100414 Gen loss:  1.1773248\n",
      "Epoch:  1390 Seg loss:  0.2162277518202075 Seg acc:  0.925084972838056 Disc loss:  0.03417029 Gen loss:  1.1092684\n",
      "Epoch:  1390 F1 (val):  0.7198587910409083 Acc (val):  0.7606224489795919\n",
      "Epoch:  1391 Seg loss:  0.21615568132793878 Seg acc:  0.9251162722457783 Disc loss:  0.00085670484 Gen loss:  1.1046573\n",
      "Epoch:  1392 Seg loss:  0.21606630942752136 Seg acc:  0.9251511919422941 Disc loss:  0.012409298 Gen loss:  1.0337924\n",
      "Epoch:  1393 Seg loss:  0.2160082119654086 Seg acc:  0.9251697628082101 Disc loss:  0.030771779 Gen loss:  1.055579\n",
      "Epoch:  1394 Seg loss:  0.21592476719207368 Seg acc:  0.9252077050332328 Disc loss:  0.00095202215 Gen loss:  1.0846573\n",
      "Epoch:  1395 Seg loss:  0.21591713010837527 Seg acc:  0.9252150537634408 Disc loss:  0.007748426 Gen loss:  1.1758244\n",
      "Epoch:  1396 Seg loss:  0.21581644647058237 Seg acc:  0.9252572948950353 Disc loss:  0.049794037 Gen loss:  0.98454\n",
      "Epoch:  1397 Seg loss:  0.21577599830258806 Seg acc:  0.9252813974551882 Disc loss:  0.0017921953 Gen loss:  1.1453995\n",
      "Epoch:  1398 Seg loss:  0.21574804776258905 Seg acc:  0.9252852106507838 Disc loss:  0.0073253224 Gen loss:  1.1540661\n",
      "Epoch:  1399 Seg loss:  0.2157071839067406 Seg acc:  0.9252966769266677 Disc loss:  0.0044315616 Gen loss:  1.1365246\n",
      "Epoch:  1400 Seg loss:  0.21568300474967275 Seg acc:  0.9252997448979592 Disc loss:  0.013977291 Gen loss:  1.1001889\n",
      "Epoch:  1400 F1 (val):  0.7319836953109804 Acc (val):  0.7647448979591837\n",
      "Epoch:  1401 Seg loss:  0.21560815332469388 Seg acc:  0.9253275721423472 Disc loss:  0.031951502 Gen loss:  1.0544041\n",
      "Epoch:  1402 Seg loss:  0.21551893778496053 Seg acc:  0.9253650033479869 Disc loss:  0.0010111809 Gen loss:  1.0658143\n",
      "Epoch:  1403 Seg loss:  0.21550068563528768 Seg acc:  0.9253754709296406 Disc loss:  0.016863417 Gen loss:  1.1238866\n",
      "Epoch:  1404 Seg loss:  0.21546195120022676 Seg acc:  0.9253910111052969 Disc loss:  0.04263506 Gen loss:  1.0947391\n",
      "Epoch:  1405 Seg loss:  0.2153947955825999 Seg acc:  0.9254156075241485 Disc loss:  0.024000341 Gen loss:  1.0698823\n",
      "Epoch:  1406 Seg loss:  0.2153224935000007 Seg acc:  0.9254427090893256 Disc loss:  0.050939947 Gen loss:  1.0545663\n",
      "Epoch:  1407 Seg loss:  0.21535569760887524 Seg acc:  0.925421906502473 Disc loss:  0.00068958773 Gen loss:  1.2332666\n",
      "Epoch:  1408 Seg loss:  0.21529456035403366 Seg acc:  0.9254404496173468 Disc loss:  0.017929334 Gen loss:  1.0794196\n",
      "Epoch:  1409 Seg loss:  0.2152137563499768 Seg acc:  0.9254674758476846 Disc loss:  0.0019662264 Gen loss:  1.0898578\n",
      "Epoch:  1410 Seg loss:  0.21512733451652188 Seg acc:  0.9254991677522073 Disc loss:  0.007462862 Gen loss:  1.0457067\n",
      "Epoch:  1410 F1 (val):  0.7270026950368264 Acc (val):  0.768673469387755\n",
      "Epoch:  1411 Seg loss:  0.21514199034150486 Seg acc:  0.9254988139834247 Disc loss:  0.008209228 Gen loss:  1.1891525\n",
      "Epoch:  1412 Seg loss:  0.21520881630248118 Seg acc:  0.925470999306238 Disc loss:  0.005609438 Gen loss:  1.3034875\n",
      "Epoch:  1413 Seg loss:  0.21517430980915897 Seg acc:  0.9254952193191502 Disc loss:  0.009502915 Gen loss:  1.1498083\n",
      "Epoch:  1414 Seg loss:  0.21511284725627267 Seg acc:  0.9255176009583466 Disc loss:  0.0819543 Gen loss:  1.0676336\n",
      "Epoch:  1415 Seg loss:  0.21507704188461438 Seg acc:  0.9255397706785895 Disc loss:  0.022758607 Gen loss:  1.1137681\n",
      "Epoch:  1416 Seg loss:  0.21506489011443267 Seg acc:  0.9255527210884353 Disc loss:  0.0043326537 Gen loss:  1.1908095\n",
      "Epoch:  1417 Seg loss:  0.21507756067104716 Seg acc:  0.9255544913801793 Disc loss:  0.0016437955 Gen loss:  1.2057736\n",
      "Epoch:  1418 Seg loss:  0.21501541246984507 Seg acc:  0.9255785671109065 Disc loss:  0.0037283453 Gen loss:  1.069379\n",
      "Epoch:  1419 Seg loss:  0.21495982524666507 Seg acc:  0.9255966763026564 Disc loss:  0.043111186 Gen loss:  1.0434873\n",
      "Epoch:  1420 Seg loss:  0.21489699685447652 Seg acc:  0.9256217663121586 Disc loss:  0.022441061 Gen loss:  1.0792224\n",
      "Epoch:  1420 F1 (val):  0.733299477199868 Acc (val):  0.7643265306122449\n",
      "Epoch:  1421 Seg loss:  0.21489642783842147 Seg acc:  0.925630843470393 Disc loss:  0.052286144 Gen loss:  1.1530545\n",
      "Epoch:  1422 Seg loss:  0.21482384699474072 Seg acc:  0.9256709434828783 Disc loss:  0.0050719567 Gen loss:  1.0858822\n",
      "Epoch:  1423 Seg loss:  0.2147660021076551 Seg acc:  0.9256805111362887 Disc loss:  0.0057958555 Gen loss:  1.1252697\n",
      "Epoch:  1424 Seg loss:  0.21470815935329104 Seg acc:  0.9257067258083009 Disc loss:  0.02790931 Gen loss:  1.076566\n",
      "Epoch:  1425 Seg loss:  0.21470004357789693 Seg acc:  0.9257019334049408 Disc loss:  0.0013812071 Gen loss:  1.1946841\n",
      "Epoch:  1426 Seg loss:  0.21461971927575277 Seg acc:  0.9257311374760282 Disc loss:  0.027533028 Gen loss:  1.0488997\n",
      "Epoch:  1427 Seg loss:  0.2146033189705225 Seg acc:  0.9257392059837248 Disc loss:  0.014819631 Gen loss:  1.1282991\n",
      "Epoch:  1428 Seg loss:  0.21453513945935487 Seg acc:  0.9257674498370776 Disc loss:  0.04997312 Gen loss:  1.0212084\n",
      "Epoch:  1429 Seg loss:  0.21449792934640294 Seg acc:  0.9257876208566002 Disc loss:  0.0016835695 Gen loss:  1.1539798\n",
      "Epoch:  1430 Seg loss:  0.21447401491703688 Seg acc:  0.9257824318538604 Disc loss:  0.0029863375 Gen loss:  1.1484807\n",
      "Epoch:  1430 F1 (val):  0.7291093516082099 Acc (val):  0.764234693877551\n",
      "Epoch:  1431 Seg loss:  0.21446587522283123 Seg acc:  0.9257842025699168 Disc loss:  0.027033804 Gen loss:  1.1510386\n",
      "Epoch:  1432 Seg loss:  0.21443719213942908 Seg acc:  0.9257866833884392 Disc loss:  0.002760963 Gen loss:  1.1593678\n",
      "Epoch:  1433 Seg loss:  0.21432405046531144 Seg acc:  0.9258320634604156 Disc loss:  0.010270014 Gen loss:  1.0407052\n",
      "Epoch:  1434 Seg loss:  0.21431105287493604 Seg acc:  0.9258250789855692 Disc loss:  0.0474103 Gen loss:  1.1374896\n",
      "Epoch:  1435 Seg loss:  0.21424765863329276 Seg acc:  0.925850103107445 Disc loss:  0.021872915 Gen loss:  1.067898\n",
      "Epoch:  1436 Seg loss:  0.21413335625943533 Seg acc:  0.9258958771530897 Disc loss:  0.16014609 Gen loss:  0.9414613\n",
      "Epoch:  1437 Seg loss:  0.2141235375734112 Seg acc:  0.9259051950634117 Disc loss:  0.000530425 Gen loss:  1.1891516\n",
      "Epoch:  1438 Seg loss:  0.21407233056857125 Seg acc:  0.925929933865062 Disc loss:  0.023574226 Gen loss:  1.0793791\n",
      "Epoch:  1439 Seg loss:  0.21403341833566775 Seg acc:  0.9259484335777397 Disc loss:  0.001141372 Gen loss:  1.1495216\n",
      "Epoch:  1440 Seg loss:  0.2140134665545904 Seg acc:  0.9259591128117916 Disc loss:  0.043061003 Gen loss:  1.1794059\n",
      "Epoch:  1440 F1 (val):  0.7269073008096834 Acc (val):  0.7662551020408164\n",
      "Epoch:  1441 Seg loss:  0.21402127215073888 Seg acc:  0.925954906598309 Disc loss:  0.0006878759 Gen loss:  1.2176865\n",
      "Epoch:  1442 Seg loss:  0.2139651410322993 Seg acc:  0.9259724659628069 Disc loss:  0.016996833 Gen loss:  1.076135\n",
      "Epoch:  1443 Seg loss:  0.21390655187067684 Seg acc:  0.9260007849293566 Disc loss:  0.011544355 Gen loss:  1.1228627\n",
      "Epoch:  1444 Seg loss:  0.21396294197485552 Seg acc:  0.9259900220476003 Disc loss:  0.037182953 Gen loss:  1.2833169\n",
      "Epoch:  1445 Seg loss:  0.21386893291065023 Seg acc:  0.9260285290586824 Disc loss:  0.018337365 Gen loss:  1.0266789\n",
      "Epoch:  1446 Seg loss:  0.21387612034938971 Seg acc:  0.9260248186411495 Disc loss:  0.0021241207 Gen loss:  1.2184151\n",
      "Epoch:  1447 Seg loss:  0.21380879213543044 Seg acc:  0.9260521416583221 Disc loss:  0.0012756757 Gen loss:  1.1015393\n",
      "Epoch:  1448 Seg loss:  0.2137388498290797 Seg acc:  0.9260790745856354 Disc loss:  0.019057002 Gen loss:  1.0610833\n",
      "Epoch:  1449 Seg loss:  0.21365218378186968 Seg acc:  0.9261072027154549 Disc loss:  0.008494526 Gen loss:  1.074098\n",
      "Epoch:  1450 Seg loss:  0.21360495114634778 Seg acc:  0.9261259676284307 Disc loss:  0.020046523 Gen loss:  1.1221939\n",
      "Epoch:  1450 F1 (val):  0.7433636418416819 Acc (val):  0.7669489795918367\n",
      "Epoch:  1451 Seg loss:  0.21355431946925177 Seg acc:  0.9261526181802839 Disc loss:  0.023233317 Gen loss:  1.1208254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1452 Seg loss:  0.21349740839632583 Seg acc:  0.926180637544274 Disc loss:  0.014843846 Gen loss:  1.085211\n",
      "Epoch:  1453 Seg loss:  0.21341351727863386 Seg acc:  0.9262154655392786 Disc loss:  0.0019645842 Gen loss:  1.0769287\n",
      "Epoch:  1454 Seg loss:  0.21342434322120726 Seg acc:  0.9262100679336385 Disc loss:  0.00015491835 Gen loss:  1.2247095\n",
      "Epoch:  1455 Seg loss:  0.21333550249075972 Seg acc:  0.9262425485658182 Disc loss:  0.00029882442 Gen loss:  1.0768075\n",
      "Epoch:  1456 Seg loss:  0.21333283230478128 Seg acc:  0.9262429216191972 Disc loss:  0.00026138258 Gen loss:  1.2015201\n",
      "Epoch:  1457 Seg loss:  0.2133125687298009 Seg acc:  0.9262552000896447 Disc loss:  0.0050138067 Gen loss:  1.1631168\n",
      "Epoch:  1458 Seg loss:  0.21326024410799044 Seg acc:  0.9262809341843734 Disc loss:  0.047051165 Gen loss:  1.1295507\n",
      "Epoch:  1459 Seg loss:  0.21324199552994383 Seg acc:  0.9262945685470899 Disc loss:  0.014509201 Gen loss:  1.1344279\n",
      "Epoch:  1460 Seg loss:  0.21321833146455355 Seg acc:  0.9262980500419347 Disc loss:  0.01162677 Gen loss:  1.1289358\n",
      "Epoch:  1460 F1 (val):  0.7268704848310856 Acc (val):  0.7614897959183673\n",
      "Epoch:  1461 Seg loss:  0.21315509181349837 Seg acc:  0.9263264956906788 Disc loss:  0.0012273291 Gen loss:  1.112077\n",
      "Epoch:  1462 Seg loss:  0.21311531365223524 Seg acc:  0.9263390239816859 Disc loss:  0.0007020476 Gen loss:  1.1411648\n",
      "Epoch:  1463 Seg loss:  0.21303478199084655 Seg acc:  0.9263712388578125 Disc loss:  0.0105586415 Gen loss:  1.0749952\n",
      "Epoch:  1464 Seg loss:  0.21298142831996492 Seg acc:  0.9263931289729006 Disc loss:  0.096195854 Gen loss:  1.120069\n",
      "Epoch:  1465 Seg loss:  0.2128738903500928 Seg acc:  0.9264371038517797 Disc loss:  0.0016249726 Gen loss:  1.0392516\n",
      "Epoch:  1466 Seg loss:  0.2128340835857115 Seg acc:  0.9264559609655595 Disc loss:  0.018989246 Gen loss:  1.1460757\n",
      "Epoch:  1467 Seg loss:  0.21275859650150805 Seg acc:  0.9264847043111724 Disc loss:  0.004490038 Gen loss:  1.0884192\n",
      "Epoch:  1468 Seg loss:  0.21269900025419222 Seg acc:  0.9265069788133238 Disc loss:  0.0010195455 Gen loss:  1.1167879\n",
      "Epoch:  1469 Seg loss:  0.2126150878413832 Seg acc:  0.9265391214348231 Disc loss:  0.0037866828 Gen loss:  1.0847338\n",
      "Epoch:  1470 Seg loss:  0.21259505487218194 Seg acc:  0.9265434541163405 Disc loss:  0.031073252 Gen loss:  1.134181\n",
      "Epoch:  1470 F1 (val):  0.7230210907181429 Acc (val):  0.7538367346938776\n",
      "Epoch:  1471 Seg loss:  0.21254609146343453 Seg acc:  0.926564082465073 Disc loss:  0.023428885 Gen loss:  1.0688097\n",
      "Epoch:  1472 Seg loss:  0.2125322657191883 Seg acc:  0.9265694321206743 Disc loss:  0.010004855 Gen loss:  1.185435\n",
      "Epoch:  1473 Seg loss:  0.21250593858516226 Seg acc:  0.9265733890297463 Disc loss:  0.024772013 Gen loss:  1.1583171\n",
      "Epoch:  1474 Seg loss:  0.2125081308843161 Seg acc:  0.9265673026334008 Disc loss:  0.01601768 Gen loss:  1.19476\n",
      "Epoch:  1475 Seg loss:  0.2124946187613374 Seg acc:  0.9265733310273262 Disc loss:  0.03878095 Gen loss:  1.128409\n",
      "Epoch:  1476 Seg loss:  0.21243365432532016 Seg acc:  0.9265993999225706 Disc loss:  0.0068937717 Gen loss:  1.1067629\n",
      "Epoch:  1477 Seg loss:  0.21238886259279302 Seg acc:  0.9266136888065992 Disc loss:  0.01353818 Gen loss:  1.0924724\n",
      "Epoch:  1478 Seg loss:  0.2123425264208904 Seg acc:  0.9266321007428683 Disc loss:  0.0060127433 Gen loss:  1.115469\n",
      "Epoch:  1479 Seg loss:  0.2122738009534066 Seg acc:  0.9266604917829201 Disc loss:  0.006838778 Gen loss:  1.0988659\n",
      "Epoch:  1480 Seg loss:  0.21225136122792154 Seg acc:  0.926669194704909 Disc loss:  0.0053819222 Gen loss:  1.1640096\n",
      "Epoch:  1480 F1 (val):  0.7183349053269665 Acc (val):  0.7612142857142857\n",
      "Epoch:  1481 Seg loss:  0.21218482150893048 Seg acc:  0.9266956276095853 Disc loss:  0.028092038 Gen loss:  1.060391\n",
      "Epoch:  1482 Seg loss:  0.21212998617757187 Seg acc:  0.9267127296262634 Disc loss:  0.0010882885 Gen loss:  1.1176817\n",
      "Epoch:  1483 Seg loss:  0.21205722144223996 Seg acc:  0.9267432259485049 Disc loss:  0.020075733 Gen loss:  1.0333256\n",
      "Epoch:  1484 Seg loss:  0.21203234368016458 Seg acc:  0.9267513339567633 Disc loss:  0.012816346 Gen loss:  1.1699414\n",
      "Epoch:  1485 Seg loss:  0.2119671783864699 Seg acc:  0.9267784992784993 Disc loss:  0.023763193 Gen loss:  1.1090996\n",
      "Epoch:  1486 Seg loss:  0.2119324547044361 Seg acc:  0.9267960145027054 Disc loss:  0.0065732407 Gen loss:  1.1340122\n",
      "Epoch:  1487 Seg loss:  0.21185569235179436 Seg acc:  0.9268268874463033 Disc loss:  0.00025202092 Gen loss:  1.0922823\n",
      "Epoch:  1488 Seg loss:  0.21185742118846504 Seg acc:  0.9268251453807328 Disc loss:  0.013372533 Gen loss:  1.1663206\n",
      "Epoch:  1489 Seg loss:  0.21182656217594129 Seg acc:  0.9268386535272268 Disc loss:  0.006004592 Gen loss:  1.1627761\n",
      "Epoch:  1490 Seg loss:  0.21181239079208983 Seg acc:  0.9268399876729214 Disc loss:  0.0038437236 Gen loss:  1.1489533\n",
      "Epoch:  1490 F1 (val):  0.7259793866245263 Acc (val):  0.755704081632653\n",
      "Epoch:  1491 Seg loss:  0.21186765270353883 Seg acc:  0.9268281457452198 Disc loss:  0.030980721 Gen loss:  1.2403363\n",
      "Epoch:  1492 Seg loss:  0.2117958117436228 Seg acc:  0.9268532513541609 Disc loss:  0.0027535674 Gen loss:  1.0819992\n",
      "Epoch:  1493 Seg loss:  0.2117259475363235 Seg acc:  0.9268872083327638 Disc loss:  0.0008917831 Gen loss:  1.0988209\n",
      "Epoch:  1494 Seg loss:  0.21171729813218915 Seg acc:  0.9269008004808349 Disc loss:  0.056264006 Gen loss:  1.1278447\n",
      "Epoch:  1495 Seg loss:  0.21168048102720127 Seg acc:  0.926912326803631 Disc loss:  0.009605725 Gen loss:  1.1271747\n",
      "Epoch:  1496 Seg loss:  0.21161186620891892 Seg acc:  0.9269379911055331 Disc loss:  0.00023326155 Gen loss:  1.1007941\n",
      "Epoch:  1497 Seg loss:  0.21153562383087937 Seg acc:  0.9269658364347741 Disc loss:  0.00058606995 Gen loss:  1.0944186\n",
      "Epoch:  1498 Seg loss:  0.2114891720132452 Seg acc:  0.926988535734721 Disc loss:  0.022529118 Gen loss:  1.0854591\n",
      "Epoch:  1499 Seg loss:  0.21141265260628497 Seg acc:  0.9270115451117071 Disc loss:  0.026991025 Gen loss:  1.0887806\n",
      "Epoch:  1500 Seg loss:  0.2113745559801658 Seg acc:  0.9270263605442177 Disc loss:  0.01461803 Gen loss:  1.1323206\n",
      "Epoch:  1500 F1 (val):  0.7401107972880976 Acc (val):  0.7684897959183673\n",
      "Epoch:  1501 Seg loss:  0.21135576501697162 Seg acc:  0.9270289194958463 Disc loss:  0.0011868911 Gen loss:  1.1777978\n",
      "Epoch:  1502 Seg loss:  0.21134931497404802 Seg acc:  0.927026549634501 Disc loss:  0.017686091 Gen loss:  1.1277083\n",
      "Epoch:  1503 Seg loss:  0.21135147592562165 Seg acc:  0.9270179029695711 Disc loss:  0.04774572 Gen loss:  1.2135093\n",
      "Epoch:  1504 Seg loss:  0.21127732469145447 Seg acc:  0.9270465832609639 Disc loss:  0.010501609 Gen loss:  1.060931\n",
      "Epoch:  1505 Seg loss:  0.21133545558416963 Seg acc:  0.9270197979524036 Disc loss:  0.007224683 Gen loss:  1.2970569\n",
      "Epoch:  1506 Seg loss:  0.21126001565698607 Seg acc:  0.9270496246307288 Disc loss:  0.00017892578 Gen loss:  1.0913999\n",
      "Epoch:  1507 Seg loss:  0.21120079211252923 Seg acc:  0.9270685779288491 Disc loss:  0.00612013 Gen loss:  1.0869168\n",
      "Epoch:  1508 Seg loss:  0.21114716462949068 Seg acc:  0.9270859835976831 Disc loss:  0.0007603459 Gen loss:  1.1209937\n",
      "Epoch:  1509 Seg loss:  0.21110876537044765 Seg acc:  0.9270971112102893 Disc loss:  0.03711451 Gen loss:  1.1062158\n",
      "Epoch:  1510 Seg loss:  0.21108270456755399 Seg acc:  0.9271227530747398 Disc loss:  0.06378602 Gen loss:  1.0776641\n",
      "Epoch:  1510 F1 (val):  0.7317899587538789 Acc (val):  0.7659183673469387\n",
      "Epoch:  1511 Seg loss:  0.21104910398243595 Seg acc:  0.9271299585353664 Disc loss:  0.00065543654 Gen loss:  1.1514454\n",
      "Epoch:  1512 Seg loss:  0.21099176362807315 Seg acc:  0.9271520016736853 Disc loss:  0.0150392745 Gen loss:  1.0575062\n",
      "Epoch:  1513 Seg loss:  0.2109475883372714 Seg acc:  0.927170306324777 Disc loss:  0.003000217 Gen loss:  1.1366259\n",
      "Epoch:  1514 Seg loss:  0.21085750674791978 Seg acc:  0.9272057733265037 Disc loss:  0.0025586267 Gen loss:  1.0627238\n",
      "Epoch:  1515 Seg loss:  0.2108057517718167 Seg acc:  0.9272213241732337 Disc loss:  0.012148101 Gen loss:  1.0736318\n",
      "Epoch:  1516 Seg loss:  0.21078239483537647 Seg acc:  0.927227094663723 Disc loss:  0.029985705 Gen loss:  1.0906287\n",
      "Epoch:  1517 Seg loss:  0.2107172534557338 Seg acc:  0.9272503464141095 Disc loss:  0.011063002 Gen loss:  1.0774666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1518 Seg loss:  0.2106771444330024 Seg acc:  0.9272646608050334 Disc loss:  0.007897597 Gen loss:  1.1139991\n",
      "Epoch:  1519 Seg loss:  0.21062674556832472 Seg acc:  0.9272828189867125 Disc loss:  0.00024987973 Gen loss:  1.1276433\n",
      "Epoch:  1520 Seg loss:  0.21059025046170543 Seg acc:  0.9272989393125671 Disc loss:  0.00052897696 Gen loss:  1.1438752\n",
      "Epoch:  1520 F1 (val):  0.7317772597768581 Acc (val):  0.7610102040816327\n",
      "Epoch:  1521 Seg loss:  0.21062009000782117 Seg acc:  0.9272942411678675 Disc loss:  0.023527436 Gen loss:  1.2487051\n",
      "Epoch:  1522 Seg loss:  0.21061681330928508 Seg acc:  0.9272902196358175 Disc loss:  0.00037283482 Gen loss:  1.1974834\n",
      "Epoch:  1523 Seg loss:  0.21055683626188545 Seg acc:  0.927317358328755 Disc loss:  0.055899072 Gen loss:  1.0512336\n",
      "Epoch:  1524 Seg loss:  0.21049599080124082 Seg acc:  0.9273367614762441 Disc loss:  0.04373738 Gen loss:  1.0401028\n",
      "Epoch:  1525 Seg loss:  0.2104509370102257 Seg acc:  0.9273551354968217 Disc loss:  0.015147662 Gen loss:  1.0856198\n",
      "Epoch:  1526 Seg loss:  0.2103701693495323 Seg acc:  0.9273883636023216 Disc loss:  0.0013532992 Gen loss:  1.0840935\n",
      "Epoch:  1527 Seg loss:  0.21029905019512188 Seg acc:  0.9274140304451839 Disc loss:  0.0005277299 Gen loss:  1.090207\n",
      "Epoch:  1528 Seg loss:  0.21025150256592254 Seg acc:  0.9274331525804039 Disc loss:  0.0020555074 Gen loss:  1.1103863\n",
      "Epoch:  1529 Seg loss:  0.21017378451701002 Seg acc:  0.9274640955139415 Disc loss:  0.0010016119 Gen loss:  1.0848418\n",
      "Epoch:  1530 Seg loss:  0.21013127478703955 Seg acc:  0.9274778244631184 Disc loss:  0.006545255 Gen loss:  1.1112599\n",
      "Epoch:  1530 F1 (val):  0.7113340689904788 Acc (val):  0.7544897959183674\n",
      "Epoch:  1531 Seg loss:  0.2100622695131601 Seg acc:  0.9275111971633854 Disc loss:  0.0022087325 Gen loss:  1.0834453\n",
      "Epoch:  1532 Seg loss:  0.2099934135595283 Seg acc:  0.9275391977940001 Disc loss:  0.012410434 Gen loss:  1.0719142\n",
      "Epoch:  1533 Seg loss:  0.20989458104723122 Seg acc:  0.9275783111679113 Disc loss:  0.021958524 Gen loss:  1.0530045\n",
      "Epoch:  1534 Seg loss:  0.20987352302645224 Seg acc:  0.927580954154804 Disc loss:  0.009471866 Gen loss:  1.1583275\n",
      "Epoch:  1535 Seg loss:  0.20982472141567582 Seg acc:  0.9275945622548694 Disc loss:  0.012978221 Gen loss:  1.1317741\n",
      "Epoch:  1536 Seg loss:  0.20977963714055173 Seg acc:  0.927614131590136 Disc loss:  0.03708637 Gen loss:  1.13097\n",
      "Epoch:  1537 Seg loss:  0.20974355176207535 Seg acc:  0.9276351692270922 Disc loss:  0.016393315 Gen loss:  1.1059473\n",
      "Epoch:  1538 Seg loss:  0.20965790342399063 Seg acc:  0.927665799739922 Disc loss:  0.000556937 Gen loss:  1.0718151\n",
      "Epoch:  1539 Seg loss:  0.2096212039580006 Seg acc:  0.9276771624829268 Disc loss:  0.00046050255 Gen loss:  1.1483626\n",
      "Epoch:  1540 Seg loss:  0.20957367893114878 Seg acc:  0.9276896700238536 Disc loss:  0.0025063818 Gen loss:  1.1325942\n",
      "Epoch:  1540 F1 (val):  0.7404728060805086 Acc (val):  0.7705408163265306\n",
      "Epoch:  1541 Seg loss:  0.20953717919418288 Seg acc:  0.9277081208862519 Disc loss:  0.0071200626 Gen loss:  1.1502087\n",
      "Epoch:  1542 Seg loss:  0.20947846507196993 Seg acc:  0.9277310145848221 Disc loss:  0.01017214 Gen loss:  1.0777687\n",
      "Epoch:  1543 Seg loss:  0.20943451941505856 Seg acc:  0.927757019852659 Disc loss:  0.0015891267 Gen loss:  1.1331602\n",
      "Epoch:  1544 Seg loss:  0.20938473504393754 Seg acc:  0.927771095484826 Disc loss:  0.007340293 Gen loss:  1.1317892\n",
      "Epoch:  1545 Seg loss:  0.20934456244207508 Seg acc:  0.9277872993857738 Disc loss:  0.052134562 Gen loss:  1.0954397\n",
      "Epoch:  1546 Seg loss:  0.20926566640057276 Seg acc:  0.9278178380019536 Disc loss:  0.002515593 Gen loss:  1.065419\n",
      "Epoch:  1547 Seg loss:  0.2093592364155599 Seg acc:  0.9278257456828886 Disc loss:  0.06987754 Gen loss:  1.255344\n",
      "Epoch:  1548 Seg loss:  0.2093384694476499 Seg acc:  0.9278237554711806 Disc loss:  0.04600199 Gen loss:  1.1749806\n",
      "Epoch:  1549 Seg loss:  0.20925402768038026 Seg acc:  0.9278553642244503 Disc loss:  0.032987814 Gen loss:  1.0765257\n",
      "Epoch:  1550 Seg loss:  0.2092205329359539 Seg acc:  0.9278689927583935 Disc loss:  0.00594086 Gen loss:  1.1460565\n",
      "Epoch:  1550 F1 (val):  0.7221393183310452 Acc (val):  0.7619183673469387\n",
      "Epoch:  1551 Seg loss:  0.20919303991606664 Seg acc:  0.9278715838366293 Disc loss:  0.0006900642 Gen loss:  1.164173\n",
      "Epoch:  1552 Seg loss:  0.20913954424556613 Seg acc:  0.927895375289291 Disc loss:  0.07914033 Gen loss:  0.99453694\n",
      "Epoch:  1553 Seg loss:  0.20909495458620944 Seg acc:  0.9279050093959026 Disc loss:  0.044966247 Gen loss:  1.0780876\n",
      "Epoch:  1554 Seg loss:  0.20901513543397074 Seg acc:  0.9279394190108475 Disc loss:  0.014537869 Gen loss:  1.0627543\n",
      "Epoch:  1555 Seg loss:  0.20896126858626532 Seg acc:  0.9279562307238007 Disc loss:  0.007838234 Gen loss:  1.0862105\n",
      "Epoch:  1556 Seg loss:  0.20889494395970457 Seg acc:  0.9279841692461045 Disc loss:  0.04853714 Gen loss:  1.0485023\n",
      "Epoch:  1557 Seg loss:  0.20884778728384426 Seg acc:  0.9280037159372418 Disc loss:  0.025761968 Gen loss:  1.1085167\n",
      "Epoch:  1558 Seg loss:  0.2087622280704845 Seg acc:  0.9280387925388385 Disc loss:  0.00014167257 Gen loss:  1.0712\n",
      "Epoch:  1559 Seg loss:  0.2088356326054005 Seg acc:  0.9280281708578236 Disc loss:  0.017125797 Gen loss:  1.3194729\n",
      "Epoch:  1560 Seg loss:  0.2087934986831477 Seg acc:  0.9280424188906331 Disc loss:  0.0067166067 Gen loss:  1.1380706\n",
      "Epoch:  1560 F1 (val):  0.7295890391050307 Acc (val):  0.7755306122448979\n",
      "Epoch:  1561 Seg loss:  0.20878374347705478 Seg acc:  0.9280523996914588 Disc loss:  0.012209521 Gen loss:  1.1411638\n",
      "Epoch:  1562 Seg loss:  0.20878727051278007 Seg acc:  0.9280514254357313 Disc loss:  0.006038982 Gen loss:  1.2058218\n",
      "Epoch:  1563 Seg loss:  0.20870985672049466 Seg acc:  0.9280865225168762 Disc loss:  0.003674935 Gen loss:  1.0745137\n",
      "Epoch:  1564 Seg loss:  0.20868048477498696 Seg acc:  0.928100859909181 Disc loss:  0.030513505 Gen loss:  1.1207223\n",
      "Epoch:  1565 Seg loss:  0.20863767143207998 Seg acc:  0.9281228401903893 Disc loss:  0.0004656486 Gen loss:  1.1322811\n",
      "Epoch:  1566 Seg loss:  0.20855911226174764 Seg acc:  0.9281537519222248 Disc loss:  0.00023739286 Gen loss:  1.0841516\n",
      "Epoch:  1567 Seg loss:  0.20850075414997418 Seg acc:  0.928172902856101 Disc loss:  0.013457135 Gen loss:  1.0959084\n",
      "Epoch:  1568 Seg loss:  0.2084362581158437 Seg acc:  0.9281939816743023 Disc loss:  0.062213264 Gen loss:  1.0266254\n",
      "Epoch:  1569 Seg loss:  0.20844173157638696 Seg acc:  0.928189669749353 Disc loss:  0.00021871166 Gen loss:  1.2086092\n",
      "Epoch:  1570 Seg loss:  0.20838413620782886 Seg acc:  0.9282170479656833 Disc loss:  0.0021380163 Gen loss:  1.1123828\n",
      "Epoch:  1570 F1 (val):  0.7264973900539979 Acc (val):  0.7725510204081633\n",
      "Epoch:  1571 Seg loss:  0.2083396640322263 Seg acc:  0.9282346484106055 Disc loss:  0.0004223932 Gen loss:  1.135692\n",
      "Epoch:  1572 Seg loss:  0.2083585508921333 Seg acc:  0.9282363231552163 Disc loss:  0.006156421 Gen loss:  1.2019912\n",
      "Epoch:  1573 Seg loss:  0.20828366393515887 Seg acc:  0.9282632951464119 Disc loss:  0.01896581 Gen loss:  1.0170323\n",
      "Epoch:  1574 Seg loss:  0.20821996546069957 Seg acc:  0.9282892604309831 Disc loss:  0.00902703 Gen loss:  1.1006656\n",
      "Epoch:  1575 Seg loss:  0.20815184979448242 Seg acc:  0.928316488500162 Disc loss:  0.016870322 Gen loss:  1.0922502\n",
      "Epoch:  1576 Seg loss:  0.20809474871328412 Seg acc:  0.9283401209468559 Disc loss:  0.0004616926 Gen loss:  1.1136243\n",
      "Epoch:  1577 Seg loss:  0.20804867291316323 Seg acc:  0.9283577381491595 Disc loss:  0.02669864 Gen loss:  1.1138301\n",
      "Epoch:  1578 Seg loss:  0.20800031135413508 Seg acc:  0.9283746863764518 Disc loss:  0.031909112 Gen loss:  1.1210809\n",
      "Epoch:  1579 Seg loss:  0.20795400238031447 Seg acc:  0.928394036525313 Disc loss:  0.018865896 Gen loss:  1.1266611\n",
      "Epoch:  1580 Seg loss:  0.20789689891087482 Seg acc:  0.9284133621803152 Disc loss:  0.0020846804 Gen loss:  1.1059908\n",
      "Epoch:  1580 F1 (val):  0.7398752843080137 Acc (val):  0.7692244897959184\n",
      "Epoch:  1581 Seg loss:  0.20782403314956224 Seg acc:  0.9284408924860268 Disc loss:  0.0013423993 Gen loss:  1.092721\n",
      "Epoch:  1582 Seg loss:  0.20781463236511508 Seg acc:  0.9284454900797235 Disc loss:  0.007060794 Gen loss:  1.1537448\n",
      "Epoch:  1583 Seg loss:  0.2077663578375449 Seg acc:  0.9284647466061597 Disc loss:  0.04945562 Gen loss:  1.0767623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1584 Seg loss:  0.20774135473090213 Seg acc:  0.9284709338280767 Disc loss:  0.00046752903 Gen loss:  1.1594123\n",
      "Epoch:  1585 Seg loss:  0.20772941766618178 Seg acc:  0.9284777570334127 Disc loss:  0.0014174195 Gen loss:  1.1848353\n",
      "Epoch:  1586 Seg loss:  0.2077483403441246 Seg acc:  0.9284700954782922 Disc loss:  0.020069614 Gen loss:  1.1737751\n",
      "Epoch:  1587 Seg loss:  0.20775653774689862 Seg acc:  0.9284627650682201 Disc loss:  0.0003430155 Gen loss:  1.2126274\n",
      "Epoch:  1588 Seg loss:  0.20768373373483004 Seg acc:  0.9284907854829588 Disc loss:  0.013643753 Gen loss:  1.0542927\n",
      "Epoch:  1589 Seg loss:  0.20764589526551636 Seg acc:  0.9285064088568089 Disc loss:  0.004211526 Gen loss:  1.1179745\n",
      "Epoch:  1590 Seg loss:  0.20761945571211524 Seg acc:  0.9285207290463355 Disc loss:  0.0064789345 Gen loss:  1.1193736\n",
      "Epoch:  1590 F1 (val):  0.7424946243596648 Acc (val):  0.7731224489795918\n",
      "Epoch:  1591 Seg loss:  0.20760628933439385 Seg acc:  0.9285263728370041 Disc loss:  0.007399557 Gen loss:  1.1870229\n",
      "Epoch:  1592 Seg loss:  0.20754861953111375 Seg acc:  0.9285459504153419 Disc loss:  0.017940018 Gen loss:  1.0441283\n",
      "Epoch:  1593 Seg loss:  0.20749267964984588 Seg acc:  0.9285639020203185 Disc loss:  0.034569357 Gen loss:  1.0388253\n",
      "Epoch:  1594 Seg loss:  0.20745960961667403 Seg acc:  0.9285739891941719 Disc loss:  0.0016718653 Gen loss:  1.1402426\n",
      "Epoch:  1595 Seg loss:  0.207429853354969 Seg acc:  0.9285867826754526 Disc loss:  0.022492727 Gen loss:  1.1130829\n",
      "Epoch:  1596 Seg loss:  0.20734804526746348 Seg acc:  0.9286177816991458 Disc loss:  0.013885554 Gen loss:  1.0746799\n",
      "Epoch:  1597 Seg loss:  0.20731801488573803 Seg acc:  0.928631649904796 Disc loss:  0.0026116436 Gen loss:  1.1427217\n",
      "Epoch:  1598 Seg loss:  0.20723971723810827 Seg acc:  0.9286600278409236 Disc loss:  0.00022348613 Gen loss:  1.0726416\n",
      "Epoch:  1599 Seg loss:  0.20718614497758434 Seg acc:  0.9286795956656583 Disc loss:  0.00019044797 Gen loss:  1.1150581\n",
      "Epoch:  1600 Seg loss:  0.2071603639307432 Seg acc:  0.9286903698979592 Disc loss:  0.004937897 Gen loss:  1.1267931\n",
      "Epoch:  1600 F1 (val):  0.7185618917615936 Acc (val):  0.7617142857142857\n",
      "Epoch:  1601 Seg loss:  0.20709248006036696 Seg acc:  0.9287180206248645 Disc loss:  0.000748104 Gen loss:  1.0960287\n",
      "Epoch:  1602 Seg loss:  0.20708077635090524 Seg acc:  0.9287266873041352 Disc loss:  0.02300032 Gen loss:  1.1403971\n",
      "Epoch:  1603 Seg loss:  0.2070444874716452 Seg acc:  0.9287407539434988 Disc loss:  0.016857525 Gen loss:  1.0787535\n",
      "Epoch:  1604 Seg loss:  0.20698422368411484 Seg acc:  0.9287659359254924 Disc loss:  0.016858194 Gen loss:  1.1060833\n",
      "Epoch:  1605 Seg loss:  0.206945664389204 Seg acc:  0.9287818678873418 Disc loss:  0.030300418 Gen loss:  1.1435481\n",
      "Epoch:  1606 Seg loss:  0.2068865064364553 Seg acc:  0.9288027041451699 Disc loss:  0.014309751 Gen loss:  1.1116042\n",
      "Epoch:  1607 Seg loss:  0.20681921992851995 Seg acc:  0.928825101913821 Disc loss:  0.026059255 Gen loss:  1.0262341\n",
      "Epoch:  1608 Seg loss:  0.20679440624335438 Seg acc:  0.9288322418519646 Disc loss:  0.0005336125 Gen loss:  1.166765\n",
      "Epoch:  1609 Seg loss:  0.20673721655277158 Seg acc:  0.9288520566710214 Disc loss:  0.018388482 Gen loss:  1.032185\n",
      "Epoch:  1610 Seg loss:  0.20669228496342343 Seg acc:  0.9288753327417923 Disc loss:  0.055077367 Gen loss:  1.081\n",
      "Epoch:  1610 F1 (val):  0.716819843539599 Acc (val):  0.7636836734693877\n",
      "Epoch:  1611 Seg loss:  0.20660913517567994 Seg acc:  0.928909664424429 Disc loss:  0.014703073 Gen loss:  1.0153328\n",
      "Epoch:  1612 Seg loss:  0.20659237194843313 Seg acc:  0.9289130943940852 Disc loss:  0.008130173 Gen loss:  1.1687889\n",
      "Epoch:  1613 Seg loss:  0.20654716984047258 Seg acc:  0.9289309121044573 Disc loss:  0.0003242921 Gen loss:  1.1283467\n",
      "Epoch:  1614 Seg loss:  0.20650661910065857 Seg acc:  0.9289469691222213 Disc loss:  0.02283704 Gen loss:  1.0969942\n",
      "Epoch:  1615 Seg loss:  0.206491342323022 Seg acc:  0.9289457888418525 Disc loss:  0.010984217 Gen loss:  1.1818284\n",
      "Epoch:  1616 Seg loss:  0.20643017344444178 Seg acc:  0.9289651318448171 Disc loss:  0.0013535835 Gen loss:  1.1077305\n",
      "Epoch:  1617 Seg loss:  0.20633873116771012 Seg acc:  0.9289994383653275 Disc loss:  0.016023487 Gen loss:  1.0535942\n",
      "Epoch:  1618 Seg loss:  0.2063232171631272 Seg acc:  0.9290098950581469 Disc loss:  0.0030249627 Gen loss:  1.168551\n",
      "Epoch:  1619 Seg loss:  0.20626174080069967 Seg acc:  0.9290342047875356 Disc loss:  0.001902435 Gen loss:  1.0927898\n",
      "Epoch:  1620 Seg loss:  0.20618736904436424 Seg acc:  0.9290630511463844 Disc loss:  0.00036111986 Gen loss:  1.0788794\n",
      "Epoch:  1620 F1 (val):  0.7261546464802556 Acc (val):  0.7681428571428571\n",
      "Epoch:  1621 Seg loss:  0.20614594817253487 Seg acc:  0.9290758098427526 Disc loss:  0.0073803393 Gen loss:  1.1038389\n",
      "Epoch:  1622 Seg loss:  0.2061493095658196 Seg acc:  0.9290662195827776 Disc loss:  0.003768092 Gen loss:  1.2102494\n",
      "Epoch:  1623 Seg loss:  0.2061089890528739 Seg acc:  0.9290868195707118 Disc loss:  0.0076473416 Gen loss:  1.0979333\n",
      "Epoch:  1624 Seg loss:  0.20602452348036865 Seg acc:  0.9291224741127977 Disc loss:  0.0008788034 Gen loss:  1.0646707\n",
      "Epoch:  1625 Seg loss:  0.20597140512099632 Seg acc:  0.929141601255887 Disc loss:  0.0009539084 Gen loss:  1.1020807\n",
      "Epoch:  1626 Seg loss:  0.20587540020866074 Seg acc:  0.9291773351406982 Disc loss:  0.011444581 Gen loss:  1.045297\n",
      "Epoch:  1627 Seg loss:  0.20582536440148044 Seg acc:  0.9291954642951218 Disc loss:  0.0060682185 Gen loss:  1.1180631\n",
      "Epoch:  1628 Seg loss:  0.20577344713682258 Seg acc:  0.9292109073359073 Disc loss:  0.0014527834 Gen loss:  1.1035095\n",
      "Epoch:  1629 Seg loss:  0.2057376164460453 Seg acc:  0.9292236692098569 Disc loss:  0.042310353 Gen loss:  1.0829482\n",
      "Epoch:  1630 Seg loss:  0.20570583961264122 Seg acc:  0.9292323463127582 Disc loss:  0.005443799 Gen loss:  1.127702\n",
      "Epoch:  1630 F1 (val):  0.7385932640914006 Acc (val):  0.7684285714285715\n",
      "Epoch:  1631 Seg loss:  0.2056725119805314 Seg acc:  0.9292388230583466 Disc loss:  0.0015737641 Gen loss:  1.1417227\n",
      "Epoch:  1632 Seg loss:  0.20561674297741597 Seg acc:  0.9292652998699479 Disc loss:  0.035593364 Gen loss:  1.0679885\n",
      "Epoch:  1633 Seg loss:  0.20556324451878913 Seg acc:  0.9292779971756001 Disc loss:  0.0034660625 Gen loss:  1.115923\n",
      "Epoch:  1634 Seg loss:  0.20553915079277252 Seg acc:  0.9292941136062748 Disc loss:  0.0079711545 Gen loss:  1.1658365\n",
      "Epoch:  1635 Seg loss:  0.20547100018242812 Seg acc:  0.929317699556887 Disc loss:  0.07446021 Gen loss:  0.99742544\n",
      "Epoch:  1636 Seg loss:  0.20541807145909532 Seg acc:  0.9293275348036525 Disc loss:  0.03790159 Gen loss:  1.0603845\n",
      "Epoch:  1637 Seg loss:  0.20538124486931447 Seg acc:  0.9293434356027077 Disc loss:  0.00259467 Gen loss:  1.1397464\n",
      "Epoch:  1638 Seg loss:  0.20534450988602507 Seg acc:  0.9293580710672548 Disc loss:  0.0010760024 Gen loss:  1.1436311\n",
      "Epoch:  1639 Seg loss:  0.2052790467548363 Seg acc:  0.9293834281729776 Disc loss:  0.0033474858 Gen loss:  1.0952773\n",
      "Epoch:  1640 Seg loss:  0.20528885168591288 Seg acc:  0.929379044300647 Disc loss:  0.0006234262 Gen loss:  1.2153159\n",
      "Epoch:  1640 F1 (val):  0.7372581648069827 Acc (val):  0.7658265306122449\n",
      "Epoch:  1641 Seg loss:  0.20527704246909717 Seg acc:  0.9293748212264796 Disc loss:  0.009818809 Gen loss:  1.1410347\n",
      "Epoch:  1642 Seg loss:  0.20524310135258755 Seg acc:  0.9293807017325809 Disc loss:  0.06796014 Gen loss:  1.0747929\n",
      "Epoch:  1643 Seg loss:  0.20516906847142258 Seg acc:  0.9294109518426968 Disc loss:  0.0012838333 Gen loss:  1.0801735\n",
      "Epoch:  1644 Seg loss:  0.20513582222136487 Seg acc:  0.9294259583395401 Disc loss:  0.027444486 Gen loss:  1.0983436\n",
      "Epoch:  1645 Seg loss:  0.20503574790019757 Seg acc:  0.9294652937162707 Disc loss:  0.022256557 Gen loss:  0.9963983\n",
      "Epoch:  1646 Seg loss:  0.2049510379345637 Seg acc:  0.9294979170282937 Disc loss:  0.030472778 Gen loss:  0.9500181\n",
      "Epoch:  1647 Seg loss:  0.20486991304698393 Seg acc:  0.9295301909470528 Disc loss:  0.037499867 Gen loss:  1.067381\n",
      "Epoch:  1648 Seg loss:  0.2047809712290402 Seg acc:  0.9295659859817713 Disc loss:  0.007535476 Gen loss:  1.0555203\n",
      "Epoch:  1649 Seg loss:  0.20471503899594812 Seg acc:  0.9295870410019678 Disc loss:  0.012728464 Gen loss:  1.0863491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1650 Seg loss:  0.20466140525810647 Seg acc:  0.9296057513914656 Disc loss:  0.0042582904 Gen loss:  1.1184051\n",
      "Epoch:  1650 F1 (val):  0.7354927753728746 Acc (val):  0.7644081632653061\n",
      "Epoch:  1651 Seg loss:  0.20465556452268546 Seg acc:  0.9296068245590179 Disc loss:  0.00045377476 Gen loss:  1.1897514\n",
      "Epoch:  1652 Seg loss:  0.20460228999449756 Seg acc:  0.9296278166230171 Disc loss:  0.0091870865 Gen loss:  1.1073595\n",
      "Epoch:  1653 Seg loss:  0.2045489119955142 Seg acc:  0.9296510981888217 Disc loss:  0.008664313 Gen loss:  1.0800489\n",
      "Epoch:  1654 Seg loss:  0.20445953257282815 Seg acc:  0.9296845310070823 Disc loss:  0.0021908616 Gen loss:  1.0393276\n",
      "Epoch:  1655 Seg loss:  0.20437345031840204 Seg acc:  0.9297157654602627 Disc loss:  0.003377698 Gen loss:  1.0466208\n",
      "Epoch:  1656 Seg loss:  0.20430441890676745 Seg acc:  0.9297408003056296 Disc loss:  0.009292445 Gen loss:  1.0886314\n",
      "Epoch:  1657 Seg loss:  0.2042501469445682 Seg acc:  0.9297631877132264 Disc loss:  0.02648694 Gen loss:  1.0921024\n",
      "Epoch:  1658 Seg loss:  0.20424266473420494 Seg acc:  0.9297709312916963 Disc loss:  0.015773807 Gen loss:  1.1906176\n",
      "Epoch:  1659 Seg loss:  0.20423166926516834 Seg acc:  0.929774052478134 Disc loss:  0.0008106116 Gen loss:  1.1810637\n",
      "Epoch:  1660 Seg loss:  0.20415997247783893 Seg acc:  0.9298039095156134 Disc loss:  0.00079456717 Gen loss:  1.0710908\n",
      "Epoch:  1660 F1 (val):  0.7300937037210242 Acc (val):  0.770030612244898\n",
      "Epoch:  1661 Seg loss:  0.20409125694977023 Seg acc:  0.9298332698521914 Disc loss:  0.00024435797 Gen loss:  1.0811439\n",
      "Epoch:  1662 Seg loss:  0.20405932297766496 Seg acc:  0.929847399248508 Disc loss:  0.00046331377 Gen loss:  1.145482\n",
      "Epoch:  1663 Seg loss:  0.2039994455479708 Seg acc:  0.9298714825677714 Disc loss:  0.011830558 Gen loss:  1.0704997\n",
      "Epoch:  1664 Seg loss:  0.2039195575791662 Seg acc:  0.9299035088795135 Disc loss:  0.094570234 Gen loss:  1.0236899\n",
      "Epoch:  1665 Seg loss:  0.2038689228395621 Seg acc:  0.9299241588527303 Disc loss:  0.0047292793 Gen loss:  1.1161473\n",
      "Epoch:  1666 Seg loss:  0.203837552381789 Seg acc:  0.9299297780336625 Disc loss:  0.002037159 Gen loss:  1.1509016\n",
      "Epoch:  1667 Seg loss:  0.20378951724544928 Seg acc:  0.9299459495855932 Disc loss:  0.0074311253 Gen loss:  1.0826077\n",
      "Epoch:  1668 Seg loss:  0.20383901415924302 Seg acc:  0.9299463490432145 Disc loss:  0.00081223855 Gen loss:  1.2763586\n",
      "Epoch:  1669 Seg loss:  0.20383231679994307 Seg acc:  0.9299490407307321 Disc loss:  0.009435486 Gen loss:  1.1558018\n",
      "Epoch:  1670 Seg loss:  0.2037686820984065 Seg acc:  0.9299747953073446 Disc loss:  0.046529204 Gen loss:  1.0442984\n",
      "Epoch:  1670 F1 (val):  0.7305644501076933 Acc (val):  0.7725510204081633\n",
      "Epoch:  1671 Seg loss:  0.20372506465377171 Seg acc:  0.9299916645293667 Disc loss:  0.0038445147 Gen loss:  1.1068628\n",
      "Epoch:  1672 Seg loss:  0.20369143503535378 Seg acc:  0.9300043941021385 Disc loss:  0.009138979 Gen loss:  1.0923076\n",
      "Epoch:  1673 Seg loss:  0.20364085503158566 Seg acc:  0.9300242751015529 Disc loss:  0.0022530688 Gen loss:  1.1054767\n",
      "Epoch:  1674 Seg loss:  0.20357479613714963 Seg acc:  0.9300519042742545 Disc loss:  0.0014635703 Gen loss:  1.0807793\n",
      "Epoch:  1675 Seg loss:  0.20359078446653353 Seg acc:  0.9300485836125496 Disc loss:  0.017723337 Gen loss:  1.1852974\n",
      "Epoch:  1676 Seg loss:  0.20360418420000478 Seg acc:  0.9300434404071892 Disc loss:  0.00096878706 Gen loss:  1.2158644\n",
      "Epoch:  1677 Seg loss:  0.20357932493570452 Seg acc:  0.930046669830723 Disc loss:  0.027410658 Gen loss:  1.1201491\n",
      "Epoch:  1678 Seg loss:  0.20353679216208206 Seg acc:  0.9300670745056069 Disc loss:  0.00097484724 Gen loss:  1.1246378\n",
      "Epoch:  1679 Seg loss:  0.20351015139834877 Seg acc:  0.9300778828505794 Disc loss:  0.0016579009 Gen loss:  1.1416605\n",
      "Epoch:  1680 Seg loss:  0.20350529113562688 Seg acc:  0.9300778972303209 Disc loss:  0.0470248 Gen loss:  1.1119925\n",
      "Epoch:  1680 F1 (val):  0.7462523293151525 Acc (val):  0.7777857142857143\n",
      "Epoch:  1681 Seg loss:  0.20345463646949224 Seg acc:  0.9300956670592092 Disc loss:  0.017373323 Gen loss:  1.08671\n",
      "Epoch:  1682 Seg loss:  0.2034035749117734 Seg acc:  0.930117662403844 Disc loss:  0.051781837 Gen loss:  1.0570276\n",
      "Epoch:  1683 Seg loss:  0.2033888684144101 Seg acc:  0.9301167436671638 Disc loss:  0.0020277626 Gen loss:  1.1708968\n",
      "Epoch:  1684 Seg loss:  0.20343785831868436 Seg acc:  0.9300878011537158 Disc loss:  0.0004648193 Gen loss:  1.2822585\n",
      "Epoch:  1685 Seg loss:  0.20339842617113796 Seg acc:  0.9301006782534972 Disc loss:  0.0018310645 Gen loss:  1.137423\n",
      "Epoch:  1686 Seg loss:  0.20334996588634213 Seg acc:  0.9301211053816544 Disc loss:  0.025309376 Gen loss:  1.0645955\n",
      "Epoch:  1687 Seg loss:  0.20328848876796604 Seg acc:  0.9301427180237833 Disc loss:  0.01963549 Gen loss:  1.0576069\n",
      "Epoch:  1688 Seg loss:  0.203243406147418 Seg acc:  0.9301652118193249 Disc loss:  0.0030628114 Gen loss:  1.1244688\n",
      "Epoch:  1689 Seg loss:  0.2031873671934582 Seg acc:  0.9301852623820398 Disc loss:  0.0007056131 Gen loss:  1.1047268\n",
      "Epoch:  1690 Seg loss:  0.20315837251055524 Seg acc:  0.9301942700156987 Disc loss:  0.00054146367 Gen loss:  1.1443903\n",
      "Epoch:  1690 F1 (val):  0.7433258022181094 Acc (val):  0.7801530612244898\n",
      "Epoch:  1691 Seg loss:  0.2031364420936666 Seg acc:  0.9301997972459238 Disc loss:  0.004262022 Gen loss:  1.1261681\n",
      "Epoch:  1692 Seg loss:  0.2030943173664153 Seg acc:  0.930213007188691 Disc loss:  0.014650481 Gen loss:  1.1330335\n",
      "Epoch:  1693 Seg loss:  0.2030569627260535 Seg acc:  0.9302262015260919 Disc loss:  0.03856353 Gen loss:  1.123478\n",
      "Epoch:  1694 Seg loss:  0.20303329142138204 Seg acc:  0.9302365190468159 Disc loss:  0.00061623787 Gen loss:  1.1571234\n",
      "Epoch:  1695 Seg loss:  0.2029806730691838 Seg acc:  0.9302615736560111 Disc loss:  0.0006053515 Gen loss:  1.1084218\n",
      "Epoch:  1696 Seg loss:  0.20291304803356738 Seg acc:  0.9302858466499807 Disc loss:  0.011012791 Gen loss:  1.0709813\n",
      "Epoch:  1697 Seg loss:  0.20284471899472972 Seg acc:  0.9303102413623079 Disc loss:  0.017112104 Gen loss:  1.0777549\n",
      "Epoch:  1698 Seg loss:  0.20277035002705276 Seg acc:  0.9303409172856422 Disc loss:  0.00411714 Gen loss:  1.0752015\n",
      "Epoch:  1699 Seg loss:  0.20276812751892034 Seg acc:  0.9303431790609121 Disc loss:  0.0034073521 Gen loss:  1.1968851\n",
      "Epoch:  1700 Seg loss:  0.20272233886096408 Seg acc:  0.9303587935174069 Disc loss:  0.0063302196 Gen loss:  1.1227922\n",
      "Epoch:  1700 F1 (val):  0.7412580749873804 Acc (val):  0.7809387755102041\n",
      "Epoch:  1701 Seg loss:  0.20266300394062362 Seg acc:  0.9303808384023803 Disc loss:  0.012973706 Gen loss:  1.0349474\n",
      "Epoch:  1702 Seg loss:  0.2026131882733905 Seg acc:  0.9304078035444494 Disc loss:  0.0018638995 Gen loss:  1.1065319\n",
      "Epoch:  1703 Seg loss:  0.20253106082187494 Seg acc:  0.9304395304804246 Disc loss:  0.00674998 Gen loss:  1.0557188\n",
      "Epoch:  1704 Seg loss:  0.20248925532192483 Seg acc:  0.9304590938488071 Disc loss:  0.02785028 Gen loss:  1.0825518\n",
      "Epoch:  1705 Seg loss:  0.20245252266701017 Seg acc:  0.9304750433897899 Disc loss:  0.021138694 Gen loss:  1.0677364\n",
      "Epoch:  1706 Seg loss:  0.20241670389326696 Seg acc:  0.9304894789099696 Disc loss:  0.06075994 Gen loss:  1.073917\n",
      "Epoch:  1707 Seg loss:  0.20233634988301039 Seg acc:  0.9305216814317994 Disc loss:  0.00087563106 Gen loss:  1.0610425\n",
      "Epoch:  1708 Seg loss:  0.20228443006206243 Seg acc:  0.9305429431725851 Disc loss:  0.006841292 Gen loss:  1.0940762\n",
      "Epoch:  1709 Seg loss:  0.20227772427527718 Seg acc:  0.9305446256911191 Disc loss:  0.025222912 Gen loss:  1.1431743\n",
      "Epoch:  1710 Seg loss:  0.2022389671803392 Seg acc:  0.9305597326649958 Disc loss:  0.0010173002 Gen loss:  1.1326512\n",
      "Epoch:  1710 F1 (val):  0.7319649504942733 Acc (val):  0.7710714285714285\n",
      "Epoch:  1711 Seg loss:  0.2021705736517732 Seg acc:  0.9305842149834802 Disc loss:  0.0011378691 Gen loss:  1.0693723\n",
      "Epoch:  1712 Seg loss:  0.20213800812549193 Seg acc:  0.930596301020408 Disc loss:  0.0009125178 Gen loss:  1.1414723\n",
      "Epoch:  1713 Seg loss:  0.20207928141749748 Seg acc:  0.9306186485101922 Disc loss:  0.011445244 Gen loss:  1.0579356\n",
      "Epoch:  1714 Seg loss:  0.2020010833705633 Seg acc:  0.9306491558116828 Disc loss:  0.0026773252 Gen loss:  1.042692\n",
      "Epoch:  1715 Seg loss:  0.20195047100109886 Seg acc:  0.9306653477717618 Disc loss:  0.0010066603 Gen loss:  1.1063806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1716 Seg loss:  0.20188659659015895 Seg acc:  0.9306911838161838 Disc loss:  0.00027367228 Gen loss:  1.0854665\n",
      "Epoch:  1717 Seg loss:  0.20184561771860843 Seg acc:  0.9307056981208325 Disc loss:  0.03383402 Gen loss:  1.0481863\n",
      "Epoch:  1718 Seg loss:  0.20182899959229272 Seg acc:  0.930706534651113 Disc loss:  0.0049039153 Gen loss:  1.1420774\n",
      "Epoch:  1719 Seg loss:  0.20175861647659224 Seg acc:  0.930733934062281 Disc loss:  0.0038242242 Gen loss:  1.0765252\n",
      "Epoch:  1720 Seg loss:  0.2017062424032321 Seg acc:  0.9307526993355482 Disc loss:  0.016286947 Gen loss:  1.0539786\n",
      "Epoch:  1720 F1 (val):  0.741307722832238 Acc (val):  0.7694183673469388\n",
      "Epoch:  1721 Seg loss:  0.20167146748465414 Seg acc:  0.9307675888484388 Disc loss:  0.03514315 Gen loss:  1.0904018\n",
      "Epoch:  1722 Seg loss:  0.20164170001744877 Seg acc:  0.9307808314963616 Disc loss:  0.064458445 Gen loss:  1.051602\n",
      "Epoch:  1723 Seg loss:  0.20162903566996648 Seg acc:  0.9307844350740876 Disc loss:  0.0039135776 Gen loss:  1.1787091\n",
      "Epoch:  1724 Seg loss:  0.20161231854182868 Seg acc:  0.9308010559212083 Disc loss:  0.003208338 Gen loss:  1.1676772\n",
      "Epoch:  1725 Seg loss:  0.2015811733296816 Seg acc:  0.9308093759242827 Disc loss:  0.0039415215 Gen loss:  1.1257917\n",
      "Epoch:  1726 Seg loss:  0.20151421863495061 Seg acc:  0.9308358656324638 Disc loss:  0.0011524332 Gen loss:  1.0853328\n",
      "Epoch:  1727 Seg loss:  0.20145040020329386 Seg acc:  0.9308568592463041 Disc loss:  0.01408119 Gen loss:  1.0449817\n",
      "Epoch:  1728 Seg loss:  0.20140259826116058 Seg acc:  0.9308784190759638 Disc loss:  0.043081004 Gen loss:  1.0353751\n",
      "Epoch:  1729 Seg loss:  0.20142199174259148 Seg acc:  0.9308738388357078 Disc loss:  0.0008235112 Gen loss:  1.234437\n",
      "Epoch:  1730 Seg loss:  0.20137845332265933 Seg acc:  0.9308975757933232 Disc loss:  0.018383771 Gen loss:  1.074229\n",
      "Epoch:  1730 F1 (val):  0.7341928270295376 Acc (val):  0.7663265306122449\n",
      "Epoch:  1731 Seg loss:  0.20133446084883155 Seg acc:  0.9309181904997701 Disc loss:  0.00051757577 Gen loss:  1.1100501\n",
      "Epoch:  1732 Seg loss:  0.20125903358885172 Seg acc:  0.9309430527407268 Disc loss:  0.022868628 Gen loss:  1.0265937\n",
      "Epoch:  1733 Seg loss:  0.20121750200518762 Seg acc:  0.9309605261608395 Disc loss:  0.00014791821 Gen loss:  1.1226679\n",
      "Epoch:  1734 Seg loss:  0.20118066088662773 Seg acc:  0.9309723889555823 Disc loss:  0.0007916107 Gen loss:  1.1302254\n",
      "Epoch:  1735 Seg loss:  0.20110711274341136 Seg acc:  0.9309998235605481 Disc loss:  0.007889859 Gen loss:  1.047505\n",
      "Epoch:  1736 Seg loss:  0.20108144812946838 Seg acc:  0.93101488291169 Disc loss:  0.037330706 Gen loss:  1.0991722\n",
      "Epoch:  1737 Seg loss:  0.20101900555077612 Seg acc:  0.9310369743752424 Disc loss:  0.017039876 Gen loss:  1.0925919\n",
      "Epoch:  1738 Seg loss:  0.20097268697933238 Seg acc:  0.9310505272304549 Disc loss:  0.00012666533 Gen loss:  1.1215048\n",
      "Epoch:  1739 Seg loss:  0.20095958113199064 Seg acc:  0.9310611306052036 Disc loss:  0.00024692318 Gen loss:  1.1691631\n",
      "Epoch:  1740 Seg loss:  0.200932864247468 Seg acc:  0.9310695226366408 Disc loss:  0.0015098898 Gen loss:  1.1545893\n",
      "Epoch:  1740 F1 (val):  0.7346063523463031 Acc (val):  0.7723775510204082\n",
      "Epoch:  1741 Seg loss:  0.2008840343211486 Seg acc:  0.9310943159572846 Disc loss:  0.01967331 Gen loss:  1.0891316\n",
      "Epoch:  1742 Seg loss:  0.20081974902370972 Seg acc:  0.931118055718269 Disc loss:  0.0002589363 Gen loss:  1.0753447\n",
      "Epoch:  1743 Seg loss:  0.20075739880599514 Seg acc:  0.9311405973749225 Disc loss:  0.0021254101 Gen loss:  1.0859542\n",
      "Epoch:  1744 Seg loss:  0.2007402308656911 Seg acc:  0.9311470230293953 Disc loss:  0.003364692 Gen loss:  1.1672983\n",
      "Epoch:  1745 Seg loss:  0.20066733973202186 Seg acc:  0.9311743465294428 Disc loss:  0.00084204646 Gen loss:  1.075786\n",
      "Epoch:  1746 Seg loss:  0.2006136348357964 Seg acc:  0.93119521004278 Disc loss:  0.0033335562 Gen loss:  1.105443\n",
      "Epoch:  1747 Seg loss:  0.20057969278712987 Seg acc:  0.9312055360209338 Disc loss:  0.0017847737 Gen loss:  1.1357269\n",
      "Epoch:  1748 Seg loss:  0.20051191384249817 Seg acc:  0.931231319759025 Disc loss:  0.0019747268 Gen loss:  1.0645218\n",
      "Epoch:  1749 Seg loss:  0.2004737407416361 Seg acc:  0.9312433635546844 Disc loss:  0.0022661772 Gen loss:  1.1265452\n",
      "Epoch:  1750 Seg loss:  0.20039652257519108 Seg acc:  0.9312743440233235 Disc loss:  0.003239348 Gen loss:  1.0629115\n",
      "Epoch:  1750 F1 (val):  0.7448318851212734 Acc (val):  0.7735816326530612\n",
      "Epoch:  1751 Seg loss:  0.20037959743480488 Seg acc:  0.9312805219175049 Disc loss:  0.0010250284 Gen loss:  1.1684334\n",
      "Epoch:  1752 Seg loss:  0.2003772384316988 Seg acc:  0.9312791212375361 Disc loss:  0.035092816 Gen loss:  1.1390228\n",
      "Epoch:  1753 Seg loss:  0.20032173655480912 Seg acc:  0.9312991140552057 Disc loss:  0.0010336796 Gen loss:  1.1080328\n",
      "Epoch:  1754 Seg loss:  0.20025989051988963 Seg acc:  0.931328101365974 Disc loss:  0.013180095 Gen loss:  1.0745124\n",
      "Epoch:  1755 Seg loss:  0.20026511182090495 Seg acc:  0.9313242048956335 Disc loss:  0.0058340863 Gen loss:  1.2075955\n",
      "Epoch:  1756 Seg loss:  0.2002365646739586 Seg acc:  0.9313354214123007 Disc loss:  0.00056417397 Gen loss:  1.140134\n",
      "Epoch:  1757 Seg loss:  0.20020111110199224 Seg acc:  0.9313461895856806 Disc loss:  0.0541384 Gen loss:  1.061585\n",
      "Epoch:  1758 Seg loss:  0.2001864105713076 Seg acc:  0.9313454818787584 Disc loss:  0.04036471 Gen loss:  1.157406\n",
      "Epoch:  1759 Seg loss:  0.2001205758213353 Seg acc:  0.9313718949774339 Disc loss:  0.016306859 Gen loss:  1.0839365\n",
      "Epoch:  1760 Seg loss:  0.2000711877343499 Seg acc:  0.9313834937384046 Disc loss:  0.0012647343 Gen loss:  1.0983495\n",
      "Epoch:  1760 F1 (val):  0.7439696757120413 Acc (val):  0.773673469387755\n",
      "Epoch:  1761 Seg loss:  0.20001846620646951 Seg acc:  0.9314018878420193 Disc loss:  0.028010039 Gen loss:  1.0143762\n",
      "Epoch:  1762 Seg loss:  0.19996908307709774 Seg acc:  0.9314222879844332 Disc loss:  0.003446076 Gen loss:  1.0914791\n",
      "Epoch:  1763 Seg loss:  0.19998509712597556 Seg acc:  0.931415317119474 Disc loss:  0.00044136148 Gen loss:  1.2225428\n",
      "Epoch:  1764 Seg loss:  0.19994444139681908 Seg acc:  0.9314312034337545 Disc loss:  0.00014643089 Gen loss:  1.1264977\n",
      "Epoch:  1765 Seg loss:  0.1999361147096238 Seg acc:  0.9314352199803435 Disc loss:  0.023712246 Gen loss:  1.1078709\n",
      "Epoch:  1766 Seg loss:  0.19994662373642083 Seg acc:  0.9314415432084499 Disc loss:  0.00012292845 Gen loss:  1.2167654\n",
      "Epoch:  1767 Seg loss:  0.19989059172490592 Seg acc:  0.9314656168069946 Disc loss:  0.0070681847 Gen loss:  1.0710155\n",
      "Epoch:  1768 Seg loss:  0.19987167840469544 Seg acc:  0.9314701842275372 Disc loss:  0.050136212 Gen loss:  1.118772\n",
      "Epoch:  1769 Seg loss:  0.19981781014442915 Seg acc:  0.9314874366931623 Disc loss:  0.02462144 Gen loss:  1.0292883\n",
      "Epoch:  1770 Seg loss:  0.19980237460195344 Seg acc:  0.931492995503286 Disc loss:  0.012150943 Gen loss:  1.1448358\n",
      "Epoch:  1770 F1 (val):  0.7357080187123639 Acc (val):  0.7680102040816327\n",
      "Epoch:  1771 Seg loss:  0.19977894899730356 Seg acc:  0.9314975397273534 Disc loss:  0.0052371854 Gen loss:  1.1383222\n",
      "Epoch:  1772 Seg loss:  0.19972733845703017 Seg acc:  0.931509132998572 Disc loss:  0.00092351926 Gen loss:  1.1040324\n",
      "Epoch:  1773 Seg loss:  0.19971329090802667 Seg acc:  0.9315077638500409 Disc loss:  0.002349205 Gen loss:  1.172211\n",
      "Epoch:  1774 Seg loss:  0.19968019708310672 Seg acc:  0.9315212076939005 Disc loss:  0.023235299 Gen loss:  1.131237\n",
      "Epoch:  1775 Seg loss:  0.19962464211062647 Seg acc:  0.9315409600459902 Disc loss:  0.006352847 Gen loss:  1.1035447\n",
      "Epoch:  1776 Seg loss:  0.19957571731133572 Seg acc:  0.9315559500827358 Disc loss:  0.004502432 Gen loss:  1.078309\n",
      "Epoch:  1777 Seg loss:  0.19956616592133858 Seg acc:  0.9315582901703169 Disc loss:  0.0040246565 Gen loss:  1.1536075\n",
      "Epoch:  1778 Seg loss:  0.19952240823668557 Seg acc:  0.9315801404926426 Disc loss:  0.0005352383 Gen loss:  1.1151785\n",
      "Epoch:  1779 Seg loss:  0.19947558774823818 Seg acc:  0.931597520964541 Disc loss:  0.05100524 Gen loss:  1.1133165\n",
      "Epoch:  1780 Seg loss:  0.19948012142578203 Seg acc:  0.931587938546205 Disc loss:  0.00013635239 Gen loss:  1.2024252\n",
      "Epoch:  1780 F1 (val):  0.7363913302481309 Acc (val):  0.7761428571428571\n",
      "Epoch:  1781 Seg loss:  0.19942716787925335 Seg acc:  0.9316067274748193 Disc loss:  0.0018888735 Gen loss:  1.0986006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1782 Seg loss:  0.19940429469141963 Seg acc:  0.9316156176275223 Disc loss:  0.0006763704 Gen loss:  1.151144\n",
      "Epoch:  1783 Seg loss:  0.19933692547448284 Seg acc:  0.9316420959858986 Disc loss:  0.0030651204 Gen loss:  1.068384\n",
      "Epoch:  1784 Seg loss:  0.1993157109684173 Seg acc:  0.9316429486592844 Disc loss:  0.021306522 Gen loss:  1.1640813\n",
      "Epoch:  1785 Seg loss:  0.19928232954621983 Seg acc:  0.9316473732350082 Disc loss:  0.030559238 Gen loss:  1.0537975\n",
      "Epoch:  1786 Seg loss:  0.19922287945509423 Seg acc:  0.9316727894965378 Disc loss:  0.0037421037 Gen loss:  1.0829772\n",
      "Epoch:  1787 Seg loss:  0.19915516501283206 Seg acc:  0.9316966070143782 Disc loss:  0.00017093403 Gen loss:  1.0771626\n",
      "Epoch:  1788 Seg loss:  0.19907726691223232 Seg acc:  0.9317261048714788 Disc loss:  0.026653985 Gen loss:  1.0574193\n",
      "Epoch:  1789 Seg loss:  0.19904564377264047 Seg acc:  0.9317370324317542 Disc loss:  0.020733982 Gen loss:  1.1420287\n",
      "Epoch:  1790 Seg loss:  0.19900540291180824 Seg acc:  0.9317512256299169 Disc loss:  0.013775938 Gen loss:  1.1260949\n",
      "Epoch:  1790 F1 (val):  0.7392345300012084 Acc (val):  0.771795918367347\n",
      "Epoch:  1791 Seg loss:  0.19895733094195425 Seg acc:  0.9317702457867568 Disc loss:  0.016697083 Gen loss:  1.108021\n",
      "Epoch:  1792 Seg loss:  0.19889853325522772 Seg acc:  0.9317893870717932 Disc loss:  0.00090116967 Gen loss:  1.0782447\n",
      "Epoch:  1793 Seg loss:  0.19886478886831027 Seg acc:  0.931802673662884 Disc loss:  0.0016539701 Gen loss:  1.1191844\n",
      "Epoch:  1794 Seg loss:  0.19878840988861146 Seg acc:  0.9318313027552159 Disc loss:  0.0005977657 Gen loss:  1.0540117\n",
      "Epoch:  1795 Seg loss:  0.19875425934625535 Seg acc:  0.931842135182764 Disc loss:  0.00018792869 Gen loss:  1.1261158\n",
      "Epoch:  1796 Seg loss:  0.19872637384286967 Seg acc:  0.9318502568065089 Disc loss:  0.014753169 Gen loss:  1.1576915\n",
      "Epoch:  1797 Seg loss:  0.19882598709217628 Seg acc:  0.9318252927214292 Disc loss:  0.0005041279 Gen loss:  1.3780787\n",
      "Epoch:  1798 Seg loss:  0.19877088881689264 Seg acc:  0.9318483121836054 Disc loss:  0.008112605 Gen loss:  1.032662\n",
      "Epoch:  1799 Seg loss:  0.1987340623112173 Seg acc:  0.9318603872899911 Disc loss:  0.009460939 Gen loss:  1.1285346\n",
      "Epoch:  1800 Seg loss:  0.19870390206989313 Seg acc:  0.9318728741496599 Disc loss:  0.0061847055 Gen loss:  1.138146\n",
      "Epoch:  1800 F1 (val):  0.742477451727684 Acc (val):  0.7766938775510204\n",
      "Epoch:  1801 Seg loss:  0.19867491082126468 Seg acc:  0.9318859137214021 Disc loss:  0.052869778 Gen loss:  1.0911038\n",
      "Epoch:  1802 Seg loss:  0.19867618502294448 Seg acc:  0.9318846406487125 Disc loss:  0.030860875 Gen loss:  1.1931719\n",
      "Epoch:  1803 Seg loss:  0.1986100573053442 Seg acc:  0.9319086952584695 Disc loss:  0.0055435826 Gen loss:  1.0760766\n",
      "Epoch:  1804 Seg loss:  0.19856759838495577 Seg acc:  0.9319279152902847 Disc loss:  0.03257871 Gen loss:  1.0634189\n",
      "Epoch:  1805 Seg loss:  0.19853821925591894 Seg acc:  0.9319321329639889 Disc loss:  0.0026728637 Gen loss:  1.1433873\n",
      "Epoch:  1806 Seg loss:  0.1985387201828352 Seg acc:  0.9319315433814722 Disc loss:  0.0070525357 Gen loss:  1.1672201\n",
      "Epoch:  1807 Seg loss:  0.19847520649037312 Seg acc:  0.9319604598895453 Disc loss:  0.000379605 Gen loss:  1.0753782\n",
      "Epoch:  1808 Seg loss:  0.19846798765547244 Seg acc:  0.9319633826982121 Disc loss:  0.0013291788 Gen loss:  1.1849022\n",
      "Epoch:  1809 Seg loss:  0.1984574020633782 Seg acc:  0.9319610845996774 Disc loss:  0.032978054 Gen loss:  1.1088201\n",
      "Epoch:  1810 Seg loss:  0.19840162044895288 Seg acc:  0.9319804938550007 Disc loss:  0.00288539 Gen loss:  1.0773907\n",
      "Epoch:  1810 F1 (val):  0.7296763513267264 Acc (val):  0.7683367346938775\n",
      "Epoch:  1811 Seg loss:  0.19835003150276292 Seg acc:  0.9319956557995922 Disc loss:  0.008066157 Gen loss:  1.0842917\n",
      "Epoch:  1812 Seg loss:  0.19826257547926956 Seg acc:  0.9320275543992432 Disc loss:  0.00017979102 Gen loss:  1.0384017\n",
      "Epoch:  1813 Seg loss:  0.19822438958759014 Seg acc:  0.9320423922464739 Disc loss:  0.0008610015 Gen loss:  1.1255573\n",
      "Epoch:  1814 Seg loss:  0.19815463227730207 Seg acc:  0.9320694485070766 Disc loss:  0.012483883 Gen loss:  1.0329959\n",
      "Epoch:  1815 Seg loss:  0.19810921585921085 Seg acc:  0.9320867768595043 Disc loss:  0.006202495 Gen loss:  1.0683541\n",
      "Epoch:  1816 Seg loss:  0.19807308159013676 Seg acc:  0.9321071765710691 Disc loss:  0.00028023144 Gen loss:  1.1254163\n",
      "Epoch:  1817 Seg loss:  0.19799695870068681 Seg acc:  0.9321425763480957 Disc loss:  0.032536075 Gen loss:  1.0056185\n",
      "Epoch:  1818 Seg loss:  0.19793477611835508 Seg acc:  0.9321676938101975 Disc loss:  0.012009032 Gen loss:  1.0867102\n",
      "Epoch:  1819 Seg loss:  0.19790057849431839 Seg acc:  0.9321788995972221 Disc loss:  0.001191658 Gen loss:  1.121569\n",
      "Epoch:  1820 Seg loss:  0.19783493214092412 Seg acc:  0.9322057916573223 Disc loss:  0.0017905524 Gen loss:  1.0702202\n",
      "Epoch:  1820 F1 (val):  0.7322808929277146 Acc (val):  0.7686632653061225\n",
      "Epoch:  1821 Seg loss:  0.19781527775843546 Seg acc:  0.9322159835927782 Disc loss:  0.06685806 Gen loss:  1.0477555\n",
      "Epoch:  1822 Seg loss:  0.1978144666791355 Seg acc:  0.9322169235421941 Disc loss:  0.003735318 Gen loss:  1.1947807\n",
      "Epoch:  1823 Seg loss:  0.1977679823298933 Seg acc:  0.9322342348897871 Disc loss:  0.0023776419 Gen loss:  1.112582\n",
      "Epoch:  1824 Seg loss:  0.19772147275752536 Seg acc:  0.932248030791264 Disc loss:  0.025689434 Gen loss:  1.0840901\n",
      "Epoch:  1825 Seg loss:  0.19768002747672878 Seg acc:  0.9322658652502097 Disc loss:  0.0003531218 Gen loss:  1.1184115\n",
      "Epoch:  1826 Seg loss:  0.1976417761952958 Seg acc:  0.9322829816483001 Disc loss:  0.0013502201 Gen loss:  1.1290243\n",
      "Epoch:  1827 Seg loss:  0.19758115716168445 Seg acc:  0.932308177786714 Disc loss:  0.010184719 Gen loss:  1.0862578\n",
      "Epoch:  1828 Seg loss:  0.1975320674666495 Seg acc:  0.9323340441209307 Disc loss:  0.005957758 Gen loss:  1.1011147\n",
      "Epoch:  1829 Seg loss:  0.1974995863191608 Seg acc:  0.9323439818792472 Disc loss:  0.004420135 Gen loss:  1.1224264\n",
      "Epoch:  1830 Seg loss:  0.1974550331306588 Seg acc:  0.9323558603769377 Disc loss:  0.017140798 Gen loss:  1.109345\n",
      "Epoch:  1830 F1 (val):  0.7335378959236483 Acc (val):  0.7697755102040816\n",
      "Epoch:  1831 Seg loss:  0.19742957705653216 Seg acc:  0.9323635461830828 Disc loss:  0.0011106725 Gen loss:  1.145414\n",
      "Epoch:  1832 Seg loss:  0.1973837014474788 Seg acc:  0.9323792999732644 Disc loss:  0.00063059566 Gen loss:  1.1093028\n",
      "Epoch:  1833 Seg loss:  0.19732254607815333 Seg acc:  0.9324057528084884 Disc loss:  0.0002485997 Gen loss:  1.082886\n",
      "Epoch:  1834 Seg loss:  0.19729014147263968 Seg acc:  0.9324181281018405 Disc loss:  0.0002581569 Gen loss:  1.1306905\n",
      "Epoch:  1835 Seg loss:  0.19723064158446782 Seg acc:  0.9324421676027359 Disc loss:  0.0048965034 Gen loss:  1.0882888\n",
      "Epoch:  1836 Seg loss:  0.19721414273389673 Seg acc:  0.9324456171357431 Disc loss:  0.00045348285 Gen loss:  1.1611975\n",
      "Epoch:  1837 Seg loss:  0.1971929905470714 Seg acc:  0.9324492017819649 Disc loss:  0.0049075303 Gen loss:  1.1500769\n",
      "Epoch:  1838 Seg loss:  0.19712245504455936 Seg acc:  0.9324781816970532 Disc loss:  0.008425626 Gen loss:  1.0708944\n",
      "Epoch:  1839 Seg loss:  0.19709011353653627 Seg acc:  0.9324865998601725 Disc loss:  0.00088782667 Gen loss:  1.1285372\n",
      "Epoch:  1840 Seg loss:  0.1970788656005069 Seg acc:  0.9324907109582964 Disc loss:  0.0005595873 Gen loss:  1.1779281\n",
      "Epoch:  1840 F1 (val):  0.7329640344188058 Acc (val):  0.7698061224489796\n",
      "Epoch:  1841 Seg loss:  0.19703660624902058 Seg acc:  0.9325077043310533 Disc loss:  0.0005568956 Gen loss:  1.1109996\n",
      "Epoch:  1842 Seg loss:  0.19698368240629163 Seg acc:  0.9325263411553547 Disc loss:  0.005638496 Gen loss:  1.0952322\n",
      "Epoch:  1843 Seg loss:  0.19696235376583515 Seg acc:  0.9325282093303952 Disc loss:  0.00169333 Gen loss:  1.1377938\n",
      "Epoch:  1844 Seg loss:  0.19692106993460862 Seg acc:  0.9325472298463854 Disc loss:  0.04412963 Gen loss:  1.071116\n",
      "Epoch:  1845 Seg loss:  0.19687028401266268 Seg acc:  0.9325659532105525 Disc loss:  0.026649533 Gen loss:  1.0535095\n",
      "Epoch:  1846 Seg loss:  0.19681833504839424 Seg acc:  0.9325890784266035 Disc loss:  0.07946764 Gen loss:  1.0980811\n",
      "Epoch:  1847 Seg loss:  0.19679775890154522 Seg acc:  0.9325917372904766 Disc loss:  0.0016612743 Gen loss:  1.136684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1848 Seg loss:  0.19676311807989172 Seg acc:  0.9326047464440321 Disc loss:  0.045686595 Gen loss:  1.1340357\n",
      "Epoch:  1849 Seg loss:  0.19671690082827278 Seg acc:  0.9326210527477622 Disc loss:  0.0015777149 Gen loss:  1.1027501\n",
      "Epoch:  1850 Seg loss:  0.19669146721427505 Seg acc:  0.9326286541643684 Disc loss:  0.002854867 Gen loss:  1.122313\n",
      "Epoch:  1850 F1 (val):  0.7158333330232853 Acc (val):  0.7622959183673469\n",
      "Epoch:  1851 Seg loss:  0.19666614816969372 Seg acc:  0.9326354204566754 Disc loss:  0.0005965103 Gen loss:  1.1491098\n",
      "Epoch:  1852 Seg loss:  0.19664721611734343 Seg acc:  0.9326350167496804 Disc loss:  0.00040492453 Gen loss:  1.1614721\n",
      "Epoch:  1853 Seg loss:  0.19661310083532874 Seg acc:  0.9326449387094287 Disc loss:  0.019176729 Gen loss:  1.1220225\n",
      "Epoch:  1854 Seg loss:  0.19656249601494405 Seg acc:  0.9326650320322304 Disc loss:  0.0031665908 Gen loss:  1.1010126\n",
      "Epoch:  1855 Seg loss:  0.19654982678411465 Seg acc:  0.9326655756642279 Disc loss:  0.0012325109 Gen loss:  1.1565281\n",
      "Epoch:  1856 Seg loss:  0.19652230154064582 Seg acc:  0.932675327674173 Disc loss:  0.00042140012 Gen loss:  1.1465083\n",
      "Epoch:  1857 Seg loss:  0.1964806238802197 Seg acc:  0.9326847944347367 Disc loss:  0.0005224334 Gen loss:  1.1120917\n",
      "Epoch:  1858 Seg loss:  0.19648199768654753 Seg acc:  0.9326796972825728 Disc loss:  0.000573566 Gen loss:  1.1913487\n",
      "Epoch:  1859 Seg loss:  0.19641703006527383 Seg acc:  0.9327071280367983 Disc loss:  0.0021470645 Gen loss:  1.0721747\n",
      "Epoch:  1860 Seg loss:  0.1963840100153159 Seg acc:  0.9327228714066271 Disc loss:  0.0007970104 Gen loss:  1.1270771\n",
      "Epoch:  1860 F1 (val):  0.7399784658410467 Acc (val):  0.771265306122449\n",
      "Epoch:  1861 Seg loss:  0.19634893984163018 Seg acc:  0.93273571922052 Disc loss:  0.015736962 Gen loss:  1.0898834\n",
      "Epoch:  1862 Seg loss:  0.19632420847322452 Seg acc:  0.9327504712948552 Disc loss:  0.0005679755 Gen loss:  1.1421654\n",
      "Epoch:  1863 Seg loss:  0.1962803111392135 Seg acc:  0.9327632905013857 Disc loss:  0.0050941333 Gen loss:  1.0870984\n",
      "Epoch:  1864 Seg loss:  0.19622124527688958 Seg acc:  0.9327866339668915 Disc loss:  0.0002592791 Gen loss:  1.0801052\n",
      "Epoch:  1865 Seg loss:  0.1961949657339193 Seg acc:  0.9327921704874979 Disc loss:  0.00026360204 Gen loss:  1.1339349\n",
      "Epoch:  1866 Seg loss:  0.1961547232174094 Seg acc:  0.9328078176608264 Disc loss:  0.0005317503 Gen loss:  1.1150882\n",
      "Epoch:  1867 Seg loss:  0.1961345766029003 Seg acc:  0.9328211252363826 Disc loss:  0.0046825917 Gen loss:  1.1495882\n",
      "Epoch:  1868 Seg loss:  0.19606100713207966 Seg acc:  0.9328510794039242 Disc loss:  0.0012204527 Gen loss:  1.0605631\n",
      "Epoch:  1869 Seg loss:  0.19600523888283455 Seg acc:  0.9328770432731679 Disc loss:  0.03236804 Gen loss:  1.0608628\n",
      "Epoch:  1870 Seg loss:  0.1959692557427016 Seg acc:  0.9328909745716468 Disc loss:  0.022501497 Gen loss:  1.1218798\n",
      "Epoch:  1870 F1 (val):  0.7318881606166845 Acc (val):  0.7708367346938776\n",
      "Epoch:  1871 Seg loss:  0.19595190430710113 Seg acc:  0.932900800619553 Disc loss:  0.09757577 Gen loss:  1.1119769\n",
      "Epoch:  1872 Seg loss:  0.1959116726747563 Seg acc:  0.9329144317983603 Disc loss:  0.00051096105 Gen loss:  1.1108627\n",
      "Epoch:  1873 Seg loss:  0.19588784969750409 Seg acc:  0.9329108872593351 Disc loss:  0.0022595432 Gen loss:  1.1496332\n",
      "Epoch:  1874 Seg loss:  0.19583084418367805 Seg acc:  0.9329364776860584 Disc loss:  0.0005398234 Gen loss:  1.0851308\n",
      "Epoch:  1875 Seg loss:  0.19578069476683935 Seg acc:  0.932955918367347 Disc loss:  0.00060003996 Gen loss:  1.0949948\n",
      "Epoch:  1876 Seg loss:  0.19578301225469183 Seg acc:  0.9329542611287586 Disc loss:  0.0022797731 Gen loss:  1.1998875\n",
      "Epoch:  1877 Seg loss:  0.19577691367428926 Seg acc:  0.9329562752112033 Disc loss:  0.02127742 Gen loss:  1.1127669\n",
      "Epoch:  1878 Seg loss:  0.195760512317871 Seg acc:  0.9329624980982809 Disc loss:  0.0014830509 Gen loss:  1.1608086\n",
      "Epoch:  1879 Seg loss:  0.1957314021215279 Seg acc:  0.9329802543689111 Disc loss:  0.011257876 Gen loss:  1.1409881\n",
      "Epoch:  1880 Seg loss:  0.19567736407068181 Seg acc:  0.9330020625271386 Disc loss:  0.010707493 Gen loss:  1.0897694\n",
      "Epoch:  1880 F1 (val):  0.7380149363710027 Acc (val):  0.7695714285714286\n",
      "Epoch:  1881 Seg loss:  0.19563446094513193 Seg acc:  0.9330184226800768 Disc loss:  0.09356205 Gen loss:  1.0107381\n",
      "Epoch:  1882 Seg loss:  0.19558175489322285 Seg acc:  0.9330373408662084 Disc loss:  0.0017512089 Gen loss:  1.0745618\n",
      "Epoch:  1883 Seg loss:  0.19551520709559694 Seg acc:  0.9330630127781331 Disc loss:  0.007364307 Gen loss:  1.0467626\n",
      "Epoch:  1884 Seg loss:  0.19545443983246313 Seg acc:  0.933082835044846 Disc loss:  0.00022063665 Gen loss:  1.0786164\n",
      "Epoch:  1885 Seg loss:  0.19543775967482863 Seg acc:  0.9330861256969633 Disc loss:  0.008010192 Gen loss:  1.129339\n",
      "Epoch:  1886 Seg loss:  0.1954183401194256 Seg acc:  0.9330894128595235 Disc loss:  0.003814003 Gen loss:  1.1350776\n",
      "Epoch:  1887 Seg loss:  0.19536834152116306 Seg acc:  0.9331055395131026 Disc loss:  0.002782798 Gen loss:  1.101755\n",
      "Epoch:  1888 Seg loss:  0.1953359443568072 Seg acc:  0.9331175955551713 Disc loss:  0.001131385 Gen loss:  1.1311572\n",
      "Epoch:  1889 Seg loss:  0.19532075212738892 Seg acc:  0.9331209958837956 Disc loss:  0.045849368 Gen loss:  1.11537\n",
      "Epoch:  1890 Seg loss:  0.19528177293047072 Seg acc:  0.9331307364215528 Disc loss:  0.030985821 Gen loss:  1.1200331\n",
      "Epoch:  1890 F1 (val):  0.741130378443992 Acc (val):  0.7735204081632653\n",
      "Epoch:  1891 Seg loss:  0.1952404859108877 Seg acc:  0.9331486957554043 Disc loss:  0.019145649 Gen loss:  1.0763271\n",
      "Epoch:  1892 Seg loss:  0.1952087090648002 Seg acc:  0.9331598945074859 Disc loss:  0.0016311846 Gen loss:  1.1348698\n",
      "Epoch:  1893 Seg loss:  0.19517794409663478 Seg acc:  0.9331704076242223 Disc loss:  0.0006413801 Gen loss:  1.1218294\n",
      "Epoch:  1894 Seg loss:  0.19521146812087756 Seg acc:  0.9331545104842359 Disc loss:  0.0041411025 Gen loss:  1.2549337\n",
      "Epoch:  1895 Seg loss:  0.19523766592027014 Seg acc:  0.9331453610467935 Disc loss:  0.0010803464 Gen loss:  1.232022\n",
      "Epoch:  1896 Seg loss:  0.19519795068708654 Seg acc:  0.9331586906914665 Disc loss:  0.00039054395 Gen loss:  1.1137962\n",
      "Epoch:  1897 Seg loss:  0.19519571879064654 Seg acc:  0.933164072165503 Disc loss:  0.017244313 Gen loss:  1.1829903\n",
      "Epoch:  1898 Seg loss:  0.19515292089357894 Seg acc:  0.9331823509171846 Disc loss:  0.053045053 Gen loss:  1.0384531\n",
      "Epoch:  1899 Seg loss:  0.195090850155061 Seg acc:  0.9332069241598693 Disc loss:  0.0034404693 Gen loss:  1.0576503\n",
      "Epoch:  1900 Seg loss:  0.19504301990725492 Seg acc:  0.9332274436090225 Disc loss:  0.0015821249 Gen loss:  1.0876042\n",
      "Epoch:  1900 F1 (val):  0.7417526799912358 Acc (val):  0.7734285714285715\n",
      "Epoch:  1901 Seg loss:  0.19505659344242096 Seg acc:  0.9332223104917927 Disc loss:  0.0037828276 Gen loss:  1.2180972\n",
      "Epoch:  1902 Seg loss:  0.19506401605081483 Seg acc:  0.933215841541664 Disc loss:  0.00036300023 Gen loss:  1.2057598\n",
      "Epoch:  1903 Seg loss:  0.19503192684632253 Seg acc:  0.9332321683271312 Disc loss:  0.0004455682 Gen loss:  1.1246879\n",
      "Epoch:  1904 Seg loss:  0.19501655507723198 Seg acc:  0.93323682151432 Disc loss:  0.014735736 Gen loss:  1.1690841\n",
      "Epoch:  1905 Seg loss:  0.19499493797854803 Seg acc:  0.9332469602014034 Disc loss:  0.028852226 Gen loss:  1.0711174\n",
      "Epoch:  1906 Seg loss:  0.19499958534446493 Seg acc:  0.9332372796967685 Disc loss:  0.032889508 Gen loss:  1.1686403\n",
      "Epoch:  1907 Seg loss:  0.19500288034007382 Seg acc:  0.9332348329997967 Disc loss:  0.043653224 Gen loss:  1.1375873\n",
      "Epoch:  1908 Seg loss:  0.19498410009128866 Seg acc:  0.9332481656184486 Disc loss:  0.0011487767 Gen loss:  1.1496279\n",
      "Epoch:  1909 Seg loss:  0.19502453616444138 Seg acc:  0.9332372970141435 Disc loss:  0.014407996 Gen loss:  1.2839494\n",
      "Epoch:  1910 Seg loss:  0.1950116812207624 Seg acc:  0.9332424671439257 Disc loss:  0.0015312629 Gen loss:  1.1676652\n",
      "Epoch:  1910 F1 (val):  0.7359669777291356 Acc (val):  0.7713673469387755\n",
      "Epoch:  1911 Seg loss:  0.19497469228203543 Seg acc:  0.9332551073804718 Disc loss:  0.0023914557 Gen loss:  1.0947293\n",
      "Epoch:  1912 Seg loss:  0.1948975311674053 Seg acc:  0.9332864134147383 Disc loss:  0.005005187 Gen loss:  1.0094994\n",
      "Epoch:  1913 Seg loss:  0.1948705419403405 Seg acc:  0.9332994175192294 Disc loss:  0.014710875 Gen loss:  1.1336417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1914 Seg loss:  0.19487655182858557 Seg acc:  0.9332920158659076 Disc loss:  0.0007926021 Gen loss:  1.2023708\n",
      "Epoch:  1915 Seg loss:  0.19481593102177813 Seg acc:  0.9333164597431662 Disc loss:  0.002824908 Gen loss:  1.051311\n",
      "Epoch:  1916 Seg loss:  0.19474658465289 Seg acc:  0.9333414106770057 Disc loss:  0.00042581177 Gen loss:  1.0577215\n",
      "Epoch:  1917 Seg loss:  0.19467556629530078 Seg acc:  0.9333684647567947 Disc loss:  0.018399848 Gen loss:  1.0468827\n",
      "Epoch:  1918 Seg loss:  0.1946591947740478 Seg acc:  0.9333764710263668 Disc loss:  0.00047607778 Gen loss:  1.161769\n",
      "Epoch:  1919 Seg loss:  0.1946354010562185 Seg acc:  0.9333911156958875 Disc loss:  0.0040991423 Gen loss:  1.1255829\n",
      "Epoch:  1920 Seg loss:  0.1946503875059231 Seg acc:  0.9333824936224491 Disc loss:  0.0020450589 Gen loss:  1.219179\n",
      "Epoch:  1920 F1 (val):  0.7243052897220017 Acc (val):  0.7585918367346939\n",
      "Epoch:  1921 Seg loss:  0.19461279892435862 Seg acc:  0.9333976510958367 Disc loss:  0.021247925 Gen loss:  1.1207182\n",
      "Epoch:  1922 Seg loss:  0.19460739359515453 Seg acc:  0.9333976618743232 Disc loss:  0.0008590687 Gen loss:  1.171213\n",
      "Epoch:  1923 Seg loss:  0.19458498334046212 Seg acc:  0.9334080199942691 Disc loss:  0.00063126854 Gen loss:  1.1474568\n",
      "Epoch:  1924 Seg loss:  0.1945792667532878 Seg acc:  0.933402721795579 Disc loss:  0.055630278 Gen loss:  1.1061976\n",
      "Epoch:  1925 Seg loss:  0.19453923705142814 Seg acc:  0.9334147892923405 Disc loss:  0.017082954 Gen loss:  1.0452238\n",
      "Epoch:  1926 Seg loss:  0.19447717346978274 Seg acc:  0.9334419437556953 Disc loss:  0.00054042233 Gen loss:  1.072351\n",
      "Epoch:  1927 Seg loss:  0.19444696516471324 Seg acc:  0.9334509335649154 Disc loss:  0.0031708854 Gen loss:  1.1204612\n",
      "Epoch:  1928 Seg loss:  0.1943849206600663 Seg acc:  0.9334720869675671 Disc loss:  0.020260995 Gen loss:  1.0299149\n",
      "Epoch:  1929 Seg loss:  0.19440110430059623 Seg acc:  0.9334670337808529 Disc loss:  0.0180177 Gen loss:  1.2290154\n",
      "Epoch:  1930 Seg loss:  0.1943779985270815 Seg acc:  0.9334754679073702 Disc loss:  0.00065004197 Gen loss:  1.1565593\n",
      "Epoch:  1930 F1 (val):  0.7425201790182354 Acc (val):  0.7744081632653061\n",
      "Epoch:  1931 Seg loss:  0.19437249300201775 Seg acc:  0.9334717392912628 Disc loss:  0.0012788353 Gen loss:  1.1749239\n",
      "Epoch:  1932 Seg loss:  0.19434977115920551 Seg acc:  0.9334849157054127 Disc loss:  0.0023972644 Gen loss:  1.1323092\n",
      "Epoch:  1933 Seg loss:  0.194330036106331 Seg acc:  0.9334880486079584 Disc loss:  0.0006408276 Gen loss:  1.1536701\n",
      "Epoch:  1934 Seg loss:  0.19428712345906288 Seg acc:  0.933504368655425 Disc loss:  0.002035381 Gen loss:  1.1052386\n",
      "Epoch:  1935 Seg loss:  0.1942554725444748 Seg acc:  0.9335244950693455 Disc loss:  0.0007146257 Gen loss:  1.1328855\n",
      "Epoch:  1936 Seg loss:  0.19420224023513372 Seg acc:  0.9335467089728453 Disc loss:  0.00035837863 Gen loss:  1.0848707\n",
      "Epoch:  1937 Seg loss:  0.19419522074406517 Seg acc:  0.933550462002044 Disc loss:  0.04933279 Gen loss:  1.1296506\n",
      "Epoch:  1938 Seg loss:  0.1941684275669487 Seg acc:  0.9335578968429478 Disc loss:  0.007864938 Gen loss:  1.1335005\n",
      "Epoch:  1939 Seg loss:  0.1941408171323755 Seg acc:  0.9335719022007979 Disc loss:  0.0006500753 Gen loss:  1.1370221\n",
      "Epoch:  1940 Seg loss:  0.19410166196793932 Seg acc:  0.9335820797391121 Disc loss:  0.0014575269 Gen loss:  1.110642\n",
      "Epoch:  1940 F1 (val):  0.7364483885749235 Acc (val):  0.7747755102040816\n",
      "Epoch:  1941 Seg loss:  0.19410137308013925 Seg acc:  0.9335846239577748 Disc loss:  0.00031497199 Gen loss:  1.1842344\n",
      "Epoch:  1942 Seg loss:  0.1940728020782359 Seg acc:  0.9335968862313205 Disc loss:  0.00032774563 Gen loss:  1.1327521\n",
      "Epoch:  1943 Seg loss:  0.19405413068336308 Seg acc:  0.9335936433245455 Disc loss:  0.0037124925 Gen loss:  1.1559539\n",
      "Epoch:  1944 Seg loss:  0.19400139128283403 Seg acc:  0.9336140243134291 Disc loss:  0.003309099 Gen loss:  1.0881958\n",
      "Epoch:  1945 Seg loss:  0.19399319428826053 Seg acc:  0.9336177272965742 Disc loss:  0.00032537166 Gen loss:  1.1682895\n",
      "Epoch:  1946 Seg loss:  0.19398787679516338 Seg acc:  0.9336237861023136 Disc loss:  0.010586329 Gen loss:  1.1756765\n",
      "Epoch:  1947 Seg loss:  0.19396079450455395 Seg acc:  0.9336341624477217 Disc loss:  0.00032900184 Gen loss:  1.1370807\n",
      "Epoch:  1948 Seg loss:  0.19390587202126058 Seg acc:  0.9336546117420275 Disc loss:  0.001546486 Gen loss:  1.0772649\n",
      "Epoch:  1949 Seg loss:  0.19384875275641908 Seg acc:  0.9336751709406185 Disc loss:  0.0006316718 Gen loss:  1.0782698\n",
      "Epoch:  1950 Seg loss:  0.19383705970377493 Seg acc:  0.9336824960753533 Disc loss:  0.006740652 Gen loss:  1.1684855\n",
      "Epoch:  1950 F1 (val):  0.7396617144121738 Acc (val):  0.7732448979591837\n",
      "Epoch:  1951 Seg loss:  0.19380266942095292 Seg acc:  0.933691252000544 Disc loss:  0.017334465 Gen loss:  1.1129746\n",
      "Epoch:  1952 Seg loss:  0.19377621637893933 Seg acc:  0.9337001296420208 Disc loss:  0.049884427 Gen loss:  1.1290175\n",
      "Epoch:  1953 Seg loss:  0.19370362535882046 Seg acc:  0.9337248032853694 Disc loss:  0.008072186 Gen loss:  1.0163927\n",
      "Epoch:  1954 Seg loss:  0.19370639727030525 Seg acc:  0.9337149854824223 Disc loss:  0.00044577726 Gen loss:  1.1979808\n",
      "Epoch:  1955 Seg loss:  0.19366341799002168 Seg acc:  0.9337298397619918 Disc loss:  0.0031395485 Gen loss:  1.1038566\n",
      "Epoch:  1956 Seg loss:  0.1935974938132189 Seg acc:  0.9337514607069822 Disc loss:  0.00041149673 Gen loss:  1.0536568\n",
      "Epoch:  1957 Seg loss:  0.19354393562196345 Seg acc:  0.9337705828371206 Disc loss:  0.002339689 Gen loss:  1.0827639\n",
      "Epoch:  1958 Seg loss:  0.19352290045138948 Seg acc:  0.9337732692668488 Disc loss:  0.054143704 Gen loss:  1.0997647\n",
      "Epoch:  1959 Seg loss:  0.19348548608107066 Seg acc:  0.9337893656696982 Disc loss:  0.009547159 Gen loss:  1.0701525\n",
      "Epoch:  1960 Seg loss:  0.19349211053542642 Seg acc:  0.9337854019158685 Disc loss:  0.0014376407 Gen loss:  1.2049835\n",
      "Epoch:  1960 F1 (val):  0.750810182011163 Acc (val):  0.7835\n",
      "Epoch:  1961 Seg loss:  0.19346006534336357 Seg acc:  0.9338010854520289 Disc loss:  0.0006748874 Gen loss:  1.1112223\n",
      "Epoch:  1962 Seg loss:  0.19341770929989768 Seg acc:  0.9338145426366266 Disc loss:  0.0018764881 Gen loss:  1.107633\n",
      "Epoch:  1963 Seg loss:  0.19334711818953468 Seg acc:  0.9338437106885547 Disc loss:  0.00040072895 Gen loss:  1.0445096\n",
      "Epoch:  1964 Seg loss:  0.19334287898778127 Seg acc:  0.9338486896795378 Disc loss:  0.0008386154 Gen loss:  1.1859841\n",
      "Epoch:  1965 Seg loss:  0.19329520301092368 Seg acc:  0.933866126603313 Disc loss:  0.0014903087 Gen loss:  1.1095837\n",
      "Epoch:  1966 Seg loss:  0.19325352055593825 Seg acc:  0.933883416031723 Disc loss:  0.0020168899 Gen loss:  1.1102121\n",
      "Epoch:  1967 Seg loss:  0.19320682806862935 Seg acc:  0.9339025035535312 Disc loss:  0.0009640157 Gen loss:  1.0946138\n",
      "Epoch:  1968 Seg loss:  0.19315337683301328 Seg acc:  0.9339210531773685 Disc loss:  0.025687788 Gen loss:  1.0384302\n",
      "Epoch:  1969 Seg loss:  0.1931039178455433 Seg acc:  0.9339406204330386 Disc loss:  0.00097358826 Gen loss:  1.0858984\n",
      "Epoch:  1970 Seg loss:  0.19309421040798505 Seg acc:  0.9339461825339274 Disc loss:  0.024434052 Gen loss:  1.1296268\n",
      "Epoch:  1970 F1 (val):  0.7340174705503499 Acc (val):  0.7662857142857142\n",
      "Epoch:  1971 Seg loss:  0.19305948737889664 Seg acc:  0.9339589869433315 Disc loss:  0.008253443 Gen loss:  1.1116099\n",
      "Epoch:  1972 Seg loss:  0.19306008668302824 Seg acc:  0.9339536676739661 Disc loss:  0.0060410947 Gen loss:  1.1907771\n",
      "Epoch:  1973 Seg loss:  0.19300240467623955 Seg acc:  0.9339773162179215 Disc loss:  0.011795064 Gen loss:  1.0687327\n",
      "Epoch:  1974 Seg loss:  0.19298011203991908 Seg acc:  0.9339849161549119 Disc loss:  0.00032173534 Gen loss:  1.1397285\n",
      "Epoch:  1975 Seg loss:  0.1929524504289597 Seg acc:  0.9339987083440972 Disc loss:  0.020513091 Gen loss:  1.0855737\n",
      "Epoch:  1976 Seg loss:  0.19291893290808265 Seg acc:  0.9340154558787078 Disc loss:  0.03875234 Gen loss:  1.0524228\n",
      "Epoch:  1977 Seg loss:  0.19287193910071326 Seg acc:  0.9340301219121944 Disc loss:  0.00071678066 Gen loss:  1.0993868\n",
      "Epoch:  1978 Seg loss:  0.1928680857513533 Seg acc:  0.9340335527537608 Disc loss:  0.00023827566 Gen loss:  1.184771\n",
      "Epoch:  1979 Seg loss:  0.19286972396696922 Seg acc:  0.9340336286106156 Disc loss:  0.022352759 Gen loss:  1.1973221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1980 Seg loss:  0.19282448767599733 Seg acc:  0.9340517419088848 Disc loss:  0.00043102133 Gen loss:  1.0962574\n",
      "Epoch:  1980 F1 (val):  0.7473388666839502 Acc (val):  0.7758979591836734\n",
      "Epoch:  1981 Seg loss:  0.19283239778313657 Seg acc:  0.9340560580617912 Disc loss:  0.044923577 Gen loss:  1.1844953\n",
      "Epoch:  1982 Seg loss:  0.192801313801818 Seg acc:  0.9340624292098272 Disc loss:  0.033100817 Gen loss:  1.1306651\n",
      "Epoch:  1983 Seg loss:  0.19277135889734875 Seg acc:  0.9340739397120423 Disc loss:  0.00049809105 Gen loss:  1.1263762\n",
      "Epoch:  1984 Seg loss:  0.19274628131027002 Seg acc:  0.9340791382077025 Disc loss:  0.0012918864 Gen loss:  1.1347637\n",
      "Epoch:  1985 Seg loss:  0.19275832359564093 Seg acc:  0.9340740502750219 Disc loss:  0.0014955509 Gen loss:  1.1991647\n",
      "Epoch:  1986 Seg loss:  0.1927074182493479 Seg acc:  0.9340976118544095 Disc loss:  0.0008892341 Gen loss:  1.0871919\n",
      "Epoch:  1987 Seg loss:  0.19267384635371723 Seg acc:  0.9341054866838533 Disc loss:  0.058755673 Gen loss:  1.0207357\n",
      "Epoch:  1988 Seg loss:  0.1926466615016102 Seg acc:  0.934120411242968 Disc loss:  0.0034003663 Gen loss:  1.11569\n",
      "Epoch:  1989 Seg loss:  0.19262768370331143 Seg acc:  0.9341147997660603 Disc loss:  0.0004039717 Gen loss:  1.1495948\n",
      "Epoch:  1990 Seg loss:  0.19258949927910787 Seg acc:  0.9341284227258744 Disc loss:  0.0010794149 Gen loss:  1.1161796\n",
      "Epoch:  1990 F1 (val):  0.7444957885672555 Acc (val):  0.7783775510204082\n",
      "Epoch:  1991 Seg loss:  0.19255271047495945 Seg acc:  0.934144850808229 Disc loss:  0.07373293 Gen loss:  1.0165422\n",
      "Epoch:  1992 Seg loss:  0.1925329743009285 Seg acc:  0.9341481999426277 Disc loss:  0.021875747 Gen loss:  1.1087595\n",
      "Epoch:  1993 Seg loss:  0.19250598314512152 Seg acc:  0.9341570496738586 Disc loss:  0.0145896 Gen loss:  1.0939593\n",
      "Epoch:  1994 Seg loss:  0.1924501847841944 Seg acc:  0.9341785560763924 Disc loss:  0.0021672198 Gen loss:  1.0639799\n",
      "Epoch:  1995 Seg loss:  0.19239937244239905 Seg acc:  0.9342011917548976 Disc loss:  0.0014724571 Gen loss:  1.0825512\n",
      "Epoch:  1996 Seg loss:  0.19242683237601438 Seg acc:  0.9341830344362194 Disc loss:  0.009932276 Gen loss:  1.2501446\n",
      "Epoch:  1997 Seg loss:  0.19239556205327893 Seg acc:  0.9341938928801365 Disc loss:  0.050589815 Gen loss:  1.0750356\n",
      "Epoch:  1998 Seg loss:  0.19237328006198873 Seg acc:  0.93420052705767 Disc loss:  0.0009120746 Gen loss:  1.1444805\n",
      "Epoch:  1999 Seg loss:  0.19234070235703993 Seg acc:  0.9342047299159784 Disc loss:  0.0003458893 Gen loss:  1.1222421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/unet_acdc_epochs_1999.ckpt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/danielcsonth/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from models/unet_acdc_epochs_1999.ckpt\n",
      "best model chkpt name models/unet_acdc_epochs_1999.ckpt\n",
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "# Run for n_epochs\n",
    "\n",
    "# arrays to store metrics from every epoch\n",
    "seg_cost_epoch = np.array([])\n",
    "seg_acc_epoch = np.array([])\n",
    "g_loss_epoch = np.array([])\n",
    "d_loss_epoch = np.array([])\n",
    "val_acc_epoch = np.array([])\n",
    "val_f1_epoch = np.array([])\n",
    "\n",
    "\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "    \n",
    "\n",
    "    \n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batches=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),labels_present=0)\n",
    "    # P: already did this above\n",
    "#     unld_img_batch = np.moveaxis(unld_img_batch,3,0).reshape(20,16,16,16)\n",
    "    \n",
    "    # sample Labelled shuffled batch\n",
    "    ld_img_batches,ld_label_batches=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size)\n",
    "    # P: already did this above\n",
    "#     ld_img_batch = np.moveaxis(ld_img_batch,3,0)\n",
    "#     ld_label_batch = np.moveaxis(ld_label_batch,2,0)\n",
    "\n",
    "    minibatches = math.floor(len(train_imgs)/cfg.batch_size+0.5)\n",
    "    for b in range(minibatches):\n",
    "        \n",
    "        unld_img_batch = unld_img_batches[b]\n",
    "        ld_img_batch = ld_img_batches[b]\n",
    "        ld_label_batch = ld_label_batches[b]\n",
    "\n",
    "        # sample z's from Gaussian Distribution\n",
    "        z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "        if(cfg.aug_en==1):\n",
    "            # Apply affine transformations\n",
    "            ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "            unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "        ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "        # Compute 1 hot encoding of the segmentation mask labels\n",
    "        ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})    \n",
    "\n",
    "        if(epoch_i>=seg_tr_limit):\n",
    "            # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "            # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "            ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "            ###########################\n",
    "            ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "            flow_vec,ld_img_batch=sess.run([ae['flow_vec'],ae['y_trans']],\\\n",
    "                                        feed_dict={ae['x_l']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "\n",
    "            ld_label_batch=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch,df_ae['flow_v']:flow_vec})\n",
    "            ld_label_batch=ld_label_batch[0]\n",
    "\n",
    "            ###########################\n",
    "            #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original images with conventional affine transformations\n",
    "            no_orig=np.random.randint(5, high=15)\n",
    "            ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "            if(params.en_1hot==1):\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n",
    "            #D: this else statement here baffles me - we will have to look into it at some later point - why would you turn images back from 1hot to\n",
    "            # regular 1d classes with that argmax? When the ld_label batch assumes 1hot input? and especially in a scenario called 1hot == 0\n",
    "            else:\n",
    "                ld_label_batch = np.argmax(ld_label_batch,axis=3)\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n",
    "\n",
    "            #Pick equal number of images from each category\n",
    "            # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "            # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "        elif(epoch_i<seg_tr_limit):\n",
    "            # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "            ld_img_batch=ld_img_batch\n",
    "            unld_img_batch=unld_img_batch\n",
    "            ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        if(epoch_i<seg_tr_limit):\n",
    "            #Optimize only Segmentation Network for initial 500 epochs\n",
    "            train_summary, seg_cost, _ =sess.run([ae['seg_summary'], ae['seg_cost'], ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                       ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch))\n",
    "\n",
    "\n",
    "         #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs       \n",
    "        if(epoch_i>seg_tr_limit):   \n",
    "\n",
    "            # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "            train_summary, z_cost, cost_a1_seg, seg_cost, _ =sess.run([ae['train_summary'],\\\n",
    "                                                                       ae['z_cost'],  ae['cost_a1_seg'], ae['seg_cost'], ae['optimizer_l2_both_gen_unet']],\\\n",
    "                                                                       feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                       ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "            # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "            train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch, ae['x_l']: ld_img_batch, ae['z']:z_samples,\\\n",
    "                                  ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                g_loss_epoch = np.append(g_loss_epoch, cost_a1_seg)\n",
    "                d_loss_epoch = np.append(d_loss_epoch, z_cost)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch), \"Disc loss: \", z_cost, \"Gen loss: \", cost_a1_seg,)\n",
    "\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        f1_arr=[]\n",
    "\n",
    "        # Compute segmentation mask and dice_score validation data\n",
    "        val_pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_imgs)\n",
    "        f1_val = np.mean(f1_util.calc_f1_score(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_f1_epoch = np.append(val_f1_epoch, f1_val)\n",
    "        val_acc = np.mean(f1_util.calc_accuracy(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_acc_epoch = np.append(val_acc_epoch, val_acc)\n",
    "\n",
    "        print(\"Epoch: \", epoch_i, \"F1 (val): \", f1_val, \"Acc (val): \", val_acc)\n",
    "        \n",
    "\n",
    "\n",
    "        # if (f1_val-f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "        #     print(\"prev f1_val; present_f1_val\", f1_val_prev, f1_val)\n",
    "        #     f1_val_prev = f1_val\n",
    "        #     # to save the best model with maximum dice score over the entire n_epochs\n",
    "        #     print(\"best model saved at epoch no. \", epoch_i)\n",
    "        #     mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "        #     saver.save(sess, mp_best)\n",
    "\n",
    "        # # calc. and save validation image dice summary\n",
    "        # dsc_summary_msg = sess.run(ae['val_f1_summary'], feed_dict={ae['f1']:f1_val})\n",
    "        # val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        # val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt name\",mp_best)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TkAgg')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Batch Segmentation Cost')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1 Validation Score')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15c7b9d90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Tree GAN Training (2k Epochs). Medium Dataset')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Segmentation Cost', color='red')\n",
    "ln1 = ax1.plot(seg_cost_epoch, color='red', label='SegCost')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('F1 Validation Score', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(seg_acc_epoch, color ='green', label = 'Seg Acc')\n",
    "#D: this is a hacky way of getting the validation data scores that are only calculated every few epochs to show properly on this graph\n",
    "# it basically just repeats every value val_step_update number of times, so that it is flat for val_step_update epochs and thus works on the same x axis\n",
    "ln3 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_f1_epoch]) for i in b], color='blue', label = \"F1score\")\n",
    "ln4 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_acc_epoch]) for i in b], color=\"orange\", label = \"Valid. Acc.\")\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"Tree GAN Training (2k Epochs). Medium Dataset\")\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(val_acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_epoch[196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Batch Generator Loss')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Batch Discrimanotr Loss')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15ca34910>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'GAN Losses')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig2, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Generator Loss', color='red')\n",
    "ln1 = ax1.plot(g_loss_epoch, color='red', label='Gen Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('Batch Discrimanotr Loss', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(d_loss_epoch, color ='green', label = 'Disc Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "fig2.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"GAN Losses\")\n",
    "\n",
    "fig2.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_normalize(array):\n",
    "    x_min = np.min(array)\n",
    "    x_range = np.max(array) - np.min(array)  \n",
    "    n = np.prod(array.shape[:-1])\n",
    "    dim = array.shape\n",
    "    return (array - x_min) / x_range\n",
    "\n",
    "##\n",
    "\n",
    "deformed_images = np_normalize(np.copy(ld_img_batch[no_orig:])[:,1:15,1:15,2:5])\n",
    "deformed_labels = np_normalize(np.argmax(np.copy(ld_label_batch[no_orig:]), -1))\n",
    "\n",
    "real_images = np_normalize(np.copy(ld_img_batch_tmp[no_orig:])[:,1:15,1:15,2:5])\n",
    "real_labels = np_normalize(np.copy(ld_label_batch_tmp[no_orig:]))\n",
    "\n",
    "##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def highlight_cell(x,y, ax=None, **kwargs):\n",
    "    rect = plt.Rectangle((x-.5, y-.5), 1,1, fill=False, **kwargs)\n",
    "    ax = ax or plt.gca()\n",
    "    ax.add_patch(rect)\n",
    "    return rect\n",
    "\n",
    "# Plot Images along chosen axes\n",
    "def plot_deformed_imgs(deformed_images, deformed_labels, real_images, real_labels, plot_ax=(7,2)):\n",
    "    \n",
    "    assert len(deformed_images) == plot_ax[0], \"dimensions do not match\"\n",
    "    \n",
    "    plt.figure(figsize=(10,20))\n",
    "    gs1 = gridspec.GridSpec(plot_ax[0], plot_ax[1])\n",
    "    gs1.update(wspace=0.5, hspace=0.2) # set the spacing between axes. \n",
    "    \n",
    "    i = 0 \n",
    "    for n in range(plot_ax[0]):\n",
    "        plt.subplot(gs1[i])\n",
    "        plt.imshow(real_images[n])\n",
    "        for x in range(real_labels[n].shape[0]):\n",
    "            for y in range(real_labels[n].shape[1]):\n",
    "                if(real_labels[n][y,x] == 1):\n",
    "                    highlight_cell(x,y,color=\"red\", linewidth=0.5, alpha = 1)\n",
    "        plt.title('True RGB Image')\n",
    "\n",
    "        plt.subplot(gs1[i+1])\n",
    "        plt.imshow(deformed_images[n])\n",
    "        for x in range(deformed_labels[n].shape[0]):\n",
    "            for y in range(deformed_labels[n].shape[1]):\n",
    "                if(deformed_labels[n][y,x] == 1):\n",
    "                    highlight_cell(x,y,color=\"red\", linewidth=0.5, alpha = 1)\n",
    "        plt.title('Deformed RGB')\n",
    "        i += 2\n",
    "    plt.savefig(\"deformed.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "##\n",
    "\n",
    "plot_deformed_imgs(deformed_images, deformed_labels, real_images, real_labels, plot_ax=(8,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deformed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITKtK1haQdKG"
   },
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOCLtLtAQdKJ"
   },
   "outputs": [],
   "source": [
    "logs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6loZeYJQdKW"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir data_aug_seg/models/dabes/tflogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qkl7qlDNQdKZ"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "#D: we will have to put back some of these validation data references\n",
    "# To compute inference on validation images on the best model\n",
    "#save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "#f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI-JoaIAOeFl"
   },
   "source": [
    "# Train Additive Intensity Field GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGmOCYBzOi3g"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "# load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "# load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# load unlabeled images\n",
    "unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_img_labels(unl_list,label_present=0)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot intensity transformed images for an fixed input image and different sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    int_vec,y_int_deformed,z_cost=sess.run([ae['int_c1'],ae['y_int'],ae['z_cost']], feed_dict={ae['x']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_intensity_transformed_imgs(ld_img_tmp,y_int_deformed,int_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the transformed images generated for the fixed input image\n",
    "    #f1_util.write_gif_func(ip_img=y_int_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define additive intensity field generator model graph\n",
    "ae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define graph to compute 1 hot encoding for an input label\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labeled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        # Here, the labels do not change on application of intensity transformation since it is an additive operation\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        # use additive intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        _,ld_img_batch=sess.run([ae['int_c1'],ae['y_int']],\\\n",
    "                                    feed_dict={ae['x']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        ###########################\n",
    "        # shuffle the quantity/number of images chosen from intensity field cGAN augmented images and rest are original images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch = ld_label_batch_1hot\n",
    "        else:\n",
    "            ld_label_batch = ld_label_batch_tmp\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        #Optimize only Segmentation Network for initial 500 epochs\n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr = np.asarray(mean_f1_arr)\n",
    "        mean_f1 = np.mean(mean_f1_arr)\n",
    "        f1_arr = np.asarray(f1_arr)\n",
    "\n",
    "        if ((epoch_i%disp_step == 0) or (epoch_i==n_epochs-1)):\n",
    "            print('mean_f1',epoch_i, mean_f1)\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Htfi8elnNp4c"
   },
   "source": [
    "# Train Unet with trained GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_67bO43M4_R"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('set acdc img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "proj_save_name='tr_deform_and_int_cgans_data_aug/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+\\\n",
    "         '_lamda_g_'+str(params.lamda_l1_g)+'_lamda_i_'+str(params.lamda_l1_i)+\\\n",
    "         '/'+str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+'/unet_model_dsc_loss_'+str(params.dsc_loss)+'_lr_seg_'+str(params.lr_seg)+'/'\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#print(train_list)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "#print(val_list)\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "#print(pixel_val_list)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load deformation field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_geo = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading deformation field cGAN checkpoint file',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_geo = tf.train.Saver(max_to_keep=2)\n",
    "sess_geo = tf.Session(config=config)\n",
    "saver_geo.restore(sess_geo,mp)\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load additive intensity field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_int = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading additive intensity field cGAN checkpoint file ',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_int = tf.train.Saver(max_to_keep=2)\n",
    "sess_int = tf.Session(config=config)\n",
    "saver_int.restore(sess_int,mp)\n",
    "\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=500\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "debug_en=0\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define current graph - unet\n",
    "tf.reset_default_graph()\n",
    "ae = model.unet(learn_rate_seg=params.lr_seg,en_1hot=params.en_1hot,dsc_loss=params.dsc_loss)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define deformations net for labels\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "\n",
    "    ld_img_batch_orig_tmp=np.copy(ld_img_batch)\n",
    "    ld_label_batch_orig_tmp=np.copy(ld_label_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_orig_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp})\n",
    "\n",
    "    ############################\n",
    "    ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    flow_vec,ld_img_batch_geo=sess_geo.run([ae_geo['flow_vec'],ae_geo['y_trans']],\\\n",
    "                                feed_dict={ae_geo['x_l']: ld_img_batch_orig_tmp, ae_geo['z']:z_samples, ae_geo['train_phase']: False})\n",
    "\n",
    "    ld_label_batch_geo=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp,df_ae['flow_v']:flow_vec})\n",
    "    ld_label_batch_geo=ld_label_batch_geo[0]\n",
    "\n",
    "    ############################\n",
    "    # use additive Intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    int_c1,ld_img_batch_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_orig_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_int = ld_label_batch_orig_1hot\n",
    "\n",
    "    ############################\n",
    "    # use additive intensity field cGAN over augmented images generated from deformation field cGAN to create augmented images \\\n",
    "    # that have both spatial deformations and intensity transformations applied in them\n",
    "    ld_img_batch_geo_tmp=np.copy(ld_img_batch_geo)\n",
    "    int_c1,ld_img_batch_geo_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_geo_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_geo_int = np.copy(ld_label_batch_geo)\n",
    "\n",
    "    # shuffle the quantity/number of images chosen from \n",
    "    # deformation field cGAN --> no_g,\n",
    "    # intensity field cGAN   --> no_i,\n",
    "    # both cGANs             --> no_b,\n",
    "    # and rest (batch_size - (no_g+no_i+no_b)) are original images with conventional affine transformations.\n",
    "    no_g=np.random.randint(1, high=5)\n",
    "    no_i=np.random.randint(5, high=10)\n",
    "    no_b=np.random.randint(10, high=15)\n",
    "\n",
    "    ld_img_batch=ld_img_batch_orig_tmp\n",
    "    ld_label_batch=ld_label_batch_orig_1hot\n",
    "\n",
    "    ld_img_batch[0:no_g] = ld_img_batch_geo[0:no_g]\n",
    "    ld_label_batch[0:no_g] = ld_label_batch_geo[0:no_g]\n",
    "    ld_img_batch[no_g:no_i] = ld_img_batch_int[no_g:no_i]\n",
    "    ld_label_batch[no_g:no_i] = ld_label_batch_int[no_g:no_i]\n",
    "    ld_img_batch[no_i:no_b] = ld_img_batch_geo_int[no_i:no_b]\n",
    "    ld_label_batch[no_i:no_b] = ld_label_batch_geo_int[no_i:no_b]\n",
    "\n",
    "    #Optimer over this batch of images\n",
    "    train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                               ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "        mean_f1=np.mean(mean_f1_arr)\n",
    "        f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQSIfVO4TuWI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
